2023.11.23 14:00:49 INFO  Started: Metals version 1.1.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.84.2.
2023.11.23 14:00:51 WARN  Build server is not auto-connectable.
2023.11.23 14:00:51 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.11.23 14:00:51 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala
2023.11.23 14:00:52 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\example.scala
2023.11.23 14:00:52 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
2023.11.23 14:01:15 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\example.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.11.23 14:03:19 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
Nov 23, 2023 2:04:15 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 65
2023.11.23 14:11:18 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
2023.11.23 14:13:50 INFO  
2023.11.23 14:13:50 INFO  Template applied in C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\.\hello-world
2023.11.23 14:13:50 INFO  
2023.11.23 14:13:50 INFO  time: ran 'giter8.Giter8' in 10s
2023.11.23 14:13:59 INFO  Shutting down server
2023.11.23 14:13:59 INFO  shutting down Metals
2023.11.23 14:13:59 INFO  Exiting server
2023.11.23 14:14:21 INFO  Started: Metals version 1.1.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.84.2.
2023.11.23 14:14:22 WARN  Build server is not auto-connectable.
2023.11.23 14:14:22 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.11.23 14:14:23 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\example.scala
2023.11.23 14:14:26 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\example.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.11.23 14:14:29 INFO  time: code lens generation in 6.48s
2023.11.23 14:14:38 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\build.sbt
2023.11.23 14:14:38 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/scalaproject/hello-world/build.sbt
2023.11.23 14:14:39 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/scalaproject/hello-world/build.sbt
2023.11.23 14:14:57 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\build.sbt
2023.11.23 14:14:57 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/scalaproject/hello-world/build.sbt
2023.11.23 14:14:58 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/scalaproject/hello-world/build.sbt
2023.11.23 14:15:09 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala
2023.11.23 14:15:31 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\Main.scala
2023.11.23 14:15:48 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
2023.11.23 14:16:11 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
2023.11.23 14:16:51 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
2023.11.23 14:20:11 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\build.sbt
2023.11.23 14:20:11 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/scalaproject/hello-world/build.sbt
2023.11.23 14:20:12 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/scalaproject/hello-world/build.sbt
2023.11.23 14:20:20 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\Main.scala
Nov 23, 2023 2:24:23 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 140
2023.11.23 14:24:25 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\Main.scala
Nov 23, 2023 2:24:25 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 146
2023.11.23 14:25:10 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\Main.scala
2023.11.23 14:31:56 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\build.sbt
2023.11.23 14:31:56 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/scalaproject/hello-world/build.sbt
2023.11.23 14:31:56 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/scalaproject/hello-world/build.sbt
2023.11.23 14:42:52 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\example.scala
2023.11.23 14:43:01 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\example.scala
Nov 23, 2023 5:04:55 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 272
2023.11.23 17:05:35 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
2023.11.23 17:05:35 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/scalaproject/hello-world/src/main/scala/read.scala
2023.11.23 17:05:49 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
Exception in thread "pool-3-thread-1" java.lang.InterruptedException
	at scala.meta.internal.metals.FutureCancelToken.checkCanceled(FutureCancelToken.scala:29)
	at scala.meta.internal.pc.CompilerAccess.onCompilerJobQueue$$anonfun$1(CompilerAccess.scala:230)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:152)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2023.11.23 17:06:28 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\Main.scala
Nov 23, 2023 5:08:15 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 732
2023.11.23 17:08:53 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
scala.meta.tokenizers.TokenizeException: <input>:26: error: unclosed string interpolation
    .format(csv")
                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.23 17:10:59 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
2023.11.23 17:11:31 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
Nov 23, 2023 5:14:34 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1080
2023.11.23 17:14:34 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
Nov 23, 2023 5:14:34 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1081
Nov 23, 2023 5:15:21 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1117
2023.11.23 17:15:47 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
2023.11.23 17:26:52 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
Nov 23, 2023 5:27:27 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1457
Nov 23, 2023 5:28:51 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1672
Nov 23, 2023 5:29:08 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1701
2023.11.23 17:29:15 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
2023.11.23 17:30:24 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
Nov 23, 2023 5:32:06 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1828
2023.11.23 17:32:51 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
2023.11.23 17:32:59 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
scala.meta.tokenizers.TokenizeException: <input>:68: error: invalid escape character
    .option("path","C:\\Users\\pp255070\\OneDrive - Teradata\\Documents\\sparklearning\\C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\users-201019-002101.parquet")
                                                                                           ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.23 17:33:06 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
scala.meta.tokenizers.TokenizeException: <input>:68: error: invalid escape character
    .option("path","C:\\Users\\pp255070\\OneDrive - Teradata\\Documents\\sparklearning\\C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearningusers-201019-002101.parquet")
                                                                                           ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.23 17:33:07 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
scala.meta.tokenizers.TokenizeException: <input>:68: error: invalid escape character
    .option("path","C:\\Users\\pp255070\\OneDrive - Teradata\\Documents\\sparklearning\\C:\Users\pp255070\OneDrive - Teradata\Documentsusers-201019-002101.parquet")
                                                                                           ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.23 17:33:07 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
scala.meta.tokenizers.TokenizeException: <input>:68: error: invalid escape character
    .option("path","C:\\Users\\pp255070\\OneDrive - Teradata\\Documents\\sparklearning\\C:\Users\pp255070\OneDrive - Terusers-201019-002101.parquet")
                                                                                           ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.23 17:33:08 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
scala.meta.tokenizers.TokenizeException: <input>:68: error: invalid escape character
    .option("path","C:\\Users\\pp255070\\OneDrive - Teradata\\Documents\\sparklearning\\C:\Users\pp255070users-201019-002101.parquet")
                                                                                           ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.23 17:33:15 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
2023.11.23 17:35:51 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
Nov 23, 2023 5:56:36 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2864
2023.11.23 17:56:48 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
2023.11.23 17:57:33 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
2023.11.23 17:58:27 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
Nov 23, 2023 5:58:43 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3178
Nov 23, 2023 5:59:05 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3247
2023.11.23 18:03:38 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
2023.11.23 18:20:50 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
2023.11.23 18:20:51 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
2023.11.23 18:31:14 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
2023.11.23 21:40:53 INFO  Shutting down server
2023.11.23 21:40:53 INFO  shutting down Metals
2023.11.23 21:40:53 INFO  Exiting server
2023.11.24 14:33:23 INFO  Started: Metals version 1.1.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.84.2.
2023.11.24 14:33:23 WARN  Build server is not auto-connectable.
2023.11.24 14:33:23 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.11.24 14:33:23 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
2023.11.24 14:33:31 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.11.24 14:33:35 INFO  time: code lens generation in 11s
2023.11.24 14:44:02 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
2023.11.24 14:44:02 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.24 14:44:02 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.24 14:51:03 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.24 14:52:00 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.24 14:53:26 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.24 14:57:48 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.24 14:58:37 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.24 15:06:01 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.24 15:06:48 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.24 15:06:59 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\\Users\pp255070\Downloads\customerorders.csv")
                                       ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.24 15:07:02 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\\Users\\pp255070\Downloads\customerorders.csv")
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.24 15:07:05 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\\Users\\pp255070\\Downloads\customerorders.csv")
                                                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.24 15:07:10 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
2023.11.24 15:07:19 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
2023.11.24 15:07:51 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad3.scala
2023.11.24 15:07:51 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad3.scala
scala.meta.tokenizers.TokenizeException: <input>:5: error: invalid escape character
    val base = sc.textFile("C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\ratings-201019-002101.dat")
                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.24 15:07:51 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad3.scala
scala.meta.tokenizers.TokenizeException: <input>:5: error: invalid escape character
    val base = sc.textFile("C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\ratings-201019-002101.dat")
                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.24 15:07:57 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad3.scala
scala.meta.tokenizers.TokenizeException: <input>:5: error: invalid escape character
    val base = sc.textFile("C:\\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\ratings-201019-002101.dat")
                                      ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.24 15:08:00 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad3.scala
scala.meta.tokenizers.TokenizeException: <input>:5: error: invalid escape character
    val base = sc.textFile("C:\\Users\\pp255070\OneDrive - Teradata\Documents\sparklearning\ratings-201019-002101.dat")
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.24 15:08:02 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad3.scala
scala.meta.tokenizers.TokenizeException: <input>:5: error: invalid escape character
    val base = sc.textFile("C:\\Users\\pp255070\\OneDrive - Teradata\Documents\sparklearning\ratings-201019-002101.dat")
                                                                     ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.24 15:08:06 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad3.scala
scala.meta.tokenizers.TokenizeException: <input>:5: error: invalid escape character
    val base = sc.textFile("C:\\Users\\pp255070\\OneDrive - Teradata\\Documents\sparklearning\ratings-201019-002101.dat")
                                                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.24 15:08:08 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad3.scala
scala.meta.tokenizers.TokenizeException: <input>:21: error: invalid escape character
    val moviesrdd = sc.textFile("C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\movies-201019-002101.dat")
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.24 15:08:12 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad3.scala
scala.meta.tokenizers.TokenizeException: <input>:21: error: invalid escape character
    val moviesrdd = sc.textFile("C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\movies-201019-002101.dat")
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.24 15:08:27 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad3.scala
2023.11.24 15:36:34 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\example.scala
2023.11.24 15:36:38 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala
2023.11.24 15:36:41 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\example.scala
2023.11.24 15:45:00 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala
2023.11.24 16:10:00 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\example.scala
2023.11.24 16:10:06 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\Main.scala
2023.11.24 16:10:07 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\scalaproject\hello-world\src\main\scala\read.scala
2023.11.24 16:10:21 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala
2023.11.24 16:10:31 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala
2023.11.24 16:29:11 WARN  Using indexes to guess the definition of read
2023.11.24 21:27:30 INFO  Shutting down server
2023.11.24 21:27:30 INFO  shutting down Metals
2023.11.24 21:27:30 INFO  Exiting server
2023.11.27 16:22:37 INFO  Started: Metals version 1.1.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.84.2.
2023.11.27 16:22:38 WARN  Build server is not auto-connectable.
2023.11.27 16:22:38 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.11.27 16:22:38 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
2023.11.27 16:22:44 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.11.27 16:22:47 INFO  time: code lens generation in 9.69s
2023.11.27 16:29:54 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
2023.11.27 16:29:54 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/writeexample.scala
2023.11.27 16:29:55 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/writeexample.scala
2023.11.27 16:30:00 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\example.scala
2023.11.27 16:30:37 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala
2023.11.27 16:30:44 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/writeexample.scala
2023.11.27 16:32:16 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
scala.meta.tokenizers.TokenizeException: <input>:7: error: unclosed string interpolation
    sparkconf.set(spark.app.name")
                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 16:32:28 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
scala.meta.tokenizers.TokenizeException: <input>:7: error: unclosed string interpolation
    sparkconf.set("spark.app.name",""load")
                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Nov 27, 2023 4:35:48 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1028
Nov 27, 2023 4:36:20 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1103
Nov 27, 2023 4:39:10 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1354
Nov 27, 2023 4:39:49 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1403
2023.11.27 16:39:52 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
scala.meta.tokenizers.TokenizeException: <input>:14: error: invalid escape character
    ordersDf = spark.read.format("csv").option("path","C:\Users\pp255070\OneDrive - Teradata\Documents\Spark\data folder\week12").option("header",true).load()
                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 16:39:55 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
scala.meta.tokenizers.TokenizeException: <input>:14: error: invalid escape character
    ordersDf = spark.read.format("csv").option("path","C:\Users\pp255070\OneDrive - Teradata\Documents\Spark\data folder\week12\").option("header",true).load()
                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 16:39:56 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
scala.meta.tokenizers.TokenizeException: <input>:14: error: invalid escape character
    ordersDf = spark.read.format("csv").option("path","C:\Users\pp255070\OneDrive - Teradata\Documents\Spark\data folder\week12\\").option("header",true).load()
                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 16:40:14 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
scala.meta.tokenizers.TokenizeException: <input>:14: error: invalid escape character
    ordersDf = spark.read.format("csv").option("path","C:\Users\pp255070\OneDrive - Teradata\Documents\Spark\data folder\week12\\orders-201025-223502").option("header",true).load()
                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 16:40:28 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
scala.meta.tokenizers.TokenizeException: <input>:14: error: invalid escape character
    ordersDf = spark.read.format("csv").option("path","C:\Users\pp255070\OneDrive - Teradata\Documents\Spark\data folder\week12\\orders-201025-223502.c").option("header",true).load()
                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 16:40:29 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
scala.meta.tokenizers.TokenizeException: <input>:14: error: invalid escape character
    ordersDf = spark.read.format("csv").option("path","C:\Users\pp255070\OneDrive - Teradata\Documents\Spark\data folder\week12\\orders-201025-223502.csv").option("header",true).load()
                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 16:40:32 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
scala.meta.tokenizers.TokenizeException: <input>:14: error: invalid escape character
    ordersDf = spark.read.format("csv").option("path","C:\Users\pp255070\OneDrive - Teradata\Documents\Spark\data folder\\week12\\orders-201025-223502.csv").option("header",true).load()
                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 16:40:36 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
scala.meta.tokenizers.TokenizeException: <input>:14: error: invalid escape character
    ordersDf = spark.read.format("csv").option("path","C:\Users\pp255070\OneDrive - Teradata\Documents\Spark\\data folder\\week12\\orders-201025-223502.csv").option("header",true).load()
                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 16:40:39 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
scala.meta.tokenizers.TokenizeException: <input>:14: error: invalid escape character
    ordersDf = spark.read.format("csv").option("path","C:\Users\pp255070\OneDrive - Teradata\Documents\\Spark\\data folder\\week12\\orders-201025-223502.csv").option("header",true).load()
                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 16:40:41 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
scala.meta.tokenizers.TokenizeException: <input>:14: error: invalid escape character
    ordersDf = spark.read.format("csv").option("path","C:\Users\pp255070\OneDrive - Teradata\\Documents\\Spark\\data folder\\week12\\orders-201025-223502.csv").option("header",true).load()
                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 16:40:44 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
scala.meta.tokenizers.TokenizeException: <input>:14: error: invalid escape character
    ordersDf = spark.read.format("csv").option("path","C:\Users\pp255070\\OneDrive - Teradata\\Documents\\Spark\\data folder\\week12\\orders-201025-223502.csv").option("header",true).load()
                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 16:40:47 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
scala.meta.tokenizers.TokenizeException: <input>:14: error: invalid escape character
    ordersDf = spark.read.format("csv").option("path","C:\Users\\pp255070\\OneDrive - Teradata\\Documents\\Spark\\data folder\\week12\\orders-201025-223502.csv").option("header",true).load()
                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 16:41:20 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
2023.11.27 16:42:38 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
Nov 27, 2023 4:42:59 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1603
2023.11.27 16:43:34 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
Exception in thread "pool-3-thread-1" java.lang.InterruptedException
	at scala.meta.internal.metals.FutureCancelToken.checkCanceled(FutureCancelToken.scala:29)
	at scala.meta.internal.pc.CompilerAccess.onCompilerJobQueue$$anonfun$1(CompilerAccess.scala:230)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:152)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2023.11.27 16:44:34 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
2023.11.27 16:44:54 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
2023.11.27 17:10:48 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: unclosed string literal
    print("oordersdf.rdd.getNumPartitions())
          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 17:10:48 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: unclosed string literal
    print("ordeordersdf.rdd.getNumPartitions())
          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 17:10:49 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: unclosed string literal
    print("ordersordersdf.rdd.getNumPartitions())
          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 17:10:51 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: unclosed string literal
    print("ordersDfordersdf.rdd.getNumPartitions())
          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Nov 27, 2023 5:10:51 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2142
2023.11.27 17:10:51 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: unclosed string literal
    print("ordersDf hordersdf.rdd.getNumPartitions())
          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 17:10:52 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: unclosed string literal
    print("ordersDf hasordersdf.rdd.getNumPartitions())
          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 17:15:42 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
Nov 27, 2023 5:36:54 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2699
Nov 27, 2023 5:36:57 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2705
Nov 27, 2023 5:46:42 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2889
2023.11.27 17:47:20 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
Nov 27, 2023 5:51:13 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3196
Nov 27, 2023 5:51:19 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3225
2023.11.27 17:51:23 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
2023.11.27 20:21:13 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
2023.11.27 20:21:13 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/sparkSQL.scala
2023.11.27 20:21:13 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/sparkSQL.scala
2023.11.27 20:21:28 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/sparkSQL.scala
Nov 27, 2023 8:21:39 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3291
Nov 27, 2023 8:21:41 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3304
Nov 27, 2023 8:22:03 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3404
2023.11.27 20:22:38 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
scala.meta.tokenizers.TokenizeException: <input>:6: error: unclosed string interpolation
    sparkconf.set(spark.app.name")
                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Nov 27, 2023 8:23:09 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3689
2023.11.27 20:24:09 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
2023.11.27 20:24:09 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
Nov 27, 2023 8:25:40 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4154
Nov 27, 2023 8:29:21 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4399
2023.11.27 20:32:10 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
Nov 27, 2023 8:32:17 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4855
2023.11.27 21:34:37 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
scala.meta.tokenizers.TokenizeException: <input>:25: error: unclosed string interpolation
    val resultsdf = spark.sql(" select order_customer_id , count(*) as order_count from orders where order_status = "group by order_customer_id order by order_count")
                                                                                                                                                                     ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 21:34:38 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
scala.meta.tokenizers.TokenizeException: <input>:25: error: unclosed string interpolation
    val resultsdf = spark.sql(" select order_customer_id , count(*) as order_count from orders where order_status = "Cgroup by order_customer_id order by order_count")
                                                                                                                                                                      ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 21:55:33 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
2023.11.27 21:55:54 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
2023.11.27 21:55:54 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/sparkSqlTable.scala
2023.11.27 21:55:54 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/sparkSqlTable.scala
2023.11.27 21:56:10 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/sparkSqlTable.scala
Nov 27, 2023 9:56:39 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5408
Nov 27, 2023 9:57:57 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5614
2023.11.27 21:59:08 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
scala.meta.tokenizers.TokenizeException: <input>:28: error: unclosed string interpolation
    lect order_status , count(*) as status_count from orders group by order_status order by status_count")
                                                                                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 21:59:09 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
scala.meta.tokenizers.TokenizeException: <input>:28: error: unclosed string interpolation
    tus , count(*) as status_count from orders group by order_status order by status_count")
                                                                                           ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 21:59:09 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
scala.meta.tokenizers.TokenizeException: <input>:28: error: unclosed string interpolation
     as status_count from orders group by order_status order by status_count")
                                                                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 21:59:09 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
scala.meta.tokenizers.TokenizeException: <input>:28: error: unclosed string interpolation
    nt from orders group by order_status order by status_count")
                                                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 21:59:10 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
scala.meta.tokenizers.TokenizeException: <input>:28: error: unclosed string interpolation
     group by order_status order by status_count")
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 21:59:11 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
scala.meta.tokenizers.TokenizeException: <input>:28: error: unclosed string interpolation
    r_status order by status_count")
                                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 21:59:11 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
scala.meta.tokenizers.TokenizeException: <input>:28: error: unclosed string interpolation
    r by status_count")
                      ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 21:59:12 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
scala.meta.tokenizers.TokenizeException: <input>:28: error: unclosed string interpolation
    y status_count")
                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 21:59:13 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
scala.meta.tokenizers.TokenizeException: <input>:28: error: unclosed string interpolation
    tatus_count")
                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 21:59:13 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
scala.meta.tokenizers.TokenizeException: <input>:28: error: unclosed string interpolation
    us_count")
             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Nov 27, 2023 9:59:14 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5859
2023.11.27 21:59:14 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
scala.meta.tokenizers.TokenizeException: <input>:28: error: unclosed string interpolation
    count")
          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.27 21:59:14 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
scala.meta.tokenizers.TokenizeException: <input>:28: error: unclosed string interpolation
    nt")
       ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Nov 27, 2023 9:59:15 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: java.lang.StringIndexOutOfBoundsException: Range [851, 865) out of bounds for length 863
java.util.concurrent.CompletionException: java.lang.StringIndexOutOfBoundsException: Range [851, 865) out of bounds for length 863
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:708)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2194)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1(CancelTokens.scala:40)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1$adapted(CancelTokens.scala:38)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.lang.StringIndexOutOfBoundsException: Range [851, 865) out of bounds for length 863
	at java.base/jdk.internal.util.Preconditions$1.apply(Preconditions.java:55)
	at java.base/jdk.internal.util.Preconditions$1.apply(Preconditions.java:52)
	at java.base/jdk.internal.util.Preconditions$4.apply(Preconditions.java:213)
	at java.base/jdk.internal.util.Preconditions$4.apply(Preconditions.java:210)
	at java.base/jdk.internal.util.Preconditions.outOfBounds(Preconditions.java:98)
	at java.base/jdk.internal.util.Preconditions.outOfBoundsCheckFromToIndex(Preconditions.java:112)
	at java.base/jdk.internal.util.Preconditions.checkFromToIndex(Preconditions.java:349)
	at java.base/java.lang.String.checkBoundsBeginEnd(String.java:4861)
	at java.base/java.lang.String.substring(String.java:2830)
	at scala.meta.internal.metals.codeactions.FlatMapToForComprehensionCodeAction.getIndentForPos(FlatMapToForComprehensionCodeAction.scala:677)
	at scala.meta.internal.metals.codeactions.FlatMapToForComprehensionCodeAction.$anonfun$contribute$4(FlatMapToForComprehensionCodeAction.scala:57)
	at scala.Option.map(Option.scala:242)
	at scala.meta.internal.metals.codeactions.FlatMapToForComprehensionCodeAction.$anonfun$contribute$3(FlatMapToForComprehensionCodeAction.scala:53)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.codeactions.FlatMapToForComprehensionCodeAction.$anonfun$contribute$2(FlatMapToForComprehensionCodeAction.scala:52)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.codeactions.FlatMapToForComprehensionCodeAction.$anonfun$contribute$1(FlatMapToForComprehensionCodeAction.scala:51)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	... 3 more

Nov 27, 2023 9:59:15 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: java.lang.StringIndexOutOfBoundsException: Range [851, 865) out of bounds for length 862
java.util.concurrent.CompletionException: java.lang.StringIndexOutOfBoundsException: Range [851, 865) out of bounds for length 862
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:708)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2194)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1(CancelTokens.scala:40)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1$adapted(CancelTokens.scala:38)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.lang.StringIndexOutOfBoundsException: Range [851, 865) out of bounds for length 862
	at java.base/jdk.internal.util.Preconditions$1.apply(Preconditions.java:55)
	at java.base/jdk.internal.util.Preconditions$1.apply(Preconditions.java:52)
	at java.base/jdk.internal.util.Preconditions$4.apply(Preconditions.java:213)
	at java.base/jdk.internal.util.Preconditions$4.apply(Preconditions.java:210)
	at java.base/jdk.internal.util.Preconditions.outOfBounds(Preconditions.java:98)
	at java.base/jdk.internal.util.Preconditions.outOfBoundsCheckFromToIndex(Preconditions.java:112)
	at java.base/jdk.internal.util.Preconditions.checkFromToIndex(Preconditions.java:349)
	at java.base/java.lang.String.checkBoundsBeginEnd(String.java:4861)
	at java.base/java.lang.String.substring(String.java:2830)
	at scala.meta.internal.metals.codeactions.FlatMapToForComprehensionCodeAction.getIndentForPos(FlatMapToForComprehensionCodeAction.scala:677)
	at scala.meta.internal.metals.codeactions.FlatMapToForComprehensionCodeAction.$anonfun$contribute$4(FlatMapToForComprehensionCodeAction.scala:57)
	at scala.Option.map(Option.scala:242)
	at scala.meta.internal.metals.codeactions.FlatMapToForComprehensionCodeAction.$anonfun$contribute$3(FlatMapToForComprehensionCodeAction.scala:53)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.codeactions.FlatMapToForComprehensionCodeAction.$anonfun$contribute$2(FlatMapToForComprehensionCodeAction.scala:52)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.codeactions.FlatMapToForComprehensionCodeAction.$anonfun$contribute$1(FlatMapToForComprehensionCodeAction.scala:51)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	... 3 more

2023.11.27 21:59:15 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
scala.meta.tokenizers.TokenizeException: <input>:28: error: unclosed string literal
    ")
    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Nov 27, 2023 9:59:15 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: java.lang.StringIndexOutOfBoundsException: Range [851, 865) out of bounds for length 862
java.util.concurrent.CompletionException: java.lang.StringIndexOutOfBoundsException: Range [851, 865) out of bounds for length 862
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:708)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2194)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1(CancelTokens.scala:40)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1$adapted(CancelTokens.scala:38)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.lang.StringIndexOutOfBoundsException: Range [851, 865) out of bounds for length 862
	at java.base/jdk.internal.util.Preconditions$1.apply(Preconditions.java:55)
	at java.base/jdk.internal.util.Preconditions$1.apply(Preconditions.java:52)
	at java.base/jdk.internal.util.Preconditions$4.apply(Preconditions.java:213)
	at java.base/jdk.internal.util.Preconditions$4.apply(Preconditions.java:210)
	at java.base/jdk.internal.util.Preconditions.outOfBounds(Preconditions.java:98)
	at java.base/jdk.internal.util.Preconditions.outOfBoundsCheckFromToIndex(Preconditions.java:112)
	at java.base/jdk.internal.util.Preconditions.checkFromToIndex(Preconditions.java:349)
	at java.base/java.lang.String.checkBoundsBeginEnd(String.java:4861)
	at java.base/java.lang.String.substring(String.java:2830)
	at scala.meta.internal.metals.codeactions.FlatMapToForComprehensionCodeAction.getIndentForPos(FlatMapToForComprehensionCodeAction.scala:677)
	at scala.meta.internal.metals.codeactions.FlatMapToForComprehensionCodeAction.$anonfun$contribute$4(FlatMapToForComprehensionCodeAction.scala:57)
	at scala.Option.map(Option.scala:242)
	at scala.meta.internal.metals.codeactions.FlatMapToForComprehensionCodeAction.$anonfun$contribute$3(FlatMapToForComprehensionCodeAction.scala:53)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.codeactions.FlatMapToForComprehensionCodeAction.$anonfun$contribute$2(FlatMapToForComprehensionCodeAction.scala:52)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.codeactions.FlatMapToForComprehensionCodeAction.$anonfun$contribute$1(FlatMapToForComprehensionCodeAction.scala:51)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	... 3 more

Nov 27, 2023 9:59:15 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5868
Nov 27, 2023 9:59:16 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: java.lang.StringIndexOutOfBoundsException: Range [851, 865) out of bounds for length 861
java.util.concurrent.CompletionException: java.lang.StringIndexOutOfBoundsException: Range [851, 865) out of bounds for length 861
	at java.base/java.util.concurrent.CompletableFuture.encodeThrowable(CompletableFuture.java:332)
	at java.base/java.util.concurrent.CompletableFuture.completeThrowable(CompletableFuture.java:347)
	at java.base/java.util.concurrent.CompletableFuture$UniAccept.tryFire(CompletableFuture.java:708)
	at java.base/java.util.concurrent.CompletableFuture.postComplete(CompletableFuture.java:510)
	at java.base/java.util.concurrent.CompletableFuture.completeExceptionally(CompletableFuture.java:2194)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1(CancelTokens.scala:40)
	at scala.meta.internal.metals.CancelTokens$.$anonfun$future$1$adapted(CancelTokens.scala:38)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:484)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.lang.StringIndexOutOfBoundsException: Range [851, 865) out of bounds for length 861
	at java.base/jdk.internal.util.Preconditions$1.apply(Preconditions.java:55)
	at java.base/jdk.internal.util.Preconditions$1.apply(Preconditions.java:52)
	at java.base/jdk.internal.util.Preconditions$4.apply(Preconditions.java:213)
	at java.base/jdk.internal.util.Preconditions$4.apply(Preconditions.java:210)
	at java.base/jdk.internal.util.Preconditions.outOfBounds(Preconditions.java:98)
	at java.base/jdk.internal.util.Preconditions.outOfBoundsCheckFromToIndex(Preconditions.java:112)
	at java.base/jdk.internal.util.Preconditions.checkFromToIndex(Preconditions.java:349)
	at java.base/java.lang.String.checkBoundsBeginEnd(String.java:4861)
	at java.base/java.lang.String.substring(String.java:2830)
	at scala.meta.internal.metals.codeactions.FlatMapToForComprehensionCodeAction.getIndentForPos(FlatMapToForComprehensionCodeAction.scala:677)
	at scala.meta.internal.metals.codeactions.FlatMapToForComprehensionCodeAction.$anonfun$contribute$4(FlatMapToForComprehensionCodeAction.scala:57)
	at scala.Option.map(Option.scala:242)
	at scala.meta.internal.metals.codeactions.FlatMapToForComprehensionCodeAction.$anonfun$contribute$3(FlatMapToForComprehensionCodeAction.scala:53)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.codeactions.FlatMapToForComprehensionCodeAction.$anonfun$contribute$2(FlatMapToForComprehensionCodeAction.scala:52)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.codeactions.FlatMapToForComprehensionCodeAction.$anonfun$contribute$1(FlatMapToForComprehensionCodeAction.scala:51)
	at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:687)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	... 3 more

Nov 27, 2023 9:59:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2023-11-27\r_compiler-error_21-59-46-154.md
Nov 27, 2023 9:59:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2023-11-27\r_compiler-error_21-59-46-870.md
2023.11.27 22:00:37 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
scala.meta.tokenizers.TokenizeException: <input>:22: error: unclosed string literal
    spark.sql("create database if not exists import org.apache.spark.sql.SparkSession
              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Nov 27, 2023 10:00:43 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6065
2023.11.27 22:02:47 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
2023.11.27 22:03:01 INFO  Shutting down server
2023.11.27 22:03:01 INFO  shutting down Metals
2023.11.27 22:03:01 INFO  Exiting server
2023.11.28 12:19:04 INFO  Started: Metals version 1.1.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.84.2.
2023.11.28 12:19:06 WARN  Build server is not auto-connectable.
2023.11.28 12:19:06 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.11.28 12:19:07 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
2023.11.28 12:19:07 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
2023.11.28 12:19:07 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
2023.11.28 12:19:12 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.11.28 12:19:16 INFO  time: code lens generation in 9.82s
Nov 28, 2023 12:22:20 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 150
Nov 28, 2023 12:22:26 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 182
Nov 28, 2023 12:22:28 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 192
Nov 28, 2023 12:22:47 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 253
2023.11.28 12:25:05 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
scala.meta.tokenizers.TokenizeException: <input>:57: error: unclosed string interpolation
    bucketBy( 4 , order_customer_id").
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Nov 28, 2023 12:25:20 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 583
Nov 28, 2023 12:25:40 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 640
Nov 28, 2023 12:25:43 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 656
Nov 28, 2023 12:26:10 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 728
2023.11.28 12:26:31 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
2023.11.28 12:43:17 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
2023.11.28 12:43:51 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala
2023.11.28 12:44:23 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\example.scala
Nov 28, 2023 1:08:06 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 933
Nov 28, 2023 1:08:08 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 954
2023.11.28 13:08:21 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ([\t\n\r ] | "="):30:19, found "( x => x.o"
    orderDs.filter( x => x.order_id < 10)  // 
                  ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:22 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ([\t\n\r ] | "="):30:19, found "( x => x.o"
    orderDs.filter( x => x.order_id < 10)  // 
                  ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:23 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ([\t\n\r ] | "="):30:19, found "( x => x.o"
    orderDs.filter( x => x.order_id < 10)  // 
                  ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:24 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ([\t\n\r ] | "="):30:19, found "( x => x.o"
    orderDs.filter( x => x.order_id < 10)  // 
                  ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:24 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ([\t\n\r ] | "="):30:19, found "( x => x.o"
    orderDs.filter( x => x.order_id < 10)  // 
                  ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:25 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ([\t\n\r ] | "="):30:19, found "( x => x.o"
    orderDs.filter( x => x.order_id < 10)  // 
                  ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:29 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ("{{" | "}}" | "&" | "&#" | "&#x" | "{" | "<xml:unparsed" | "<![CDATA[" | "<?" | "<!--" | "</"):30:37, found "< 10)  // "
    orderDs.filter( x => x.order_id < 10)  // 
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:30 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ("{{" | "}}" | "&" | "&#" | "&#x" | "{" | "<xml:unparsed" | "<![CDATA[" | "<?" | "<!--" | "</"):30:37, found "< 10)  // "
    orderDs.filter( x => x.order_id < 10)  // 
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:30 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ("{{" | "}}" | "&" | "&#" | "&#x" | "{" | "<xml:unparsed" | "<![CDATA[" | "<?" | "<!--" | "</"):30:37, found "< 10)  // "
    orderDs.filter( x => x.order_id < 10)  // 
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:33 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ("{{" | "}}" | "&" | "&#" | "&#x" | "{" | "<xml:unparsed" | "<![CDATA[" | "<?" | "<!--" | "</"):30:37, found "< 10)  // "
    orderDs.filter( x => x.order_id < 10)  // 
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:42 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ("{{" | "}}" | "&" | "&#" | "&#x" | "{" | "<xml:unparsed" | "<![CDATA[" | "<?" | "<!--" | "</"):30:37, found "< 10)  // "
    orderDs.filter( x => x.order_id < 10)  // 
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:42 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ("{{" | "}}" | "&" | "&#" | "&#x" | "{" | "<xml:unparsed" | "<![CDATA[" | "<?" | "<!--" | "</"):30:37, found "< 10)  // "
    orderDs.filter( x => x.order_id < 10)  // 
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:44 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ("{{" | "}}" | "&" | "&#" | "&#x" | "{" | "<xml:unparsed" | "<![CDATA[" | "<?" | "<!--" | "</"):30:37, found "< 10)  // "
    orderDs.filter( x => x.order_id < 10)  // 
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:44 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ("{{" | "}}" | "&" | "&#" | "&#x" | "{" | "<xml:unparsed" | "<![CDATA[" | "<?" | "<!--" | "</"):30:37, found "< 10)  // "
    orderDs.filter( x => x.order_id < 10)  // 
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:45 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ("{{" | "}}" | "&" | "&#" | "&#x" | "{" | "<xml:unparsed" | "<![CDATA[" | "<?" | "<!--" | "</"):30:37, found "< 10)  // "
    orderDs.filter( x => x.order_id < 10)  // 
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:45 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ("{{" | "}}" | "&" | "&#" | "&#x" | "{" | "<xml:unparsed" | "<![CDATA[" | "<?" | "<!--" | "</"):30:37, found "< 10)  // "
    orderDs.filter( x => x.order_id < 10)  // 
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:46 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ("{{" | "}}" | "&" | "&#" | "&#x" | "{" | "<xml:unparsed" | "<![CDATA[" | "<?" | "<!--" | "</"):30:37, found "< 10)  // "
    orderDs.filter( x => x.order_id < 10)  // 
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:47 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ("{{" | "}}" | "&" | "&#" | "&#x" | "{" | "<xml:unparsed" | "<![CDATA[" | "<?" | "<!--" | "</"):30:37, found "< 10)  // "
    orderDs.filter( x => x.order_id < 10)  // 
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:47 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ("{{" | "}}" | "&" | "&#" | "&#x" | "{" | "<xml:unparsed" | "<![CDATA[" | "<?" | "<!--" | "</"):30:37, found "< 10)  // "
    orderDs.filter( x => x.order_id < 10)  // 
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:48 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ("{{" | "}}" | "&" | "&#" | "&#x" | "{" | "<xml:unparsed" | "<![CDATA[" | "<?" | "<!--" | "</"):30:37, found "< 10)  // "
    orderDs.filter( x => x.order_id < 10)  // 
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:48 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ("{{" | "}}" | "&" | "&#" | "&#x" | "{" | "<xml:unparsed" | "<![CDATA[" | "<?" | "<!--" | "</"):30:37, found "< 10)  // "
    orderDs.filter( x => x.order_id < 10)  // 
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:49 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ("{{" | "}}" | "&" | "&#" | "&#x" | "{" | "<xml:unparsed" | "<![CDATA[" | "<?" | "<!--" | "</"):30:37, found "< 10)  // "
    orderDs.filter( x => x.order_id < 10)  // 
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:50 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ("{{" | "}}" | "&" | "&#" | "&#x" | "{" | "<xml:unparsed" | "<![CDATA[" | "<?" | "<!--" | "</"):30:37, found "< 10)  // "
    orderDs.filter( x => x.order_id < 10)  // 
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:51 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ("{{" | "}}" | "&" | "&#" | "&#x" | "{" | "<xml:unparsed" | "<![CDATA[" | "<?" | "<!--" | "</"):30:37, found "< 10)  // "
    orderDs.filter( x => x.order_id < 10)  // 
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:51 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ("{{" | "}}" | "&" | "&#" | "&#x" | "{" | "<xml:unparsed" | "<![CDATA[" | "<?" | "<!--" | "</"):30:37, found "< 10)  // "
    orderDs.filter( x => x.order_id < 10)  // 
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:52 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ("{{" | "}}" | "&" | "&#" | "&#x" | "{" | "<xml:unparsed" | "<![CDATA[" | "<?" | "<!--" | "</"):30:37, found "< 10)  // "
    orderDs.filter( x => x.order_id < 10)  // 
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:52 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ("{{" | "}}" | "&" | "&#" | "&#x" | "{" | "<xml:unparsed" | "<![CDATA[" | "<?" | "<!--" | "</"):30:37, found "< 10)  // "
    orderDs.filter( x => x.order_id < 10)  // 
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:53 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ("{{" | "}}" | "&" | "&#" | "&#x" | "{" | "<xml:unparsed" | "<![CDATA[" | "<?" | "<!--" | "</"):30:37, found "< 10)  // "
    orderDs.filter( x => x.order_id < 10)  // 
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:54 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ("{{" | "}}" | "&" | "&#" | "&#x" | "{" | "<xml:unparsed" | "<![CDATA[" | "<?" | "<!--" | "</"):30:37, found "< 10)  // "
    orderDs.filter( x => x.order_id < 10)  // 
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:08:59 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
2023.11.28 13:08:59 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
scala.meta.tokenizers.TokenizeException: <input>:30: error: malformed xml literal, expected:
Expected ("{{" | "}}" | "&" | "&#" | "&#x" | "{" | "<xml:unparsed" | "<![CDATA[" | "<?" | "<!--" | "</"):30:37, found "< 10)  // "
    orderDs.filter( x => x.order_id < 10)  // 
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getXml(LegacyScanner.scala:937)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchLT$1(LegacyScanner.scala:295)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:303)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 13:09:17 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
2023.11.28 13:10:28 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1.scala
2023.11.28 13:10:28 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/adv1.scala
2023.11.28 13:10:28 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/adv1.scala
2023.11.28 13:10:50 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/adv1.scala
Nov 28, 2023 1:11:47 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1294
Nov 28, 2023 1:12:11 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1368
Nov 28, 2023 1:13:17 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1507
Nov 28, 2023 1:16:25 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2007
Nov 28, 2023 1:18:54 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2372
2023.11.28 13:19:22 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1.scala
Nov 28, 2023 1:19:31 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2476
Nov 28, 2023 1:19:40 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2504
2023.11.28 13:22:40 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
2023.11.28 13:22:46 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1.scala
Nov 28, 2023 1:26:14 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2969
2023.11.28 13:28:16 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1.scala
2023.11.28 13:31:17 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1.scala
2023.11.28 13:35:37 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1.scala
2023.11.28 14:49:38 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2023.11.28 14:49:38 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/columnDfandDS.scala
2023.11.28 14:49:39 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/columnDfandDS.scala
2023.11.28 14:49:56 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
2023.11.28 14:50:00 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/columnDfandDS.scala
2023.11.28 14:55:25 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2023.11.28 15:01:12 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
scala.meta.tokenizers.TokenizeException: <input>:25: error: unclosed character literal
    ordersDf.select(col("object_id"), column("order_status"),$"order_date",'').show()    
                                                                           ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 15:01:13 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
scala.meta.tokenizers.TokenizeException: <input>:25: error: unclosed character literal
    ordersDf.select(col("object_id"), column("order_status"),$"order_date",'or').show()    
                                                                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 15:01:13 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
scala.meta.tokenizers.TokenizeException: <input>:25: error: unclosed character literal
    ordersDf.select(col("object_id"), column("order_status"),$"order_date",'ordr').show()    
                                                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 15:01:14 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
scala.meta.tokenizers.TokenizeException: <input>:25: error: unclosed character literal
    ordersDf.select(col("object_id"), column("order_status"),$"order_date",'ordr_c').show()    
                                                                                  ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 15:01:15 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
scala.meta.tokenizers.TokenizeException: <input>:25: error: unclosed character literal
    ordersDf.select(col("object_id"), column("order_status"),$"order_date",'ordr_cu').show()    
                                                                                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 15:01:16 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
scala.meta.tokenizers.TokenizeException: <input>:25: error: unclosed character literal
    ordersDf.select(col("object_id"), column("order_status"),$"order_date",'ordr_cutom').show()    
                                                                                      ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 15:01:17 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
scala.meta.tokenizers.TokenizeException: <input>:25: error: unclosed character literal
    ordersDf.select(col("object_id"), column("order_status"),$"order_date",'ordr_cutomer').show()    
                                                                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 15:01:17 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
scala.meta.tokenizers.TokenizeException: <input>:25: error: unclosed character literal
    ordersDf.select(col("object_id"), column("order_status"),$"order_date",'ordr_cutomer_i').show()    
                                                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 15:01:18 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
scala.meta.tokenizers.TokenizeException: <input>:25: error: unclosed character literal
    ordersDf.select(col("object_id"), column("order_status"),$"order_date",'ordr_cutomer_id').show()    
                                                                                           ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 15:01:22 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
scala.meta.tokenizers.TokenizeException: <input>:25: error: unclosed character literal
    ordersDf.select(col("object_id"), column("order_status"),$"order_date",'order_cutomer_id').show()    
                                                                                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Nov 28, 2023 3:01:59 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4396
Nov 28, 2023 3:02:16 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4451
2023.11.28 15:02:21 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2023.11.28 15:03:38 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2023.11.28 15:16:11 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
scala.meta.tokenizers.TokenizeException: <input>:29: error: unclosed string interpolation
    ordersDf.select(col("order_id"), column("order_status"), $"orde).show()
                                                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 15:16:12 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
scala.meta.tokenizers.TokenizeException: <input>:29: error: unclosed string interpolation
    ordersDf.select(col("order_id"), column("order_status"), $"or).show()
                                                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 15:16:13 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
scala.meta.tokenizers.TokenizeException: <input>:29: error: unclosed string interpolation
    ordersDf.select(col("order_id"), column("order_status"), $").show()
                                                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 15:16:44 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
scala.meta.tokenizers.TokenizeException: <input>:29: error: unclosed string interpolation
    ordersDf.select(col("order_id"), expr(concat"("order_status")).show()
                                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 15:16:52 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
scala.meta.tokenizers.TokenizeException: <input>:29: error: unclosed string interpolation
    ordersDf.select(col("order_id"), expr(concat"(order_status)).show()
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 15:16:57 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
scala.meta.tokenizers.TokenizeException: <input>:29: error: unclosed string interpolation
    ordersDf.select(col("order_id"), expr(concat"(order_status,)).show()
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 15:17:00 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
scala.meta.tokenizers.TokenizeException: <input>:29: error: unclosed string interpolation
    ordersDf.select(col("order_id"), expr(concat"(order_status,'')).show()
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 15:17:02 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
scala.meta.tokenizers.TokenizeException: <input>:29: error: unclosed string interpolation
    ordersDf.select(col("order_id"), expr(concat"(order_status,'_S')).show()
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 15:17:02 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
scala.meta.tokenizers.TokenizeException: <input>:29: error: unclosed string interpolation
    ordersDf.select(col("order_id"), expr(concat"(order_status,'_STAT')).show()
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 15:17:03 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
scala.meta.tokenizers.TokenizeException: <input>:29: error: unclosed string interpolation
    ordersDf.select(col("order_id"), expr(concat"(order_status,'_STATUS')).show()
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 15:17:06 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
scala.meta.tokenizers.TokenizeException: <input>:29: error: unclosed string literal
    ordersDf.select(col("order_id"), expr(concat"(order_status,'_STATUS')"").show()
                                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 15:19:49 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
scala.meta.tokenizers.TokenizeException: <input>:29: error: unclosed character literal
    ordersDf.select(col("order_id"), expr("concat"(order_status,'_STATUS')")).show()
                                                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 15:19:54 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
scala.meta.tokenizers.TokenizeException: <input>:29: error: unclosed string literal
    ordersDf.select(col("order_id"), expr("concat(order_status,'_STATUS'))).show()
                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 15:19:56 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
scala.meta.tokenizers.TokenizeException: <input>:29: error: unclosed string literal
    ordersDf.select(col("order_id"), expr("concat(order_status,'_STATUS'))"").show()
                                                                           ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Nov 28, 2023 3:23:22 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5045
2023.11.28 15:25:46 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2023.11.28 15:44:03 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2023.11.28 15:44:23 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\colExpr.scala
2023.11.28 15:44:23 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/colExpr.scala
2023.11.28 15:44:24 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/colExpr.scala
2023.11.28 15:44:32 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/colExpr.scala
Nov 28, 2023 3:46:15 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5693
2023.11.28 15:53:04 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
2023.11.28 15:53:50 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
2023.11.28 15:55:18 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
Nov 28, 2023 4:09:12 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6809
Nov 28, 2023 4:09:19 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6825
Nov 28, 2023 4:09:23 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6840
2023.11.28 16:10:22 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
Nov 28, 2023 4:11:12 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 7000
2023.11.28 16:13:04 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
Nov 28, 2023 4:17:05 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 7394
2023.11.28 16:17:24 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
2023.11.28 16:17:26 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
2023.11.28 16:17:56 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
Nov 28, 2023 4:42:56 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 7682
Nov 28, 2023 4:43:14 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 7700
Nov 28, 2023 4:44:47 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 7792
2023.11.28 16:45:56 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
2023.11.28 16:47:40 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
scala.meta.tokenizers.TokenizeException: <input>:36: error: unclosed string literal
    val df3 = df.withColumn("adult", expr("parseagefunc(col(age))))
                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 16:47:44 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
scala.meta.tokenizers.TokenizeException: <input>:36: error: unclosed string literal
    val df3 = df.withColumn("adult", expr("parseagefunc(c(age))))
                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 16:47:45 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
scala.meta.tokenizers.TokenizeException: <input>:36: error: unclosed string literal
    val df3 = df.withColumn("adult", expr("parseagefunc(age))))
                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 16:47:48 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
scala.meta.tokenizers.TokenizeException: <input>:36: error: unclosed string literal
    val df3 = df.withColumn("adult", expr("parseagefunc(age)))
                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 16:47:51 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
scala.meta.tokenizers.TokenizeException: <input>:36: error: unclosed string literal
    val df3 = df.withColumn("adult", expr("parseagefunc(age)""))
                                                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.28 16:48:52 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
2023.11.28 16:51:50 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
Nov 28, 2023 4:58:41 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8564
Nov 28, 2023 4:59:01 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8632
Exception in thread "pool-3-thread-1" java.lang.InterruptedException
	at scala.meta.internal.metals.FutureCancelToken.checkCanceled(FutureCancelToken.scala:29)
	at scala.meta.internal.pc.CompilerAccess.onCompilerJobQueue$$anonfun$1(CompilerAccess.scala:230)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:152)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2023.11.28 17:01:52 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
Nov 28, 2023 5:02:05 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8846
Nov 28, 2023 5:03:30 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 9160
Nov 28, 2023 5:04:34 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 9378
2023.11.28 17:07:19 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
2023.11.28 17:08:46 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
2023.11.28 21:30:55 INFO  Shutting down server
2023.11.28 21:30:55 INFO  shutting down Metals
2023.11.28 21:30:55 INFO  Exiting server
2023.11.29 13:45:01 INFO  Started: Metals version 1.1.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.84.2.
2023.11.29 13:45:02 WARN  Build server is not auto-connectable.
2023.11.29 13:45:02 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.11.29 13:45:02 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1.scala
2023.11.29 13:45:05 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.11.29 13:45:07 INFO  time: code lens generation in 4.96s
2023.11.29 19:43:21 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
2023.11.29 19:43:21 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\OneDrive - Teradata\Documents\sample.txt")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.29 19:43:22 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\OneDrive - Teradata\Documents\sample.txt")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.29 21:13:22 INFO  Shutting down server
2023.11.29 21:13:22 INFO  shutting down Metals
2023.11.29 21:13:22 INFO  Exiting server
2023.11.30 14:17:24 INFO  Started: Metals version 1.1.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.84.2.
2023.11.30 14:17:25 WARN  Build server is not auto-connectable.
2023.11.30 14:17:25 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.11.30 14:17:25 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10.scala
2023.11.30 14:17:28 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.11.30 14:17:28 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
2023.11.30 14:17:29 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week9.scala
2023.11.30 14:17:29 INFO  time: code lens generation in 4.01s
2023.11.30 14:17:29 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week9.scala
2023.11.30 14:17:34 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1.scala
2023.11.30 14:17:36 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week9.scala
2023.11.30 14:17:42 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\broadcast.scala
Nov 30, 2023 2:17:46 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 32
2023.11.30 14:17:54 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week9.scala
2023.11.30 14:19:05 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
scala.meta.tokenizers.TokenizeException: <input>:7: error: unclosed string interpolation
    val sc = new SparkContext("local[*],"temp")
                                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 14:19:09 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
scala.meta.tokenizers.TokenizeException: <input>:7: error: unclosed string interpolation
    val sc = new SparkContext("local[*]"","temp")
                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Nov 30, 2023 2:21:25 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 580
2023.11.30 14:22:37 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
2023.11.30 14:24:12 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2023.11.30 14:25:09 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week9.scala
2023.11.30 14:26:10 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
2023.11.30 14:26:16 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
2023.11.30 14:26:20 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
2023.11.30 14:26:33 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
2023.11.30 14:26:39 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
2023.11.30 14:26:49 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
2023.11.30 14:26:55 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala
Nov 30, 2023 2:27:06 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1009
Nov 30, 2023 2:27:36 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1039
Nov 30, 2023 2:28:33 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1114
2023.11.30 14:28:57 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
scala.meta.tokenizers.TokenizeException: <input>:13: error: unclosed string literal
    val temp = "stationId, timeOfTheReading, readingType, 
               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 14:31:42 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
scala.meta.tokenizers.TokenizeException: <input>:18: error: unclosed string literal
                schema(")
                       ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 14:31:43 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
scala.meta.tokenizers.TokenizeException: <input>:18: error: unclosed string interpolation
                schema(te")
                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 14:31:43 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
scala.meta.tokenizers.TokenizeException: <input>:18: error: unclosed string interpolation
                schema(temp")
                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 14:32:57 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: invalid escape character
                option("path" , "c:\Users\pp255070\OneDrive - Teradata\Documents\Spark\assignment\week9").
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 14:33:00 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: invalid escape character
                option("path" , "c:\Users\pp255070\OneDrive - Teradata\Documents\Spark\assignment\week9\\").
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 14:33:03 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: invalid escape character
                option("path" , "c:Users\pp255070\OneDrive - Teradata\Documents\Spark\assignment\week9\\").
                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 14:33:04 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: invalid escape character
                option("path" , "c:\Users\pp255070\OneDrive - Teradata\Documents\Spark\assignment\week9\\").
                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 14:33:08 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: invalid escape character
                option("path" , "c:\\Users\pp255070\OneDrive - Teradata\Documents\Spark\assignment\week9\\").
                                           ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 14:33:11 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: invalid escape character
                option("path" , "c:\\Users\\pp255070\OneDrive - Teradata\Documents\Spark\assignment\week9\\").
                                                     ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 14:33:14 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: invalid escape character
                option("path" , "c:\\Users\\pp255070\\OneDrive - Teradata\Documents\Spark\assignment\week9\\").
                                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 14:33:17 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: invalid escape character
                option("path" , "c:\\Users\\pp255070\\OneDrive - Teradata\\Documents\Spark\assignment\week9\\").
                                                                                     ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 14:33:20 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: invalid escape character
                option("path" , "c:\\Users\\pp255070\\OneDrive - Teradata\\Documents\\Spark\assignment\week9\\").
                                                                                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 14:33:23 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: invalid escape character
                option("path" , "c:\\Users\\pp255070\\OneDrive - Teradata\\Documents\\Spark\\assignment\week9\\").
                                                                                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 14:33:55 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
2023.11.30 14:35:31 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: invalid escape character
                option("path" , "c:\\Users\\pp255070\\OneDrive - Teradata\\Documents\\Spark\\assignment\week9\\").
                                                                                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 14:35:31 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: invalid escape character
                option("path" , "c:\\Users\\pp255070\\OneDrive - Teradata\Documents\Spark\assignment\week9\\").
                                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 14:35:32 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: invalid escape character
                option("path" , "c:\\Users\\pp255070\OneDrive - Teradata\Documents\Spark\assignment\week9\\").
                                                     ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Nov 30, 2023 2:36:07 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1826
Nov 30, 2023 2:37:23 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2017
2023.11.30 14:38:53 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
2023.11.30 14:38:56 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\broadcast.scala
2023.11.30 14:39:04 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
Nov 30, 2023 2:39:04 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2338
Nov 30, 2023 2:39:08 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2346
Nov 30, 2023 2:39:29 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2362
2023.11.30 14:39:34 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
2023.11.30 14:41:26 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
Nov 30, 2023 2:41:26 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2401
2023.11.30 14:41:32 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala
2023.11.30 14:41:39 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
2023.11.30 14:41:39 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 14:41:40 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 14:41:42 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad1.scala
2023.11.30 14:41:45 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\ratings.scala
2023.11.30 14:41:48 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\filter.scala
2023.11.30 14:41:50 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\linkedin.scala
2023.11.30 14:41:54 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\customer.scala
2023.11.30 14:41:54 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\customer.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 14:41:54 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\customer.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 14:42:00 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
2023.11.30 14:42:00 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\OneDrive - Teradata\Documents\sample.txt")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 14:42:00 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\OneDrive - Teradata\Documents\sample.txt")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 14:42:04 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala
2023.11.30 14:42:07 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad3.scala
2023.11.30 14:47:26 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
2023.11.30 14:47:30 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
Nov 30, 2023 2:47:30 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2553
Nov 30, 2023 2:47:40 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2561
Nov 30, 2023 2:48:00 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2649
2023.11.30 14:50:11 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
scala.meta.tokenizers.TokenizeException: <input>:24: error: unclosed string literal
    val minTemp = spark.sql("select import org.apache.spark.sql.SparkSession
                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 15:01:51 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week9.scala
2023.11.30 15:07:09 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10.scala
2023.11.30 15:07:09 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week10.scala
2023.11.30 15:07:09 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week10.scala
2023.11.30 15:07:32 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
2023.11.30 15:07:32 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\OneDrive - Teradata\Documents\sample.txt")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 15:07:32 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\OneDrive - Teradata\Documents\sample.txt")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 15:07:37 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\broadcast.scala
2023.11.30 15:07:48 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week10.scala
Nov 30, 2023 3:08:07 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3372
Nov 30, 2023 3:08:08 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3383
error while checking new SparkContext(null: <notype>)
error while checking val sc = new SparkContext(null: <notype>)
error while checking  extends App {
  val sc = new SparkContext(null: <notype>)
}
error while checking module object week10 extends App {
  val sc = new SparkContext(null: <notype>)
}
error while checking package <empty> {
  import org.apache.spark.SparkContext
  import org.apache.log4j.logger
  import org.apache.log4j.level
  module object week10 extends App {
    val sc = new SparkContext(null: <notype>)
  }
}
Nov 30, 2023 3:08:24 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2023-11-30\r_compiler-error_15-08-24-242.md
2023.11.30 15:08:24 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week10.scala
error while checking new SparkContext(null: <notype>)
error while checking val sc = new SparkContext(null: <notype>)
error while checking  extends App {
  val sc = new SparkContext(null: <notype>)
}
error while checking module object week10 extends App {
  val sc = new SparkContext(null: <notype>)
}
error while checking package <empty> {
  import org.apache.spark.SparkContext
  import org.apache.log4j.logger
  import org.apache.log4j.level
  module object week10 extends App {
    val sc = new SparkContext(null: <notype>)
  }
}
Nov 30, 2023 3:08:24 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2023-11-30\r_compiler-error_15-08-24-696.md
error while checking new SparkContext(null: <notype>)
error while checking val sc = new SparkContext(null: <notype>)
error while checking  extends App {
  val sc = new SparkContext(null: <notype>)
}
error while checking module object week10 extends App {
  val sc = new SparkContext(null: <notype>)
}
error while checking package <empty> {
  import org.apache.spark.SparkContext
  import org.apache.log4j.logger
  import org.apache.log4j.level
  module object week10 extends App {
    val sc = new SparkContext(null: <notype>)
  }
}
Nov 30, 2023 3:08:24 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2023-11-30\r_compiler-error_15-08-24-749.md
2023.11.30 15:08:24 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week10.scala
2023.11.30 15:08:25 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10.scala
scala.meta.tokenizers.TokenizeException: <input>:9: error: unclosed string literal
    val sc = new SparkContext("loacl[*]"")
                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

error while checking new SparkContext("loacl[*]", null)
error while checking val sc = new SparkContext("loacl[*]", null)
error while checking  extends App {
  val sc = new SparkContext("loacl[*]", null)
}
error while checking module object week10 extends App {
  val sc = new SparkContext("loacl[*]", null)
}
error while checking package <empty> {
  import org.apache.spark.SparkContext
  import org.apache.log4j.logger
  import org.apache.log4j.level
  module object week10 extends App {
    val sc = new SparkContext("loacl[*]", null)
  }
}
Nov 30, 2023 3:08:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2023-11-30\r_compiler-error_15-08-28-039.md
error while checking new SparkContext("loacl[*]", null)
error while checking val sc = new SparkContext("loacl[*]", null)
error while checking  extends App {
  val sc = new SparkContext("loacl[*]", null)
}
error while checking module object week10 extends App {
  val sc = new SparkContext("loacl[*]", null)
}
error while checking package <empty> {
  import org.apache.spark.SparkContext
  import org.apache.log4j.logger
  import org.apache.log4j.level
  module object week10 extends App {
    val sc = new SparkContext("loacl[*]", null)
  }
}
Nov 30, 2023 3:08:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2023-11-30\r_compiler-error_15-08-28-297.md
error while checking new SparkContext("loacl[*]", null)
error while checking val sc = new SparkContext("loacl[*]", null)
error while checking  extends App {
  val sc = new SparkContext("loacl[*]", null)
}
error while checking module object week10 extends App {
  val sc = new SparkContext("loacl[*]", null)
}
error while checking package <empty> {
  import org.apache.spark.SparkContext
  import org.apache.log4j.logger
  import org.apache.log4j.level
  module object week10 extends App {
    val sc = new SparkContext("loacl[*]", null)
  }
}
Nov 30, 2023 3:08:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2023-11-30\r_compiler-error_15-08-28-360.md
2023.11.30 15:08:28 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week10.scala
error while checking new SparkContext("loacl[*]", null)
error while checking val sc = new SparkContext("loacl[*]", null)
error while checking  extends App {
  val sc = new SparkContext("loacl[*]", null)
}
error while checking module object week10 extends App {
  val sc = new SparkContext("loacl[*]", null)
}
error while checking package <empty> {
  import org.apache.spark.SparkContext
  import org.apache.log4j.logger
  import org.apache.log4j.level
  module object week10 extends App {
    val sc = new SparkContext("loacl[*]", null)
  }
}
Nov 30, 2023 3:08:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2023-11-30\r_compiler-error_15-08-32-482.md
error while checking new SparkContext("loacl[*]", null)
error while checking val sc = new SparkContext("loacl[*]", null)
error while checking  extends App {
  val sc = new SparkContext("loacl[*]", null)
}
error while checking module object week10 extends App {
  val sc = new SparkContext("loacl[*]", null)
}
error while checking package <empty> {
  import org.apache.spark.SparkContext
  import org.apache.log4j.logger
  import org.apache.log4j.level
  module object week10 extends App {
    val sc = new SparkContext("loacl[*]", null)
  }
}
Nov 30, 2023 3:08:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2023-11-30\r_compiler-error_15-08-32-551.md
2023.11.30 15:08:32 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week10.scala
2023.11.30 15:08:33 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10.scala
scala.meta.tokenizers.TokenizeException: <input>:9: error: unclosed multi-line string literal
    val sc = new SparkContext("loacl[*]",""")
                                         ^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getRawStringLit(LegacyScanner.scala:567)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:366)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 15:15:38 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\linkedin.scala
Nov 30, 2023 3:15:47 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4337
2023.11.30 15:18:43 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10.scala
scala.meta.tokenizers.TokenizeException: <input>:11: error: invalid escape character
    val raw = sc.textFile("c:\Users\pp255070\OneDrive - Teradata\Documents\Spark\assignment\week10")
                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 15:18:46 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10.scala
scala.meta.tokenizers.TokenizeException: <input>:11: error: invalid escape character
    val raw = sc.textFile("c:\\Users\pp255070\OneDrive - Teradata\Documents\Spark\assignment\week10")
                                     ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 15:18:48 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10.scala
scala.meta.tokenizers.TokenizeException: <input>:11: error: invalid escape character
    val raw = sc.textFile("c:\\Users\\pp255070\OneDrive - Teradata\Documents\Spark\assignment\week10")
                                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 15:18:51 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10.scala
scala.meta.tokenizers.TokenizeException: <input>:11: error: invalid escape character
    val raw = sc.textFile("c:\\Users\\pp255070\\OneDrive - Teradata\Documents\Spark\assignment\week10")
                                                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 15:18:55 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10.scala
scala.meta.tokenizers.TokenizeException: <input>:11: error: invalid escape character
    val raw = sc.textFile("c:\\Users\\pp255070\\OneDrive - Teradata\\Documents\Spark\assignment\week10")
                                                                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 15:18:57 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10.scala
scala.meta.tokenizers.TokenizeException: <input>:11: error: invalid escape character
    val raw = sc.textFile("c:\\Users\\pp255070\\OneDrive - Teradata\\Documents\\Spark\assignment\week10")
                                                                                      ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 15:18:59 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10.scala
scala.meta.tokenizers.TokenizeException: <input>:11: error: invalid escape character
    val raw = sc.textFile("c:\\Users\\pp255070\\OneDrive - Teradata\\Documents\\Spark\\assignment\week10")
                                                                                                  ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 15:19:21 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10.scala
2023.11.30 15:25:07 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\filter.scala
2023.11.30 15:25:13 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\customer.scala
2023.11.30 15:25:13 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\customer.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 15:25:14 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\customer.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 15:25:17 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\broadcast.scala
2023.11.30 15:25:23 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
2023.11.30 15:25:23 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\OneDrive - Teradata\Documents\sample.txt")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 15:25:23 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\OneDrive - Teradata\Documents\sample.txt")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 15:25:26 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad1.scala
2023.11.30 15:25:31 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
2023.11.30 15:25:31 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 15:25:32 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 15:25:38 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad3.scala
Nov 30, 2023 3:25:38 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4863
2023.11.30 15:25:54 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala
2023.11.30 15:26:16 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
2023.11.30 15:26:16 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 15:26:16 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 15:28:04 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10.scala
2023.11.30 15:28:04 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10.scala
Nov 30, 2023 3:29:19 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5150
Nov 30, 2023 3:29:23 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5166
2023.11.30 15:32:09 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10.scala
2023.11.30 15:32:17 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_1.scala
2023.11.30 15:32:21 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 15:32:46 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_1.scala
2023.11.30 15:45:07 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_2.scala
2023.11.30 15:45:07 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week10_2.scala
2023.11.30 15:45:07 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week10_2.scala
2023.11.30 15:45:26 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week10_2.scala
2023.11.30 15:45:44 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_1.scala
2023.11.30 15:45:52 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_2.scala
2023.11.30 15:46:47 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
2023.11.30 15:46:47 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 15:46:47 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.11.30 15:46:51 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad3.scala
2023.11.30 15:47:06 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad3_join.scala
2023.11.30 16:04:11 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad3_join.scala
2023.11.30 16:04:35 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_2.scala
2023.11.30 16:05:20 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_2.scala
2023.11.30 16:05:41 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_2.scala
2023.11.30 16:05:41 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_2.scala
2023.11.30 16:12:25 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad3_join.scala
2023.11.30 16:13:24 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_2.scala
2023.11.30 16:17:06 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_2.scala
2023.11.30 16:17:13 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_2.scala
Nov 30, 2023 4:20:10 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6628
Nov 30, 2023 4:21:38 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6747
Nov 30, 2023 4:21:54 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6798
Nov 30, 2023 4:30:41 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6844
2023.11.30 16:32:55 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_1.scala
2023.11.30 16:35:06 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_1.scala
Nov 30, 2023 4:36:34 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 7582
Nov 30, 2023 4:36:36 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 7593
2023.11.30 16:37:19 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_2.scala
Nov 30, 2023 4:38:34 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 7877
2023.11.30 16:39:29 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_2.scala
2023.11.30 16:40:21 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_2.scala
2023.11.30 16:40:41 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_2.scala
2023.11.30 16:41:05 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_2.scala
2023.11.30 16:41:05 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_2.scala
2023.11.30 16:41:31 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_2.scala
Nov 30, 2023 4:47:24 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8575
2023.11.30 16:51:18 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_2.scala
2023.11.30 16:53:17 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_2.scala
2023.11.30 16:53:17 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_2.scala
2023.11.30 16:58:11 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_2.scala
2023.11.30 17:08:07 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_2.scala
2023.11.30 21:56:07 INFO  Shutting down server
2023.11.30 21:56:07 INFO  shutting down Metals
2023.11.30 21:56:07 INFO  Exiting server
2023.12.01 13:39:19 INFO  Started: Metals version 1.1.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.84.2.
2023.12.01 13:39:21 WARN  Build server is not auto-connectable.
2023.12.01 13:39:21 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.12.01 13:39:21 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1.scala
2023.12.01 13:39:26 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.12.01 13:39:30 INFO  time: code lens generation in 8.65s
2023.12.01 13:39:45 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
2023.12.01 13:39:45 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/week12.scala
2023.12.01 13:39:45 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/week12.scala
2023.12.01 13:40:06 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/week12.scala
Dec 01, 2023 1:47:23 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 515
Dec 01, 2023 1:47:45 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 571
Dec 01, 2023 1:49:18 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 925
Dec 01, 2023 1:50:20 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1075
Dec 01, 2023 1:55:36 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1480
2023.12.01 13:56:14 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
scala.meta.tokenizers.TokenizeException: <input>:27: error: unclosed string literal
    ordersDf.withColumn("date" unix_timestamp(col("date).cast(DateType)))
                                                  ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.01 13:56:21 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
Dec 01, 2023 1:56:50 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1638
2023.12.01 13:57:20 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
Exception in thread "pool-3-thread-1" java.lang.InterruptedException
	at scala.meta.internal.metals.FutureCancelToken.checkCanceled(FutureCancelToken.scala:29)
	at scala.meta.internal.pc.CompilerAccess.onCompilerJobQueue$$anonfun$1(CompilerAccess.scala:230)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:152)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2023.12.01 14:02:51 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
2023.12.01 14:13:35 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
Dec 01, 2023 2:13:35 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1891
2023.12.01 14:13:59 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
Dec 01, 2023 2:13:59 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1906
2023.12.01 14:14:03 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
Dec 01, 2023 2:14:03 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1920
2023.12.01 14:14:04 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
2023.12.01 14:14:19 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
Dec 01, 2023 2:14:19 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1942
2023.12.01 14:14:30 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
2023.12.01 14:14:36 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\example.scala
Dec 01, 2023 2:14:36 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1958
Dec 01, 2023 2:14:36 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1959
Dec 01, 2023 2:14:37 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1966
2023.12.01 14:14:38 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala
2023.12.01 14:14:44 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
Dec 01, 2023 2:14:44 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1976
2023.12.01 14:14:48 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
Dec 01, 2023 2:14:48 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1984
2023.12.01 14:14:52 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
Dec 01, 2023 2:14:53 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2000
Dec 01, 2023 2:16:18 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2006
Dec 01, 2023 2:16:42 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2016
Dec 01, 2023 2:17:38 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2194
Dec 01, 2023 2:42:54 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2545
2023.12.01 14:43:41 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
2023.12.01 14:43:41 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
2023.12.01 14:44:42 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
Dec 01, 2023 2:47:45 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2769
Dec 01, 2023 2:48:13 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2875
2023.12.01 15:09:22 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
Dec 01, 2023 3:09:22 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2901
2023.12.01 15:09:24 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
Dec 01, 2023 3:09:24 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2909
2023.12.01 15:09:29 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
Dec 01, 2023 3:09:29 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2917
Dec 01, 2023 3:09:32 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2925
2023.12.01 15:09:35 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2023.12.01 15:10:36 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
Dec 01, 2023 3:17:54 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3010
2023.12.01 15:17:56 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
2023.12.01 15:18:06 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_1.scala
2023.12.01 15:18:06 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/week12_1.scala
2023.12.01 15:18:06 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/week12_1.scala
2023.12.01 15:18:11 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
2023.12.01 15:18:13 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/week12_1.scala
Dec 01, 2023 3:18:49 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3186
2023.12.01 15:21:49 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_1.scala
scala.meta.tokenizers.TokenizeException: <input>:16: error: invalid escape character
    option("path" , "c:\Users\pp255070\OneDrive - Teradata\Documents\Spark\data folder\week12")
                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.01 15:21:54 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_1.scala
scala.meta.tokenizers.TokenizeException: <input>:16: error: invalid escape character
    option("path" , "c:\\Users\pp255070\OneDrive - Teradata\Documents\Spark\data folder\week12")
                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.01 15:21:57 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_1.scala
scala.meta.tokenizers.TokenizeException: <input>:16: error: invalid escape character
    option("path" , "c:\\Users\\pp255070\OneDrive - Teradata\Documents\Spark\data folder\week12")
                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.01 15:21:59 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_1.scala
scala.meta.tokenizers.TokenizeException: <input>:16: error: invalid escape character
    option("path" , "c:\\Users\\pp255070\\OneDrive - Teradata\Documents\Spark\data folder\week12")
                                                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.01 15:22:03 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_1.scala
scala.meta.tokenizers.TokenizeException: <input>:16: error: invalid escape character
    option("path" , "c:\\Users\\pp255070\\OneDrive - Teradata\\Documents\Spark\data folder\week12")
                                                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.01 15:22:05 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_1.scala
scala.meta.tokenizers.TokenizeException: <input>:16: error: invalid escape character
    option("path" , "c:\\Users\\pp255070\\OneDrive - Teradata\\Documents\\Spark\data folder\week12")
                                                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.01 15:22:08 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_1.scala
scala.meta.tokenizers.TokenizeException: <input>:16: error: invalid escape character
    option("path" , "c:\\Users\\pp255070\\OneDrive - Teradata\\Documents\\Spark\\data folder\week12")
                                                                                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.01 15:29:39 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_1.scala
2023.12.01 15:30:07 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
2023.12.01 15:30:16 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
2023.12.01 15:30:31 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1.scala
2023.12.01 15:30:49 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
2023.12.01 15:31:18 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
Dec 01, 2023 3:31:58 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4945
Dec 01, 2023 3:38:41 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5287
2023.12.01 15:38:47 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_1.scala
scala.meta.tokenizers.TokenizeException: <input>:41: error: unclosed character literal
        '
        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.01 15:42:00 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
Dec 01, 2023 3:42:00 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5517
Dec 01, 2023 3:44:25 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5731
2023.12.01 15:51:44 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_simpleAgg.scala
2023.12.01 15:51:46 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_simpleAgg.scala
2023.12.01 15:51:58 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_groupAgg.scala
2023.12.01 15:51:58 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/week12_groupAgg.scala
2023.12.01 15:51:58 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/week12_groupAgg.scala
2023.12.01 16:02:35 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/week12_groupAgg.scala
Dec 01, 2023 4:02:52 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6118
Dec 01, 2023 4:02:53 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6126
2023.12.01 16:09:40 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_groupAgg.scala
scala.meta.tokenizers.TokenizeException: <input>:27: error: unclosed string literal
    agg(sum("Quantity))
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.01 16:10:48 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_groupAgg.scala
scala.meta.tokenizers.TokenizeException: <input>:28: error: unclosed string interpolation
    sum(expr("Quantity" * Unit")))
                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.01 16:13:11 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_groupAgg.scala
Dec 01, 2023 4:13:36 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6797
2023.12.01 16:15:23 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_groupAgg.scala
Dec 01, 2023 4:17:56 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 7111
Dec 01, 2023 4:23:39 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 7800
2023.12.01 16:28:11 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_groupAgg.scala
2023.12.01 16:32:02 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_windowAgg.scala
2023.12.01 16:32:02 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/week12_windowAgg.scala
2023.12.01 16:32:02 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/week12_windowAgg.scala
2023.12.01 16:52:18 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/week12_windowAgg.scala
2023.12.01 16:52:45 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_simpleAgg.scala
2023.12.01 16:52:47 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_groupAgg.scala
2023.12.01 16:53:46 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_windowAgg.scala
2023.12.01 17:08:21 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_windowAgg.scala
2023.12.01 21:10:14 INFO  Shutting down server
2023.12.01 21:10:14 INFO  shutting down Metals
2023.12.01 21:10:14 INFO  Exiting server
2023.12.04 15:01:33 INFO  Started: Metals version 1.1.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.84.2.
2023.12.04 15:01:34 WARN  Build server is not auto-connectable.
2023.12.04 15:01:35 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.12.04 15:01:35 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_windowAgg.scala
2023.12.04 15:01:41 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_windowAgg.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.12.04 15:01:45 INFO  time: code lens generation in 10s
2023.12.04 22:00:07 INFO  Shutting down server
2023.12.04 22:00:07 INFO  shutting down Metals
2023.12.04 22:00:07 INFO  Exiting server
2023.12.05 11:34:42 INFO  Started: Metals version 1.1.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.84.2.
2023.12.05 11:34:42 WARN  Build server is not auto-connectable.
2023.12.05 11:34:42 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.12.05 11:34:42 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_windowAgg.scala
2023.12.05 11:34:44 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_windowAgg.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.12.05 11:34:46 INFO  time: code lens generation in 3.42s
2023.12.05 11:34:54 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
2023.12.05 11:35:13 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfJoin.scala
2023.12.05 11:35:13 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/week12_DfJoin.scala
2023.12.05 11:35:13 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/week12_DfJoin.scala
2023.12.05 11:39:41 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_windowAgg.scala
2023.12.05 11:39:44 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_groupAgg.scala
2023.12.05 11:39:50 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/week12_DfJoin.scala
Dec 05, 2023 11:40:24 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 151
Dec 05, 2023 11:40:36 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 206
Dec 05, 2023 11:41:21 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 372
Dec 05, 2023 11:45:00 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 620
Dec 05, 2023 11:46:06 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 864
2023.12.05 12:18:13 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_simpleAgg.scala
2023.12.05 12:18:26 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfJoin.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: unclosed string literal
                option("path" ,").
                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.05 12:19:45 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfJoin.scala
2023.12.05 12:22:40 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfJoin.scala
Dec 05, 2023 12:30:38 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1256
2023.12.05 12:31:49 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfJoin.scala
2023.12.05 12:32:01 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfJoin.scala
2023.12.05 12:52:49 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfJoin.scala
2023.12.05 12:53:01 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfJoin.scala
2023.12.05 12:54:23 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfJoin.scala
2023.12.05 12:54:23 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfJoin.scala
2023.12.05 12:54:35 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfJoin.scala
2023.12.05 13:13:17 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfJoin.scala
Dec 05, 2023 1:14:25 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1980
2023.12.05 13:16:04 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfJoin.scala
scala.meta.tokenizers.TokenizeException: <input>:48: error: unclosed string literal
    val joinDf = orders.join( customers , joinCondition , joinType).sort("order
                                                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.05 13:16:04 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfJoin.scala
scala.meta.tokenizers.TokenizeException: <input>:48: error: unclosed string literal
    val joinDf = orders.join( customers , joinCondition , joinType).sort("orde
                                                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.05 13:17:02 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfJoin.scala
2023.12.05 13:17:09 WARN  Using indexes to guess the definition of joinType
2023.12.05 13:17:44 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfJoin.scala
2023.12.05 13:17:44 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfJoin.scala
2023.12.05 13:23:41 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfJoin.scala
Dec 05, 2023 1:25:45 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2936
2023.12.05 13:26:31 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfJoin.scala
scala.meta.tokenizers.TokenizeException: <input>:67: error: unclosed string literal
    withColumn("order_id" ,expr("coalesce(order_id , -1)))
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.05 13:26:37 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfJoin.scala
scala.meta.tokenizers.TokenizeException: <input>:67: error: unclosed string literal
    withColumn("order_id" ,expr("coalesce(order_id , -1)""))
                                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Dec 05, 2023 1:26:58 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3083
2023.12.05 13:27:31 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfJoin.scala
2023.12.05 13:27:50 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfJoin.scala
2023.12.05 14:09:03 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfJoin.scala
Dec 05, 2023 2:21:19 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3314
Dec 05, 2023 2:21:31 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3381
2023.12.05 14:22:38 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfJoin.scala
2023.12.05 14:27:32 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfSimpleJoin.scala
2023.12.05 14:27:56 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
2023.12.05 14:28:12 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
2023.12.05 14:28:12 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/week12_DfBroadcastJoin.scala
2023.12.05 14:28:13 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/week12_DfBroadcastJoin.scala
Dec 05, 2023 2:28:21 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3610
2023.12.05 14:28:33 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
2023.12.05 14:28:55 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
scala.meta.tokenizers.TokenizeException: <input>:27: error: unclosed string literal
    spark.sql(SET spark.sql.autoBroadcastJoinThreshold =-1")
                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.05 14:29:02 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
scala.meta.tokenizers.TokenizeException: <input>:27: error: unclosed string literal
    spark.sql(SET spark.sql.autoBroadcastJoinThreshold = -1")
                                                           ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.05 14:29:08 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
scala.meta.tokenizers.TokenizeException: <input>:27: error: unclosed string literal
    spark.sql(SET spark.sql.autoBroadcastJoinThreshold =-1")
                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.05 14:29:27 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
scala.meta.tokenizers.TokenizeException: <input>:27: error: unclosed string literal
    spark.sql(SET spark.sql.autoBroadcastJoinThreshold =-1")
                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.05 14:29:29 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
scala.meta.tokenizers.TokenizeException: <input>:27: error: unclosed string literal
    spark.sql(SET spark.sql.autoBroadcastJoinThreshold =-1") 
                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.05 14:29:29 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
scala.meta.tokenizers.TokenizeException: <input>:27: error: unclosed string literal
    spark.sql(SET spark.sql.autoBroadcastJoinThreshold =-1") //
                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.05 14:29:30 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
scala.meta.tokenizers.TokenizeException: <input>:27: error: unclosed string literal
    spark.sql(SET spark.sql.autoBroadcastJoinThreshold =-1") //his for keeping the automaticat optimization off for joins
                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.05 14:29:35 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
scala.meta.tokenizers.TokenizeException: <input>:27: error: unclosed string literal
    spark.sql(SET spark.sql.autoBroadcastJoinThreshold =-1") //this for keeping the automaticat optimization off for joins
                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Dec 05, 2023 2:29:37 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3758
2023.12.05 14:29:47 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfSimpleJoin.scala
2023.12.05 14:30:32 WARN  Using indexes to guess the definition of joinType
2023.12.05 14:31:27 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
2023.12.05 14:40:21 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
2023.12.05 14:40:26 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
Dec 05, 2023 2:40:26 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3939
Dec 05, 2023 2:40:49 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3953
2023.12.05 14:40:53 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2023.12.05 14:40:54 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1.scala
2023.12.05 14:41:45 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2.scala
2023.12.05 14:41:45 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/adv2.scala
2023.12.05 14:41:46 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/adv2.scala
2023.12.05 14:42:20 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala
2023.12.05 14:42:41 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2023.12.05 14:42:42 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/adv2RddtoDF(case%20class).scala
Exception in thread "pool-3-thread-1" java.lang.InterruptedException
	at scala.meta.internal.metals.FutureCancelToken.checkCanceled(FutureCancelToken.scala:29)
	at scala.meta.internal.pc.CompilerAccess.onCompilerJobQueue$$anonfun$1(CompilerAccess.scala:230)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:152)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2023.12.05 14:42:54 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/adv2RddtoDF(case%20class).scala
Dec 05, 2023 2:43:58 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4258
2023.12.05 14:45:23 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
scala.meta.tokenizers.TokenizeException: <input>:7: error: unclosed string literal
    val fields = line.splti(")
                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.05 14:45:25 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
scala.meta.tokenizers.TokenizeException: <input>:7: error: unclosed character literal
    val fields = line.splti('')
                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.05 14:49:00 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
Dec 05, 2023 2:53:10 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5426
2023.12.05 14:55:05 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
Dec 05, 2023 2:56:05 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5886
2023.12.05 14:56:49 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2023.12.05 15:04:43 WARN  Using indexes to guess the definition of mapper
Dec 05, 2023 3:04:45 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6688
2023.12.05 15:06:12 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2023.12.05 15:06:13 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
Exception in thread "pool-3-thread-2" java.lang.InterruptedException
	at scala.meta.internal.metals.FutureCancelToken.checkCanceled(FutureCancelToken.scala:29)
	at scala.meta.internal.pc.CompilerAccess.onCompilerJobQueue$$anonfun$1(CompilerAccess.scala:230)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:152)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
2023.12.05 15:07:50 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
Dec 05, 2023 3:09:03 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6973
2023.12.05 15:10:06 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2023.12.05 15:10:27 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2023.12.05 15:10:27 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2023.12.05 15:12:56 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2023.12.05 22:03:44 INFO  Shutting down server
2023.12.05 22:03:44 INFO  shutting down Metals
2023.12.05 22:03:44 INFO  Exiting server
2023.12.06 12:40:05 INFO  Started: Metals version 1.1.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.84.2.
2023.12.06 12:40:09 WARN  Build server is not auto-connectable.
2023.12.06 12:40:09 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.12.06 12:40:09 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2023.12.06 12:40:16 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.12.06 12:40:21 INFO  time: code lens generation in 12s
Dec 06, 2023 12:40:36 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 20
Dec 06, 2023 12:40:50 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 78
Dec 06, 2023 12:41:21 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 134
2023.12.06 12:42:38 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
scala.meta.tokenizers.TokenizeException: <input>:51: error: unclosed string literal
    df2.createOrReplaceTempView("new_logging_table)
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.06 12:45:11 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2023.12.06 12:54:58 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
scala.meta.tokenizers.TokenizeException: <input>:56: error: unclosed string interpolation
                option"
                       ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Dec 06, 2023 12:57:29 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1277
2023.12.06 13:02:06 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala
2023.12.06 13:02:13 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2023.12.06 13:02:51 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2023.12.06 13:04:25 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
scala.meta.tokenizers.TokenizeException: <input>:58: error: invalid escape character
                option("path","c:\Users\pp255070\OneDrive - Teradata\Documents\Spark\data folder\week12\\biglog.txt").
                                  ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.06 13:04:30 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
scala.meta.tokenizers.TokenizeException: <input>:58: error: invalid escape character
                option("path","c:\\Users\pp255070\OneDrive - Teradata\Documents\Spark\data folder\week12\\biglog.txt").
                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.06 13:04:32 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
scala.meta.tokenizers.TokenizeException: <input>:58: error: invalid escape character
                option("path","c:\\Users\\pp255070\OneDrive - Teradata\Documents\Spark\data folder\week12\\biglog.txt").
                                                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.06 13:04:33 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
scala.meta.tokenizers.TokenizeException: <input>:58: error: invalid escape character
                option("path","c:\\Users\\pp255070\O\neDrive - Teradata\Documents\Spark\data folder\week12\\biglog.txt").
                                                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.06 13:04:34 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
scala.meta.tokenizers.TokenizeException: <input>:58: error: invalid escape character
                option("path","c:\\Users\\pp255070\neDrive - Teradata\Documents\Spark\data folder\week12\\biglog.txt").
                                                                      ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.06 13:04:36 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
scala.meta.tokenizers.TokenizeException: <input>:58: error: invalid escape character
                option("path","c:\\Users\\pp255070\\neDrive - Teradata\Documents\Spark\data folder\week12\\biglog.txt").
                                                                       ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.06 13:04:36 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
scala.meta.tokenizers.TokenizeException: <input>:58: error: invalid escape character
                option("path","c:\\Users\\pp255070\\OneDrive - Teradata\Documents\Spark\data folder\week12\\biglog.txt").
                                                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.06 13:04:40 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
scala.meta.tokenizers.TokenizeException: <input>:58: error: invalid escape character
                option("path","c:\\Users\\pp255070\\OneDrive - Teradata\\Documents\Spark\data folder\week12\\biglog.txt").
                                                                                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.06 13:04:42 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
scala.meta.tokenizers.TokenizeException: <input>:58: error: invalid escape character
                option("path","c:\\Users\\pp255070\\OneDrive - Teradata\\Documents\\Spark\data folder\week12\\biglog.txt").
                                                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.06 13:04:43 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
scala.meta.tokenizers.TokenizeException: <input>:58: error: invalid escape character
                option("path","c:\\Users\\pp255070\\OneDrive - Teradata\\Documents\\Spark\\data folder\week12\\biglog.txt").
                                                                                                       ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.06 13:04:48 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2023.12.06 13:06:45 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
Dec 06, 2023 1:09:29 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1800
Dec 06, 2023 1:10:30 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2008
2023.12.06 13:10:52 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
scala.meta.tokenizers.TokenizeException: <input>:65: error: unclosed multi-line string literal
    spark.sql(""" select level , date_format(datetime , 'MMMM') as month , date_format(datetime 'M') as month_number , count(1) from big_logging_table group by level , month order by month_num")
              ^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getRawStringLit(LegacyScanner.scala:567)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:366)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.06 13:10:59 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
scala.meta.tokenizers.TokenizeException: <input>:65: error: unclosed multi-line string literal
    spark.sql(""" select level , date_format(datetime , 'MMMM') as month , date_format(datetime 'M') as month_number , count(1) from big_logging_table group by level , month order by month_num")
              ^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getRawStringLit(LegacyScanner.scala:567)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:366)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Dec 06, 2023 1:11:01 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2089
2023.12.06 13:13:26 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
Dec 06, 2023 1:20:04 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2527
Dec 06, 2023 1:22:10 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2621
Dec 06, 2023 1:22:18 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2651
Dec 06, 2023 1:22:29 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2698
Dec 06, 2023 1:22:33 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2716
Dec 06, 2023 1:39:28 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3058
Dec 06, 2023 1:40:47 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3283
2023.12.06 13:40:49 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
Dec 06, 2023 1:47:57 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3361
Dec 06, 2023 1:48:11 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3421
Dec 06, 2023 1:48:23 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3476
Dec 06, 2023 1:48:29 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3505
Dec 06, 2023 1:50:10 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3664
Dec 06, 2023 1:50:53 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3819
Dec 06, 2023 1:51:52 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3898
Dec 06, 2023 1:53:24 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4150
Dec 06, 2023 1:53:38 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4192
2023.12.06 13:53:43 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2023.12.06 13:59:34 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
Dec 06, 2023 1:59:34 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4214
Dec 06, 2023 2:02:26 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4222
2023.12.06 14:05:54 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_groupAgg.scala
2023.12.06 14:06:29 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
Dec 06, 2023 2:06:29 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4259
2023.12.06 14:10:35 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
Dec 06, 2023 2:18:28 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4430
2023.12.06 14:18:45 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
2023.12.06 14:18:49 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
2023.12.06 14:19:22 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
2023.12.06 14:19:25 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
2023.12.06 14:19:26 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
2023.12.06 14:19:50 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
Dec 06, 2023 2:50:23 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4597
2023.12.06 17:17:58 INFO  Shutting down server
2023.12.06 17:17:58 INFO  shutting down Metals
2023.12.06 17:17:58 INFO  Exiting server
2023.12.08 14:52:07 INFO  Started: Metals version 1.1.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.84.2.
2023.12.08 14:52:09 WARN  Build server is not auto-connectable.
2023.12.08 14:52:09 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.12.08 14:52:09 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
2023.12.08 14:52:15 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.12.08 14:52:18 INFO  time: code lens generation in 9.24s
2023.12.08 15:04:49 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
Dec 08, 2023 3:10:19 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 84
Dec 08, 2023 3:10:50 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 213
Dec 08, 2023 3:10:51 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 217
2023.12.08 15:11:00 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
2023.12.08 15:16:09 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala
2023.12.08 15:16:33 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\example.scala
2023.12.08 15:16:34 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala
2023.12.08 15:25:41 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
2023.12.08 15:25:41 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\OneDrive - Teradata\Documents\sample.txt")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.08 15:25:41 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\OneDrive - Teradata\Documents\sample.txt")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.08 15:25:52 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala
2023.12.08 15:35:47 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2023.12.08 15:41:57 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\example.scala
2023.12.08 15:44:53 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2023.12.08 15:54:03 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
Dec 08, 2023 3:55:06 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 355
Dec 08, 2023 3:56:19 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 478
2023.12.08 16:04:48 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfSimpleJoin.scala
2023.12.08 16:15:07 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
Dec 08, 2023 4:15:07 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 584
2023.12.08 16:15:11 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfSimpleJoin.scala
2023.12.08 16:15:15 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_simpleAgg.scala
Dec 08, 2023 4:15:15 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 600
2023.12.08 16:15:16 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_groupAgg.scala
Dec 08, 2023 4:15:16 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 608
2023.12.08 16:15:17 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_simpleAgg.scala
Dec 08, 2023 4:15:17 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 616
Dec 08, 2023 4:15:37 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 624
2023.12.08 16:15:41 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
2023.12.08 16:17:28 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2023.12.08 16:18:34 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_windowAgg.scala
2023.12.08 16:18:37 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
2023.12.08 16:18:41 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfSimpleJoin.scala
2023.12.08 16:19:31 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
2023.12.08 23:03:31 INFO  Shutting down server
2023.12.08 23:03:31 INFO  shutting down Metals
2023.12.08 23:03:31 INFO  Exiting server
2023.12.11 14:06:29 INFO  Started: Metals version 1.1.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.0.
2023.12.11 14:06:30 WARN  Build server is not auto-connectable.
2023.12.11 14:06:30 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.12.11 14:06:30 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
2023.12.11 14:06:36 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.12.11 14:06:39 INFO  time: code lens generation in 7.66s
2023.12.11 14:15:39 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2023.12.11 14:19:11 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfSimpleJoin.scala
2023.12.11 14:19:31 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_simpleAgg.scala
2023.12.11 14:19:34 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
2023.12.11 14:19:36 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfSimpleJoin.scala
2023.12.11 14:19:38 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
2023.12.11 14:19:49 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_simpleAgg.scala
2023.12.11 14:24:47 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_simpleAgg.scala
scala.meta.tokenizers.TokenizeException: <input>:18: error: unclosed string literal
    option("inferSchema" , true").
                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.11 14:24:54 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_simpleAgg.scala
2023.12.11 14:34:16 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_groupAgg.scala
2023.12.11 14:35:41 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_groupAgg.scala
scala.meta.tokenizers.TokenizeException: <input>:18: error: unclosed string literal
    option("inferSchema" , "tr).
                           ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.11 14:35:42 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_groupAgg.scala
scala.meta.tokenizers.TokenizeException: <input>:18: error: unclosed string literal
    option("inferSchema" , ").
                           ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.11 14:35:47 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_groupAgg.scala
2023.12.11 14:41:41 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_windowAgg.scala
2023.12.11 14:48:10 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfSimpleJoin.scala
2023.12.11 14:48:47 WARN  Using indexes to guess the definition of sparkconf
Dec 11, 2023 2:51:14 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 430
2023.12.11 14:56:16 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
2023.12.11 16:16:37 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
2023.12.11 16:16:37 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week12_1.scala
2023.12.11 16:16:37 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week12_1.scala
2023.12.11 16:18:05 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala
2023.12.11 16:26:32 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfSimpleJoin.scala
2023.12.11 16:27:10 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2023.12.11 16:27:23 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala
2023.12.11 16:27:43 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
2023.12.11 16:27:55 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
2023.12.11 16:28:00 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
2023.12.11 16:29:37 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfSimpleJoin.scala
Dec 11, 2023 4:29:48 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 869
Dec 11, 2023 4:30:23 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1008
2023.12.11 16:32:42 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
2023.12.11 16:34:35 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
2023.12.11 16:34:54 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
2023.12.11 16:38:34 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
2023.12.11 16:39:28 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
2023.12.11 16:39:41 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: invalid escape character
    val dept = spark.read.format("json").option("path" ,"C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dept.json").load()
                                                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.11 16:39:52 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val employee = spark.read.format("json").option("path" ,"C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\emp.json").load()
                                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.11 16:39:58 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val employee = spark.read.format("json").option("path" ,"C:\\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\emp.json").load()
                                                                       ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.11 16:40:00 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val employee = spark.read.format("json").option("path" ,"C:\\Users\\pp255070\OneDrive - Teradata\Documents\sparklearning\emp.json").load()
                                                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.11 16:40:03 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val employee = spark.read.format("json").option("path" ,"C:\\Users\\pp255070\\OneDrive - Teradata\Documents\sparklearning\emp.json").load()
                                                                                                      ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.11 16:40:05 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val employee = spark.read.format("json").option("path" ,"C:\\Users\\pp255070\\OneDrive - Teradata\\Documents\sparklearning\emp.json").load()
                                                                                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.11 16:40:07 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val employee = spark.read.format("json").option("path" ,"C:\\Users\\pp255070\\OneDrive - Teradata\\Documents\\sparklearning\emp.json").load()
                                                                                                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.11 16:40:09 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: invalid escape character
    val dept = spark.read.format("json").option("path" ,"C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dept.json").load()
                                                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.11 16:40:14 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: invalid escape character
    val dept = spark.read.format("json").option("path" ,"C:\\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dept.json").load()
                                                                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.11 16:40:17 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: invalid escape character
    val dept = spark.read.format("json").option("path" ,"C:\\Users\pp255070\\OneDrive - Teradata\Documents\sparklearning\dept.json").load()
                                                                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.11 16:40:19 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: invalid escape character
    val dept = spark.read.format("json").option("path" ,"C:\\Users\\pp255070\\OneDrive - Teradata\Documents\sparklearning\dept.json").load()
                                                                                                  ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.11 16:40:22 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: invalid escape character
    val dept = spark.read.format("json").option("path" ,"C:\\Users\\pp255070\\OneDrive - Teradata\\Documents\sparklearning\dept.json").load()
                                                                                                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.11 16:40:24 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: invalid escape character
    val dept = spark.read.format("json").option("path" ,"C:\\Users\\pp255070\\OneDrive - Teradata\\Documents\\sparklearning\dept.json").load()
                                                                                                                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.11 16:40:31 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
2023.12.11 16:42:03 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
2023.12.11 16:42:04 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
2023.12.11 16:42:03 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
2023.12.11 16:42:15 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
2023.12.11 16:42:15 WARN  Using indexes to guess the definition of employee
2023.12.11 16:42:28 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
2023.12.11 16:42:40 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
2023.12.11 16:52:33 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_simpleAgg.scala
2023.12.11 16:52:42 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_groupAgg.scala
2023.12.11 16:52:53 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_simpleAgg.scala
2023.12.11 16:53:00 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_groupAgg.scala
2023.12.11 16:58:22 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_windowAgg.scala
2023.12.11 16:58:33 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_groupAgg.scala
2023.12.11 16:58:37 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_simpleAgg.scala
2023.12.11 16:58:45 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_windowAgg.scala
2023.12.11 16:58:50 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2023.12.11 17:40:33 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2023.12.11 17:40:34 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
2023.12.11 17:40:40 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
2023.12.11 17:40:50 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala
2023.12.11 17:41:01 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
2023.12.11 17:41:17 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
2023.12.11 17:41:39 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala
2023.12.11 17:43:03 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2023.12.11 17:43:06 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
2023.12.11 17:47:14 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
2023.12.11 17:47:29 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala
2023.12.11 17:47:35 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2023.12.11 17:51:08 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
2023.12.11 17:51:23 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
2023.12.11 17:51:30 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_2.scala
2023.12.11 17:51:40 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
2023.12.11 17:51:40 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week12_2.scala
2023.12.11 17:51:41 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week12_2.scala
2023.12.11 17:51:59 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
Dec 11, 2023 5:53:34 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3343
Dec 11, 2023 5:53:42 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3396
2023.12.11 17:55:50 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
2023.12.11 18:04:46 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
2023.12.11 18:05:45 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
2023.12.11 18:05:53 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
Dec 11, 2023 6:06:59 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5241
Dec 11, 2023 6:06:59 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5243
Dec 11, 2023 6:07:37 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5325
2023.12.11 18:07:57 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
Dec 11, 2023 6:11:54 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5397
Dec 11, 2023 6:13:29 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5727
Dec 11, 2023 6:13:39 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5773
Dec 11, 2023 6:14:20 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5950
Dec 11, 2023 6:14:29 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5977
Dec 11, 2023 6:14:40 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6009
2023.12.11 18:14:48 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
2023.12.11 18:14:52 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2023.12.11 18:15:06 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
2023.12.11 18:15:08 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2023.12.11 18:15:10 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala
2023.12.11 18:15:14 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
2023.12.11 18:15:15 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\example.scala
2023.12.11 18:15:21 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala
2023.12.11 18:16:01 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
2023.12.11 18:19:05 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
2023.12.11 18:19:23 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
2023.12.11 22:34:57 INFO  Shutting down server
2023.12.11 22:34:57 INFO  shutting down Metals
2023.12.11 22:34:57 INFO  Exiting server
2023.12.12 11:13:04 INFO  Started: Metals version 1.1.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.0.
2023.12.12 11:13:04 WARN  Build server is not auto-connectable.
2023.12.12 11:13:05 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.12.12 11:13:05 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
2023.12.12 11:13:06 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.12.12 11:13:08 INFO  time: code lens generation in 3.44s
Dec 12, 2023 11:17:34 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 98
2023.12.12 11:19:27 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_groupAgg.scala
Dec 12, 2023 11:19:27 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 241
Dec 12, 2023 11:19:27 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 244
2023.12.12 11:24:30 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
2023.12.12 11:24:55 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
scala.meta.tokenizers.TokenizeException: <input>:46: error: unclosed string literal
    val popular = transformedDf.filter("movieviewcount" > 1000 and "rating)
                                                                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.12 11:25:22 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
scala.meta.tokenizers.TokenizeException: <input>:46: error: unclosed string literal
    val popular = transformedDf.filter("movieviewcount > 1000 and avgMovieRating > 4.5)
                                       ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.12 11:25:56 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
2023.12.12 11:26:02 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
Dec 12, 2023 11:27:18 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1064
Dec 12, 2023 11:28:31 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1197
2023.12.12 11:28:33 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
2023.12.12 11:29:54 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
scala.meta.tokenizers.TokenizeException: <input>:54: error: unclosed string literal
      "val finalPopular 
      ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.12 11:29:59 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
scala.meta.tokenizers.TokenizeException: <input>:53: error: unclosed string literal
      "
      ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.12 11:30:38 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
2023.12.12 11:30:45 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
Dec 12, 2023 11:32:44 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1713
2023.12.12 11:33:24 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
2023.12.12 11:37:47 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
2023.12.12 11:38:11 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_simpleAgg.scala
2023.12.12 11:38:14 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_groupAgg.scala
2023.12.12 11:38:20 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_windowAgg.scala
2023.12.12 11:38:32 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala
2023.12.12 11:38:36 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2023.12.12 11:38:57 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2023.12.12 11:39:04 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
2023.12.12 11:39:11 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
2023.12.12 11:39:29 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2023.12.12 11:39:33 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2023.12.12 11:39:38 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala
2023.12.12 11:39:45 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
2023.12.12 11:39:52 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
2023.12.12 11:40:07 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala
2023.12.12 11:40:12 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2023.12.12 11:40:17 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2023.12.12 11:40:21 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
2023.12.12 11:40:27 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\example.scala
2023.12.12 11:40:29 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala
2023.12.12 11:40:31 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
2023.12.12 11:40:34 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
2023.12.12 11:40:38 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
2023.12.12 11:40:43 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfSimpleJoin.scala
2023.12.12 11:41:10 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_groupAgg.scala
2023.12.12 11:41:22 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_simpleAgg.scala
2023.12.12 11:41:31 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_windowAgg.scala
2023.12.12 11:41:40 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
2023.12.12 11:42:38 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week10_2.scala
2023.12.12 11:42:41 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
2023.12.12 11:44:29 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_3.scala
2023.12.12 11:44:29 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week12_3.scala
2023.12.12 11:44:29 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week12_3.scala
2023.12.12 11:44:41 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
2023.12.12 11:44:50 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week12_3.scala
2023.12.12 11:45:02 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week12_3.scala
2023.12.12 11:46:29 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
Dec 12, 2023 11:48:15 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2518
Dec 12, 2023 11:48:18 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2533
Dec 12, 2023 11:49:08 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2698
2023.12.12 11:50:59 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_3.scala
scala.meta.tokenizers.TokenizeException: <input>:19: error: unclosed character literal
    val rdd2 = rdd1.map( x => x.split(''))
                                      ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.12 11:50:59 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_3.scala
scala.meta.tokenizers.TokenizeException: <input>:19: error: unclosed character literal
    val rdd2 = rdd1.map( x => x.split('\'))
                                      ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Dec 12, 2023 11:52:05 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3238
2023.12.12 11:52:31 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_3.scala
scala.meta.tokenizers.TokenizeException: <input>:19: error: unclosed character literal
    val rdd2 = rdd1.map( x => x.split('\t)).map( x=> scorecard( x(0).toInt, x(1), x(2), x(3).toInt, x(4).toDouble))
                                      ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.12 11:52:31 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_3.scala
scala.meta.tokenizers.TokenizeException: <input>:19: error: unclosed character literal
    val rdd2 = rdd1.map( x => x.split(')).map( x=> scorecard( x(0).toInt, x(1), x(2), x(3).toInt, x(4).toDouble))
                                      ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.12 11:52:35 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_3.scala
scala.meta.tokenizers.TokenizeException: <input>:19: error: unclosed string literal
    val rdd2 = rdd1.map( x => x.split("\")).map( x=> scorecard( x(0).toInt, x(1), x(2), x(3).toInt, x(4).toDouble))
                                      ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.12 11:55:03 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
2023.12.12 11:55:12 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
2023.12.12 11:55:16 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
2023.12.12 11:55:27 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2023.12.12 11:55:31 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
2023.12.12 11:55:38 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
2023.12.12 11:55:46 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala
2023.12.12 11:55:49 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2023.12.12 11:55:54 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
2023.12.12 11:56:00 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
2023.12.12 11:56:02 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
2023.12.12 11:56:04 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala
2023.12.12 12:01:17 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_3.scala
scala.meta.tokenizers.TokenizeException: <input>:28: error: unclosed string literal
    val rdd4 = rdd3.map( x => x.split("\"))
                                      ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.12 12:02:49 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
2023.12.12 12:03:31 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_3.scala
2023.12.12 12:03:36 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_3.scala
2023.12.12 12:04:21 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_3.scala
2023.12.12 12:04:45 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad3_join.scala
2023.12.12 12:04:53 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
2023.12.12 12:04:53 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.12 12:04:53 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.12 12:04:59 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad1.scala
2023.12.12 12:05:04 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\ratings.scala
2023.12.12 12:05:07 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\linkedin.scala
2023.12.12 12:05:11 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\customer.scala
2023.12.12 12:05:11 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\customer.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.12 12:05:11 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\customer.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.12 12:05:14 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
2023.12.12 12:05:17 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
2023.12.12 12:05:17 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\OneDrive - Teradata\Documents\sample.txt")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.12 12:05:17 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\OneDrive - Teradata\Documents\sample.txt")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.12 12:05:20 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala
2023.12.12 12:05:49 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala
2023.12.12 12:06:04 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_3.scala
2023.12.12 12:20:11 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_3.scala
2023.12.12 12:22:27 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
2023.12.12 12:23:39 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_3.scala
2023.12.12 12:25:49 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_3.scala
2023.12.12 12:26:06 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_3.scala
2023.12.12 12:27:19 WARN  Using indexes to guess the definition of playerSch
2023.12.12 12:28:20 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_3.scala
2023.12.12 12:28:20 WARN  Using indexes to guess the definition of playerSch
2023.12.12 12:28:28 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_3.scala
2023.12.12 12:28:38 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_3.scala
2023.12.12 18:41:39 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
2023.12.12 18:41:40 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.12 18:41:40 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.12 18:41:44 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
2023.12.12 18:41:57 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
2023.12.12 18:41:57 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.12 18:41:58 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.12 21:21:20 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.12 21:21:21 INFO  Shutting down server
2023.12.12 21:21:21 INFO  shutting down Metals
2023.12.12 21:21:21 INFO  Exiting server
2023.12.13 17:14:02 INFO  Started: Metals version 1.1.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.0.
2023.12.13 17:14:02 WARN  Build server is not auto-connectable.
2023.12.13 17:14:02 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.12.13 17:14:02 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
2023.12.13 17:14:06 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.12.13 17:14:08 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.13 17:14:08 INFO  time: code lens generation in 5.61s
2023.12.13 17:14:08 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.13 17:14:10 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\salting.scala
2023.12.13 17:14:10 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/salting.scala
2023.12.13 17:14:11 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/salting.scala
2023.12.13 17:50:29 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\salting.scala
2023.12.13 21:21:09 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.13 21:21:14 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val input = sc.textFile("c:\\Users\pp255070\Downloads\customerorders.csv")
                                       ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.13 21:21:16 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val input = sc.textFile("c:\\Users\\pp255070\Downloads\customerorders.csv")
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.13 21:21:18 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
scala.meta.tokenizers.TokenizeException: <input>:15: error: invalid escape character
    val input = sc.textFile("c:\\Users\\pp255070\\Downloads\customerorders.csv")
                                                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:539)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.13 21:21:25 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
Dec 13, 2023 9:21:32 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 162
2023.12.13 21:23:11 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\salting.scala
2023.12.13 21:59:14 INFO  Shutting down server
2023.12.13 21:59:14 INFO  shutting down Metals
2023.12.13 21:59:14 INFO  Exiting server
2023.12.14 12:01:54 INFO  Started: Metals version 1.2.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.0.
2023.12.14 12:01:55 WARN  Build server is not auto-connectable.
2023.12.14 12:01:55 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.12.14 12:01:55 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
2023.12.14 12:01:55 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\salting.scala
2023.12.14 12:02:04 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala. Using presentation compiler with project's scala-library version: 3.3.1
Dec 14, 2023 12:02:06 PM org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
2023.12.14 12:02:06 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
Dec 14, 2023 12:02:06 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 7
Dec 14, 2023 12:02:06 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8
2023.12.14 12:02:07 INFO  time: code lens generation in 11s
Dec 14, 2023 12:02:44 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 90
2023.12.14 12:03:03 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
2023.12.14 12:03:37 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/cache_persist.scala
2023.12.14 12:03:38 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/cache_persist.scala
2023.12.14 12:04:15 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
2023.12.14 12:04:33 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
Dec 14, 2023 1:05:25 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 390
2023.12.14 13:05:37 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\salting.scala
2023.12.14 14:59:42 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
2023.12.14 14:59:58 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SparkOptimization.scala
2023.12.14 14:59:58 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization.scala
2023.12.14 14:59:59 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization.scala
2023.12.14 15:00:09 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization.scala
2023.12.14 15:00:20 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_3.scala
2023.12.14 15:00:32 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization.scala
2023.12.14 15:00:34 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization.scala
2023.12.14 15:00:35 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization.scala
2023.12.14 15:00:36 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization.scala
2023.12.14 15:00:36 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization.scala
2023.12.14 15:00:38 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization.scala
2023.12.14 15:00:38 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization.scala
2023.12.14 15:01:04 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization.scala
2023.12.14 15:01:05 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization.scala
2023.12.14 15:01:21 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\linkedin.scala
2023.12.14 15:01:27 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\ratings.scala
2023.12.14 15:01:30 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala
Dec 14, 2023 3:01:37 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 569
Dec 14, 2023 3:04:32 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1154
2023.12.14 15:05:14 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SparkOptimization.scala
2023.12.14 15:09:13 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SparkOptimization.scala
2023.12.14 15:19:07 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\broadcast.scala
Dec 14, 2023 3:54:32 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1570
Dec 14, 2023 3:54:58 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1673
2023.12.14 15:55:59 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SparkOptimization.scala
Dec 14, 2023 3:59:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2023-12-14\r_compiler-error_15-59-25-702.md
Dec 14, 2023 3:59:39 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1975
Dec 14, 2023 3:59:40 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1977
Dec 14, 2023 4:00:25 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2083
2023.12.14 16:05:16 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SparkOptimization.scala
2023.12.14 16:07:01 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SparkOptimization_broadcast.scala
2023.12.14 16:18:50 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
2023.12.14 16:23:11 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
2023.12.14 16:23:12 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfSimpleJoin.scala
2023.12.14 16:26:08 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SparkOptimization_broadcastDF.scala
2023.12.14 16:26:08 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization_broadcastDF.scala
2023.12.14 16:26:09 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization_broadcastDF.scala
2023.12.14 16:26:17 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SparkOptimization_broadcastRDD.scala
2023.12.14 16:26:17 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization_broadcastDF.scala
2023.12.14 16:26:25 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization_broadcastDF.scala
2023.12.14 16:26:29 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization_broadcastDF.scala
2023.12.14 16:26:30 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization_broadcastDF.scala
2023.12.14 16:26:30 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization_broadcastDF.scala
2023.12.14 16:26:32 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization_broadcastDF.scala
2023.12.14 16:26:34 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization_broadcastDF.scala
2023.12.14 16:26:34 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization_broadcastDF.scala
2023.12.14 16:26:37 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization_broadcastDF.scala
2023.12.14 16:26:37 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization_broadcastDF.scala
2023.12.14 16:26:41 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization_broadcastDF.scala
2023.12.14 16:26:42 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization_broadcastDF.scala
2023.12.14 16:26:49 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization_broadcastDF.scala
2023.12.14 16:26:50 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization_broadcastDF.scala
2023.12.14 16:29:31 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization_broadcastDF.scala
2023.12.14 16:29:32 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization_broadcastDF.scala
2023.12.14 16:29:40 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SparkOptimization_broadcastDF.scala
2023.12.14 16:30:36 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfSimpleJoin.scala
2023.12.14 16:30:59 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SparkOptimization_broadcastDF.scala
Dec 14, 2023 4:31:05 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2944
2023.12.14 16:31:57 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SparkOptimization_broadcastDF.scala
2023.12.14 16:32:39 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SparkOptimization_broadcastDF.scala
Dec 14, 2023 4:33:05 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3172
2023.12.14 16:35:06 INFO  time: code lens generation in 1.86s
Dec 14, 2023 4:37:23 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3870
2023.12.14 16:39:27 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SparkOptimization_broadcastDF.scala
2023.12.14 16:39:30 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SparkOptimization_broadcastDF.scala
2023.12.14 16:42:24 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SparkOptimization_broadcastDF.scala
2023.12.14 16:42:29 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
2023.12.14 16:43:29 WARN  Using indexes to guess the definition of dfcust
2023.12.14 16:43:30 WARN  Using indexes to guess the definition of dfcust
Dec 14, 2023 4:44:15 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4614
2023.12.14 16:44:21 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SparkOptimization_broadcastDF.scala
2023.12.14 16:45:04 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfSimpleJoin.scala
2023.12.14 16:45:05 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
2023.12.14 16:45:54 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SparkOptimization_broadcastDF.scala
2023.12.14 16:54:27 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
2023.12.14 16:54:36 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
2023.12.14 16:54:44 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala
2023.12.14 21:43:51 INFO  Shutting down server
2023.12.14 21:43:51 INFO  shutting down Metals
2023.12.14 21:43:51 INFO  Exiting server
2023.12.15 13:24:05 INFO  Started: Metals version 1.2.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.1.
2023.12.15 13:24:07 WARN  Build server is not auto-connectable.
2023.12.15 13:24:07 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.12.15 13:24:07 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SparkOptimization_broadcastDF.scala
2023.12.15 13:24:17 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SparkOptimization_broadcastDF.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.12.15 13:24:21 INFO  time: code lens generation in 12s
2023.12.15 13:24:21 INFO  time: code lens generation in 5.64s
Dec 15, 2023 1:30:12 PM org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
2023.12.15 13:30:17 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SparkOptimization_broadcastRDD.scala
2023.12.15 13:30:21 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\salting.scala
2023.12.15 13:30:21 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_3.scala
2023.12.15 13:30:37 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala
2023.12.15 13:30:43 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\ratings.scala
2023.12.15 13:30:45 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\linkedin.scala
2023.12.15 13:30:47 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\filter.scala
2023.12.15 13:30:57 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\misc.scala
2023.12.15 13:30:57 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:30:58 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:30:59 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
Dec 15, 2023 1:30:59 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 68
2023.12.15 13:31:00 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:00 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:01 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:02 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:02 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:03 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:05 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:06 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:06 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:08 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:09 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:10 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:10 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:10 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:12 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:12 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:14 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:15 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:16 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:16 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:17 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:17 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:18 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:18 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:19 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:19 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:21 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:22 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:22 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:25 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:25 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:30 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:30 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:31 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:32 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:32 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:33 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:33 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:34 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:37 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:38 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:39 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:40 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:41 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:42 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:43 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:43 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:44 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:44 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:45 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:46 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:47 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:47 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:48 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:48 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:49 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:50 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:51 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:51 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:52 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:53 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:54 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:55 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:56 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:31:58 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:32:01 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:32:02 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:32:03 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:32:03 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:32:04 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:32:05 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:32:08 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:32:15 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:32:16 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:32:16 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
2023.12.15 13:32:18 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/misc.scala
Dec 15, 2023 1:34:44 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 577
Dec 15, 2023 1:35:19 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 700
2023.12.15 13:35:19 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\misc.scala
scala.meta.tokenizers.TokenizeException: <input>:10: error: unclosed string literal
        val rdd1 = sc.textFile("pat)
                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.15 13:35:20 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\misc.scala
scala.meta.tokenizers.TokenizeException: <input>:10: error: unclosed string literal
        val rdd1 = sc.textFile("p)
                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Dec 15, 2023 1:36:30 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 811
Dec 15, 2023 1:36:51 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 886
Dec 15, 2023 1:41:25 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1148
Dec 15, 2023 1:41:55 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1257
2023.12.15 13:59:18 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\misc.scala
2023.12.15 16:09:36 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SortAggandHashAgg.scala
2023.12.15 16:09:36 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SortAggandHashAgg.scala
2023.12.15 16:09:36 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SortAggandHashAgg.scala
2023.12.15 16:09:44 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala
2023.12.15 16:09:56 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala
2023.12.15 16:10:07 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/dataframes/SortAggandHashAgg.scala
Dec 15, 2023 4:11:23 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2281
Dec 15, 2023 4:11:49 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2388
Dec 15, 2023 4:21:04 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2910
2023.12.15 16:21:06 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SortAggandHashAgg.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: unclosed string literal
   val df1 = spark.read.format("csv").option("path","").option("header",true).option("load()
                                                                                     ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.15 16:21:06 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SortAggandHashAgg.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: unclosed string literal
   val df1 = spark.read.format("csv").option("path","").option("header",true).option("inload()
                                                                                     ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.15 16:21:07 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SortAggandHashAgg.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: unclosed string literal
   val df1 = spark.read.format("csv").option("path","").option("header",true).option("inferload()
                                                                                     ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.15 16:21:07 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SortAggandHashAgg.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: unclosed string literal
   val df1 = spark.read.format("csv").option("path","").option("header",true).option("inferScload()
                                                                                     ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.15 16:21:09 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SortAggandHashAgg.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: unclosed string literal
   val df1 = spark.read.format("csv").option("path","").option("header",true).option("inferScheload()
                                                                                     ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.15 16:21:09 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SortAggandHashAgg.scala
scala.meta.tokenizers.TokenizeException: <input>:17: error: unclosed string literal
   val df1 = spark.read.format("csv").option("path","").option("header",true).option("inferSchemaload()
                                                                                     ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Dec 15, 2023 4:21:25 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2989
2023.12.15 16:22:04 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SortAggandHashAgg.scala
scala.meta.tokenizers.TokenizeException: <input>:21: error: unclosed string literal
    spark.sql(" select order_customer_id, date_format("orde)")
                                                            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.15 16:22:05 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SortAggandHashAgg.scala
scala.meta.tokenizers.TokenizeException: <input>:21: error: unclosed string literal
    spark.sql(" select order_customer_id, date_format("or)")
                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Dec 15, 2023 4:22:06 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3090
2023.12.15 16:22:06 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SortAggandHashAgg.scala
scala.meta.tokenizers.TokenizeException: <input>:21: error: unclosed string literal
    spark.sql(" select order_customer_id, date_format(")")
                                                        ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.15 16:26:49 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SortAggandHashAgg.scala
scala.meta.tokenizers.TokenizeException: <input>:21: error: unclosed multi-line string literal
    spark.sql(""" select order_customer_id, date_format(order_date ,'MMMM') dt , count(1) cnt from orders group by order_customer_id , dt" +
              ^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getRawStringLit(LegacyScanner.scala:567)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:366)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.15 16:26:49 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SortAggandHashAgg.scala
scala.meta.tokenizers.TokenizeException: <input>:21: error: unclosed multi-line string literal
    spark.sql(""" select order_customer_id, date_format(order_date ,'MMMM') dt , count(1) cnt from orders group by order_customer_id , dt" +
              ^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getRawStringLit(LegacyScanner.scala:567)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:366)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Dec 15, 2023 4:36:17 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4020
Dec 15, 2023 4:36:21 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4036
Dec 15, 2023 4:36:36 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4087
2023.12.15 16:40:53 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SortAggandHashAgg.scala
Exception in thread "pool-3-thread-1" java.lang.InterruptedException
	at scala.meta.internal.metals.FutureCancelToken.checkCanceled(FutureCancelToken.scala:29)
	at scala.meta.internal.pc.CompilerAccess.onCompilerJobQueue$$anonfun$1(CompilerAccess.scala:230)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:152)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Dec 15, 2023 4:44:30 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4397
2023.12.15 16:44:35 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SortAggandHashAgg.scala
2023.12.15 17:38:12 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SortAggandHashAgg.scala
2023.12.15 21:19:17 INFO  Shutting down server
2023.12.15 21:19:17 INFO  shutting down Metals
2023.12.15 21:19:17 INFO  Exiting server
2023.12.16 15:14:51 INFO  Started: Metals version 1.2.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.1.
2023.12.16 15:14:52 WARN  Build server is not auto-connectable.
2023.12.16 15:14:52 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.12.16 15:14:52 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SortAggandHashAgg.scala
2023.12.16 15:15:00 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SortAggandHashAgg.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.12.16 15:15:04 INFO  time: code lens generation in 11s
2023.12.16 16:26:43 INFO  Shutting down server
2023.12.16 16:26:43 INFO  shutting down Metals
2023.12.16 16:26:43 INFO  Exiting server
2023.12.18 12:37:14 INFO  Started: Metals version 1.2.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.1.
2023.12.18 12:37:15 WARN  Build server is not auto-connectable.
2023.12.18 12:37:15 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.12.18 12:37:16 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SortAggandHashAgg.scala
2023.12.18 12:37:18 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_3.scala
2023.12.18 12:37:23 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SortAggandHashAgg.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.12.18 12:37:27 INFO  time: code lens generation in 11s
2023.12.18 12:37:27 INFO  time: code lens generation in 7.56s
2023.12.18 12:37:30 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week14_1.scala
2023.12.18 12:37:30 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week14_1.scala
2023.12.18 12:37:30 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week14_1.scala
2023.12.18 12:37:48 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week14_1.scala
Dec 18, 2023 12:49:31 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1263
Dec 18, 2023 12:49:59 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1413
Dec 18, 2023 12:51:45 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1786
Dec 18, 2023 12:54:10 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2342
2023.12.18 12:55:23 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week14_1.scala
Exception in thread "pool-3-thread-1" java.lang.InterruptedException
	at scala.meta.internal.metals.FutureCancelToken.checkCanceled(FutureCancelToken.scala:29)
	at scala.meta.internal.pc.CompilerAccess.onCompilerJobQueue$$anonfun$1(CompilerAccess.scala:230)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:152)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Dec 18, 2023 1:01:07 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3098
Dec 18, 2023 1:07:30 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3347
2023.12.18 13:08:47 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week14_1.scala
scala.meta.tokenizers.TokenizeException: <input>:44: error: unclosed string literal
    val dfSelect = finalDf.groupBy(to_date(col("order_date).alias(date)))
                                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.18 13:08:53 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week14_1.scala
scala.meta.tokenizers.TokenizeException: <input>:44: error: unclosed string literal
    val dfSelect = finalDf.groupBy(to_date(col("order_date").alias("date)))
                                                                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.18 13:14:45 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week14_1.scala
2023.12.18 15:12:38 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week14_1.scala
scala.meta.tokenizers.TokenizeException: <input>:55: error: unclosed string literal
    finalDF.createOrReplaceTempView("details"")
                                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Dec 18, 2023 3:15:17 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4640
2023.12.18 15:16:38 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week14_1.scala
scala.meta.tokenizers.TokenizeException: <input>:57: error: unclosed string literal
    detailsDF = spark.sql(" select cast(to_date(order_date) as String) as date, order_status, cast(sum( order_item_subtotal) as DECIMAL (10,2) as total_amount"")
                                                                                                                                                               ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.18 15:16:43 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week14_1.scala
scala.meta.tokenizers.TokenizeException: <input>:58: error: unclosed multi-line string literal
      """")
      ^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getRawStringLit(LegacyScanner.scala:567)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:366)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.18 15:16:46 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week14_1.scala
scala.meta.tokenizers.TokenizeException: <input>:58: error: unclosed multi-line string literal
      """)
      ^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getRawStringLit(LegacyScanner.scala:567)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:366)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Dec 18, 2023 3:19:23 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5154
Dec 18, 2023 3:19:29 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5181
2023.12.18 15:20:06 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week14_1.scala
2023.12.18 15:20:14 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SparkOptimization_broadcastDF.scala
2023.12.18 15:20:19 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SparkOptimization_broadcastRDD.scala
Dec 18, 2023 3:21:07 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5301
2023.12.18 15:23:07 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week14_1.scala
2023.12.18 16:53:23 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example.scala
2023.12.18 16:53:23 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:24 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:37 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:37 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:39 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:40 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:41 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:42 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:43 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:43 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:44 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:45 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:46 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:47 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:49 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:49 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:50 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:51 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:51 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:52 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:52 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:53 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:55 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:55 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:56 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:56 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:58 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:53:58 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:00 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:01 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:02 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:03 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:03 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:04 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:05 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:05 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:05 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:06 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:07 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:08 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:08 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:09 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:10 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:10 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:11 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:11 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:12 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:13 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:27 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:27 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:28 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:28 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:30 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:30 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:31 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:32 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:32 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:33 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:34 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:34 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:35 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:36 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:36 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:37 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:37 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:38 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:42 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:43 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:43 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:44 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:44 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:46 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:46 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:47 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:47 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:48 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:49 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:50 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example.scala
2023.12.18 16:54:50 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:54:50 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:55:11 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:55:12 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:55:13 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:55:14 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:55:15 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:55:15 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:55:16 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:55:17 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:55:17 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:55:18 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:55:20 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:55:21 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:55:22 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:55:27 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:55:28 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:55:29 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:55:29 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:55:30 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:55:32 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:55:35 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:55:36 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 16:55:44 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example.scala
2023.12.18 16:56:10 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week14_1.scala
2023.12.18 16:56:54 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
2023.12.18 16:56:54 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\OneDrive - Teradata\Documents\sample.txt")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.18 16:56:55 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\OneDrive - Teradata\Documents\sample.txt")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.18 16:57:03 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
2023.12.18 16:57:03 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\OneDrive - Teradata\Documents\sample.txt")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.18 16:57:03 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
2023.12.18 16:57:03 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\OneDrive - Teradata\Documents\sample.txt")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Dec 18, 2023 5:01:00 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6553
2023.12.18 17:03:24 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 17:03:25 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example.scala
2023.12.18 17:04:28 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example.scala
2023.12.18 17:08:20 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example.scala
2023.12.18 17:08:28 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example.scala
2023.12.18 17:08:35 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\OneDrive - Teradata\Documents\sample.txt")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.18 17:08:38 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\\Users\pp255070\OneDrive - Teradata\Documents\sample.txt")
                                       ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.18 17:08:40 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\\Users\\pp255070\OneDrive - Teradata\Documents\sample.txt")
                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.18 17:08:42 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\\Users\\pp255070\\OneDrive - Teradata\Documents\sample.txt")
                                                                      ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.18 17:08:44 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\\Users\\pp255070\\OneDrive - Teradata\\Documents\sample.txt")
                                                                                 ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.18 17:08:48 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
2023.12.18 18:18:02 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala
2023.12.18 18:18:20 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala
2023.12.18 18:19:20 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala
2023.12.18 19:09:41 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example.scala
2023.12.18 19:19:42 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
2023.12.18 19:19:56 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
2023.12.18 19:20:00 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala
2023.12.18 19:20:04 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2023.12.18 19:20:14 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala
2023.12.18 19:20:17 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\example.scala
2023.12.18 19:20:25 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_groupAgg.scala
2023.12.18 19:20:31 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfSimpleJoin.scala
2023.12.18 19:22:02 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
2023.12.18 19:22:11 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala
2023.12.18 19:22:18 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala
2023.12.18 19:22:25 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2023.12.18 19:22:39 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2023.12.18 19:22:43 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
2023.12.18 19:23:20 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
2023.12.18 19:23:24 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfSimpleJoin.scala
2023.12.18 19:23:35 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_groupAgg.scala
2023.12.18 19:23:52 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_simpleAgg.scala
2023.12.18 19:24:01 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
2023.12.18 19:25:35 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2023.12.18 19:25:48 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala
2023.12.18 19:25:56 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2023.12.18 19:26:06 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala
2023.12.18 19:26:09 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSqlTable.scala
2023.12.18 19:26:13 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\UDF.scala
2023.12.18 19:26:39 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
2023.12.18 19:27:35 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
scala.meta.tokenizers.TokenizeException: <input>:34: error: unclosed string interpolation
            withColumn(:new_column")
                                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.18 19:27:39 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
scala.meta.tokenizers.TokenizeException: <input>:34: error: unclosed string interpolation
            withColumn(new_column")
                                  ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.18 19:30:09 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
2023.12.18 20:20:24 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_stateless.scala
2023.12.18 20:20:32 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_stateless.scala
2023.12.18 20:20:49 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_stateful.scala
2023.12.18 20:20:49 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example_stateful.scala
2023.12.18 20:20:50 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example_stateful.scala
2023.12.18 20:21:02 WARN  Using indexes to guess the definition of spark
2023.12.18 20:21:04 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example_stateful.scala
Dec 18, 2023 8:23:42 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8249
2023.12.18 20:24:46 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_stateful.scala
Dec 18, 2023 8:35:08 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8845
2023.12.18 20:36:44 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_stateful.scala
Dec 18, 2023 8:36:44 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 9088
Dec 18, 2023 8:40:26 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 9191
Dec 18, 2023 8:40:34 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 9235
2023.12.18 20:41:02 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_stateful.scala
2023.12.18 20:41:23 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_stateful.scala
2023.12.18 20:43:27 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_stateful.scala
2023.12.18 21:07:14 INFO  Shutting down server
2023.12.18 21:07:14 INFO  shutting down Metals
2023.12.18 21:07:14 INFO  Exiting server
2023.12.19 12:17:56 INFO  Started: Metals version 1.2.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.1.
2023.12.19 12:17:58 WARN  Build server is not auto-connectable.
2023.12.19 12:17:58 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.12.19 12:17:58 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_stateful.scala
2023.12.19 12:17:58 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_stateless.scala
2023.12.19 12:18:03 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_stateful.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.12.19 12:18:07 INFO  time: code lens generation in 8.82s
2023.12.19 12:18:18 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_stateful_slidingwindow.scala
2023.12.19 12:18:18 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example_stateful_slidingwindow.scala
2023.12.19 12:18:19 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example_stateful_slidingwindow.scala
2023.12.19 12:18:41 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example_stateful_slidingwindow.scala
2023.12.19 12:19:18 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_stateful.scala
2023.12.19 12:31:12 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_stateful_slidingwindow.scala
2023.12.19 12:45:17 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_stateful_slidingwindow.scala
Exception in thread "pool-3-thread-1" java.lang.InterruptedException
	at scala.meta.internal.metals.FutureCancelToken.checkCanceled(FutureCancelToken.scala:29)
	at scala.meta.internal.pc.CompilerAccess.onCompilerJobQueue$$anonfun$1(CompilerAccess.scala:230)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:152)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Dec 19, 2023 12:46:25 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1055
2023.12.19 12:46:59 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_stateful_slidingwindow.scala
2023.12.19 12:51:06 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_reduceByWindow.scala
2023.12.19 12:51:06 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example_reduceByWindow.scala
2023.12.19 12:51:06 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example_reduceByWindow.scala
2023.12.19 12:51:15 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example_reduceByWindow.scala
2023.12.19 12:52:01 WARN  Using indexes to guess the definition of wordcounts
2023.12.19 12:54:49 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_reduceByWindow.scala
Dec 19, 2023 12:54:50 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1654
2023.12.19 12:55:04 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_reduceByWindow.scala
Dec 19, 2023 12:55:09 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1699
2023.12.19 12:55:20 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_reduceByWindow.scala
Dec 19, 2023 12:55:22 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1751
Dec 19, 2023 12:55:33 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1782
2023.12.19 12:55:48 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_reduceByWindow.scala
2023.12.19 12:58:11 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_countByWindow.scala
2023.12.19 12:58:11 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example_countByWindow.scala
2023.12.19 12:58:12 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/sparkstreaming/example_countByWindow.scala
2023.12.19 12:58:58 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_countByWindow.scala
Dec 19, 2023 1:27:18 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1984
Dec 19, 2023 1:27:18 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1982
Dec 19, 2023 1:31:02 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1985
2023.12.19 13:56:51 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_stateful.scala
2023.12.19 13:59:07 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\SortAggandHashAgg.scala
2023.12.19 13:59:09 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\misc.scala
2023.12.19 13:59:20 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
2023.12.19 13:59:35 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week15_1.scala
2023.12.19 13:59:35 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week15_1.scala
2023.12.19 13:59:35 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week15_1.scala
2023.12.19 13:59:38 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week15_1.scala
2023.12.19 13:59:42 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week15_1.scala
2023.12.19 13:59:45 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week15_1.scala
2023.12.19 13:59:46 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week15_1.scala
2023.12.19 13:59:49 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week15_1.scala
2023.12.19 13:59:52 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week15_1.scala
2023.12.19 13:59:55 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week15_1.scala
2023.12.19 13:59:59 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week15_1.scala
2023.12.19 14:00:00 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week15_1.scala
2023.12.19 14:00:01 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week15_1.scala
2023.12.19 14:00:01 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week15_1.scala
2023.12.19 14:00:06 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_stateful.scala
2023.12.19 14:00:20 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/assingment/week15_1.scala
2023.12.19 14:01:26 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week15_1.scala
scala.meta.tokenizers.TokenizeException: <input>:38: error: unclosed character literal
    val wordcounts = pairs.updateStateByKey( updatefunc ).filter( x=> x.startswith(''))   // updateStateByKey takes 2 parameters
                                                                                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.19 14:01:27 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week15_1.scala
scala.meta.tokenizers.TokenizeException: <input>:38: error: unclosed character literal
    val wordcounts = pairs.updateStateByKey( updatefunc ).filter( x=> x.startswith('big'))   // updateStateByKey takes 2 parameters
                                                                                       ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.19 14:01:37 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week15_1.scala
scala.meta.tokenizers.TokenizeException: <input>:38: error: unclosed character literal
    val wordcounts = pairs.updateStateByKey( updatefunc ).filter( x=> x.startswith(''))   // updateStateByKey takes 2 parameters
                                                                                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Dec 19, 2023 2:13:18 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2638
Dec 19, 2023 2:13:35 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2686
Dec 19, 2023 2:13:59 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2783
2023.12.19 14:14:56 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week15_1.scala
2023.12.19 17:11:22 INFO  Shutting down server
2023.12.19 17:11:22 INFO  shutting down Metals
2023.12.19 17:11:22 INFO  Exiting server
2023.12.19 17:18:05 INFO  Started: Metals version 1.2.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.1.
2023.12.19 17:18:06 WARN  Build server is not auto-connectable.
2023.12.19 17:18:06 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.12.19 17:18:06 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week15_1.scala
2023.12.19 17:18:11 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week15_1.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.12.19 17:18:14 INFO  time: code lens generation in 7.93s
2023.12.19 18:19:24 INFO  Shutting down server
2023.12.19 18:19:24 INFO  shutting down Metals
2023.12.19 18:19:24 INFO  Exiting server
2023.12.20 12:51:02 INFO  Started: Metals version 1.2.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.1.
2023.12.20 12:51:03 WARN  Build server is not auto-connectable.
2023.12.20 12:51:03 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.12.20 12:51:03 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week15_1.scala
2023.12.20 12:51:05 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala
2023.12.20 12:51:08 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week15_1.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.12.20 12:51:11 INFO  time: code lens generation in 8.67s
2023.12.20 12:51:11 INFO  time: code lens generation in 4.73s
2023.12.20 12:52:35 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_stateful_slidingwindow.scala
2023.12.20 12:53:17 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala
2023.12.20 12:53:17 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/example.scala
2023.12.20 12:53:17 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/example.scala
2023.12.20 12:53:29 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/example.scala
2023.12.20 12:53:31 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/example.scala
2023.12.20 12:53:32 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/example.scala
2023.12.20 12:53:33 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/example.scala
2023.12.20 12:53:33 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/example.scala
2023.12.20 12:53:34 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/example.scala
2023.12.20 12:54:59 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
Dec 20, 2023 12:55:01 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 138
Dec 20, 2023 12:57:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2023-12-20\r_compiler-error_12-57-25-458.md
2023.12.20 12:58:31 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\accumulator.scala
Dec 20, 2023 1:00:14 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1044
Dec 20, 2023 1:00:14 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1045
Dec 20, 2023 1:00:17 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1057
2023.12.20 13:02:29 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala
Dec 20, 2023 1:12:33 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1853
Dec 20, 2023 1:12:39 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1866
2023.12.20 13:15:15 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala
2023.12.20 13:15:37 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala
2023.12.20 13:16:02 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala
2023.12.20 13:17:37 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala
2023.12.20 13:18:12 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala
2023.12.20 13:19:24 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala
Dec 20, 2023 2:29:51 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2798
Dec 20, 2023 2:30:35 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2935
Dec 20, 2023 2:30:36 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2938
2023.12.20 14:31:25 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala
Dec 20, 2023 2:43:06 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3141
Dec 20, 2023 2:54:39 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3641
2023.12.20 14:55:25 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala
2023.12.20 15:44:24 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala
2023.12.20 15:44:38 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala
2023.12.20 16:04:01 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala
2023.12.20 16:04:29 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala
scala.meta.tokenizers.TokenizeException: <input>:23: error: invalid escape character
    val filedf = spark.readStream.format("json").option("path","C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\inputfolder").load()
                                                                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.20 16:04:32 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala
scala.meta.tokenizers.TokenizeException: <input>:23: error: invalid escape character
    val filedf = spark.readStream.format("json").option("path","C:\\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\inputfolder").load()
                                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.20 16:04:35 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala
scala.meta.tokenizers.TokenizeException: <input>:23: error: invalid escape character
    val filedf = spark.readStream.format("json").option("path","C:\\Users\\pp255070\OneDrive - Teradata\Documents\sparklearning\inputfolder").load()
                                                                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.20 16:04:39 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala
scala.meta.tokenizers.TokenizeException: <input>:23: error: invalid escape character
    val filedf = spark.readStream.format("json").option("path","C:\\Users\\pp255070\\OneDrive - Teradata\Documents\sparklearning\inputfolder").load()
                                                                                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.20 16:04:42 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala
scala.meta.tokenizers.TokenizeException: <input>:23: error: invalid escape character
    val filedf = spark.readStream.format("json").option("path","C:\\Users\\pp255070\\OneDrive - Teradata\\Documents\sparklearning\inputfolder").load()
                                                                                                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.20 16:04:49 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala
scala.meta.tokenizers.TokenizeException: <input>:23: error: invalid escape character
    val filedf = spark.readStream.format("json").option("path","C:\\Users\\pp255070\\OneDrive - Teradata\\Documents\\sparklearning\inputfolder").load()
                                                                                                                                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Dec 20, 2023 4:07:22 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4920
Dec 20, 2023 4:07:33 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4967
Dec 20, 2023 4:07:47 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5019
Dec 20, 2023 4:07:57 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5058
Dec 20, 2023 4:08:02 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5076
2023.12.20 16:13:34 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala
2023.12.20 16:13:54 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example1.scala
2023.12.20 16:13:54 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/example1.scala
2023.12.20 16:13:54 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/example1.scala
2023.12.20 16:14:13 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala
2023.12.20 16:14:15 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/example1.scala
2023.12.20 16:14:52 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala
2023.12.20 16:16:00 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example1.scala
scala.meta.tokenizers.TokenizeException: <input>:24: error: unclosed string interpolation
    spark.sql(" select * from orders eher order_status ="COMPLETED")
                                                                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.20 16:16:03 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example1.scala
scala.meta.tokenizers.TokenizeException: <input>:24: error: unclosed multi-line string interpolation
    spark.sql(" select * from orders eher order_status ="COMPLETED""")
                                                                     ^
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:27)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:26)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter.incompleteInputError$(Reporter.scala:29)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.incompleteInputError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:657)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:347)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.20 16:16:05 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example1.scala
scala.meta.tokenizers.TokenizeException: <input>:24: error: unclosed string interpolation
    spark.sql(" select * from orders eher order_status ="COMPLETED")
                                                                   ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.20 16:16:07 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example1.scala
scala.meta.tokenizers.TokenizeException: <input>:24: error: unclosed character literal
    spark.sql(" select * from orders eher order_status ="COMPLETED'")
                                                                  ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchSingleQuote$1(LegacyScanner.scala:407)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:412)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Dec 20, 2023 4:17:21 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5731
Dec 20, 2023 4:17:23 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5745
Dec 20, 2023 4:17:37 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5806
Dec 20, 2023 4:19:59 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6177
2023.12.20 16:20:20 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example1.scala
Dec 20, 2023 4:25:45 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6351
2023.12.20 16:26:08 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example1.scala
2023.12.20 16:36:52 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example1.scala
2023.12.20 16:41:58 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_reduceByWindow.scala
2023.12.20 16:42:27 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example1.scala
2023.12.20 16:42:40 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example1.scala
2023.12.20 16:49:11 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example1.scala
Dec 20, 2023 8:58:54 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6747
2023.12.20 20:59:16 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example1.scala
2023.12.20 20:59:41 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example1.scala
2023.12.20 21:58:52 INFO  Shutting down server
2023.12.20 21:58:52 INFO  shutting down Metals
2023.12.20 21:58:52 INFO  Exiting server
2023.12.21 12:31:55 INFO  Started: Metals version 1.2.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.1.
2023.12.21 12:31:58 WARN  Build server is not auto-connectable.
2023.12.21 12:31:58 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.12.21 12:31:58 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example1.scala
2023.12.21 12:32:04 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example1.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.12.21 12:32:06 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\tumbling_window.scala
2023.12.21 12:32:08 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/tumbling_window.scala
2023.12.21 12:32:08 INFO  time: code lens generation in 2.2s
2023.12.21 12:32:08 INFO  time: code lens generation in 10s
2023.12.21 12:32:18 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/tumbling_window.scala
Dec 21, 2023 12:32:53 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 74
2023.12.21 12:36:59 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\tumbling_window.scala
2023.12.21 12:40:34 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\tumbling_window.scala
Dec 21, 2023 12:43:07 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1285
Dec 21, 2023 12:43:17 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1353
Dec 21, 2023 12:43:22 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1371
Dec 21, 2023 12:43:42 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1399
Dec 21, 2023 12:43:49 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1424
2023.12.21 12:45:17 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\tumbling_window.scala
Dec 21, 2023 12:51:02 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2145
Dec 21, 2023 12:51:20 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2173
2023.12.21 12:51:32 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\tumbling_window.scala
2023.12.21 12:55:09 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\tumbling_window.scala
scala.meta.tokenizers.TokenizeException: <input>:47: error: unclosed string interpolation
    val outputdf = windowaggdf.select("window.start", window.end, totalamount")
                                                                              ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 12:55:14 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\tumbling_window.scala
scala.meta.tokenizers.TokenizeException: <input>:47: error: unclosed string interpolation
    val outputdf = windowaggdf.select("window.start", "window.end", totalamount")
                                                                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Dec 21, 2023 12:55:24 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2597
Dec 21, 2023 12:55:33 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2627
Dec 21, 2023 12:57:00 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2934
Dec 21, 2023 12:57:16 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2990
2023.12.21 13:00:07 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\tumbling_window.scala
2023.12.21 13:12:29 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example1.scala
Dec 21, 2023 1:15:25 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3409
2023.12.21 13:15:44 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\tumbling_window.scala
2023.12.21 14:55:37 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\watermark.scala
2023.12.21 14:55:37 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/watermark.scala
2023.12.21 14:55:37 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/watermark.scala
2023.12.21 14:55:43 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/watermark.scala
2023.12.21 14:57:27 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\watermark.scala
2023.12.21 15:40:59 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\tumbling_window.scala
2023.12.21 15:41:28 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\sliding_window.scala
2023.12.21 15:41:28 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/sliding_window.scala
2023.12.21 15:41:28 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/sliding_window.scala
2023.12.21 15:41:34 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\sliding_window.scala
2023.12.21 15:43:38 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\sliding_window.scala
2023.12.21 15:44:00 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\sliding_window.scala
2023.12.21 16:26:41 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerJoin.scala
2023.12.21 16:26:41 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/innerJoin.scala
2023.12.21 16:26:42 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/innerJoin.scala
Dec 21, 2023 4:27:05 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4228
2023.12.21 16:29:09 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerJoin.scala
2023.12.21 16:29:41 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerJoin.scala
Dec 21, 2023 4:30:24 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4809
2023.12.21 16:30:32 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerJoin.scala
2023.12.21 16:30:32 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerJoin.scala
Dec 21, 2023 4:31:02 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4945
Dec 21, 2023 4:32:33 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5289
2023.12.21 16:32:49 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerJoin.scala
Dec 21, 2023 4:33:25 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5386
2023.12.21 16:33:36 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerJoin.scala
2023.12.21 16:34:45 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerJoin.scala
2023.12.21 16:34:53 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerJoin.scala
2023.12.21 16:37:26 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerJoin.scala
scala.meta.tokenizers.TokenizeException: <input>:55: error: unclosed string literal
    .option("checkpointlocation
            ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 16:37:38 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerJoin.scala
scala.meta.tokenizers.TokenizeException: <input>:55: error: unclosed string interpolation
    .option("checkpointlocation" , check-pointdir"
                                                  ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 16:39:15 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerJoin.scala
2023.12.21 16:39:31 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerJoin.scala
2023.12.21 17:30:05 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\leftouterJoin.scala
2023.12.21 17:30:05 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/leftouterJoin.scala
2023.12.21 17:30:05 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/leftouterJoin.scala
2023.12.21 17:31:50 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\leftouterJoin.scala
2023.12.21 17:32:14 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\rightouterjoin.scala
2023.12.21 17:32:14 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/rightouterjoin.scala
2023.12.21 17:32:15 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/rightouterjoin.scala
2023.12.21 17:32:36 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerJoin.scala
2023.12.21 17:32:38 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\leftouterJoin.scala
2023.12.21 17:32:40 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\rightouterjoin.scala
Dec 21, 2023 5:32:49 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6690
Dec 21, 2023 5:33:18 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6759
2023.12.21 17:33:25 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\rightouterjoin.scala
2023.12.21 18:34:55 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala
2023.12.21 18:34:55 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/innerjoin_streamtostream.scala
2023.12.21 18:34:56 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/innerjoin_streamtostream.scala
2023.12.21 18:35:11 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/innerjoin_streamtostream.scala
Dec 21, 2023 6:35:22 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6828
2023.12.21 18:35:22 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\watermark.scala
Dec 21, 2023 6:35:36 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6880
Dec 21, 2023 6:39:27 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 7809
2023.12.21 18:39:59 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala
2023.12.21 18:42:18 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala
Dec 21, 2023 6:43:54 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8533
Dec 21, 2023 6:44:52 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8707
2023.12.21 18:45:15 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala
2023.12.21 18:45:15 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala
Dec 21, 2023 6:45:50 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8933
Dec 21, 2023 6:48:05 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 9375
Dec 21, 2023 6:48:26 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 9437
2023.12.21 18:48:42 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala
Dec 21, 2023 9:44:25 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 9534
Dec 21, 2023 9:46:59 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 9812
2023.12.21 21:47:06 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala
2023.12.21 21:49:37 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
2023.12.21 21:49:37 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/left/rightouterjoin_streamtostream.scala
2023.12.21 21:49:38 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/SparkStructuredStreaming/left/rightouterjoin_streamtostream.scala
Dec 21, 2023 9:53:07 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 9905
Dec 21, 2023 9:53:34 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 9965
2023.12.21 21:53:41 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime ) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:53:47 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime be) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:53:48 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime betw) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:53:48 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime betwee) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:53:49 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:53:50 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between I) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:53:50 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between Im) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:53:52 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between Imp) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:53:52 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between Impres) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:53:53 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between Impressi) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:53:54 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between Impression) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:53:56 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionT) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:53:56 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTi) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:53:57 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:06 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime ) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:06 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime an) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:07 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime an ) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:09 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime and) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:09 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime and ) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:10 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime and Im) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:11 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime and Imp) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:12 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime and Impre) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:12 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime and Impressi) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:13 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime and Impression) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:15 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime and ImpressionTi) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:15 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime and ImpressionTime) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:16 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime and ImpressionTime ) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:19 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime and ImpressionTime + ) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:20 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime and ImpressionTime + in) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:20 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime and ImpressionTime + inte) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:21 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime and ImpressionTime + interv) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:21 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime and ImpressionTime + interva) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:22 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime and ImpressionTime + interval) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:26 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime and ImpressionTime + interval ) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:27 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime and ImpressionTime + interval 15) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:27 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime and ImpressionTime + interval 15 m) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:28 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime and ImpressionTime + interval 15 min) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:29 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime and ImpressionTime + interval 15 minut) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:29 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime and ImpressionTime + interval 15 minute) 
                             ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:30 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime and ImpressionTime + interval 15 minute "") 
                                                                                                                                      ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.21 21:54:33 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:43: error: unclosed string literal
    val joincondition = expr("impression_id == click_id AND ClickTime between ImpressionTime and ImpressionTime + interval 15 minute "" 
                                                                                                                                      ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:553)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Dec 21, 2023 9:54:52 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 10179
2023.12.21 21:57:15 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
2023.12.21 21:57:28 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala
2023.12.21 21:57:36 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala
2023.12.21 22:00:17 INFO  Shutting down server
2023.12.21 22:00:17 INFO  shutting down Metals
2023.12.21 22:00:17 INFO  Exiting server
2023.12.22 11:02:38 INFO  Started: Metals version 1.2.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.1.
2023.12.22 11:02:40 WARN  Build server is not auto-connectable.
2023.12.22 11:02:40 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.12.22 11:02:41 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala
2023.12.22 11:02:45 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\left\rightouterjoin_streamtostream.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.12.22 11:02:48 INFO  time: code lens generation in 7.88s
2023.12.22 11:14:31 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\leftouterJoin.scala
2023.12.22 11:14:45 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\rightouterjoin_streamtostream.scala
2023.12.22 11:15:04 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\leftrightouterjoin_streamtostream.scala
2023.12.22 11:15:19 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\leftrightouterjoin_streamtostream.scala
2023.12.22 11:16:06 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\leftrightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:50: error: unclosed string interpolation
    outputMode("option("checkpointlocation", "check_dir").trigger(Trigger.ProcessingTime("15 second")).start()
                                                                                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Dec 22, 2023 11:16:08 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 133
2023.12.22 11:16:08 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\leftrightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:50: error: unclosed string interpolation
    outputMode("apoption("checkpointlocation", "check_dir").trigger(Trigger.ProcessingTime("15 second")).start()
                                                                                                      ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.22 11:16:08 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\leftrightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:50: error: unclosed string interpolation
    outputMode("appenoption("checkpointlocation", "check_dir").trigger(Trigger.ProcessingTime("15 second")).start()
                                                                                                         ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.22 11:16:09 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\leftrightouterjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:50: error: unclosed string interpolation
    outputMode("appendoption("checkpointlocation", "check_dir").trigger(Trigger.ProcessingTime("15 second")).start()
                                                                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.22 11:16:14 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\leftrightouterjoin_streamtostream.scala
2023.12.22 11:16:25 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala
2023.12.22 11:16:41 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:50: error: unclosed string interpolation
    outputMode("option("checkpointlocation", "check_dir").trigger(Trigger.ProcessingTime("15 second")).start()
                                                                                                    ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.22 11:16:42 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:50: error: unclosed string interpolation
    outputMode("appoption("checkpointlocation", "check_dir").trigger(Trigger.ProcessingTime("15 second")).start()
                                                                                                       ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.22 11:16:43 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala
scala.meta.tokenizers.TokenizeException: <input>:50: error: unclosed string interpolation
    outputMode("appendoption("checkpointlocation", "check_dir").trigger(Trigger.ProcessingTime("15 second")).start()
                                                                                                          ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringPart(LegacyScanner.scala:659)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:357)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.22 11:16:50 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala
2023.12.22 11:18:49 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\leftrightouterjoin_streamtostream.scala
2023.12.22 11:18:52 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\leftrightouterjoin_streamtostream.scala
2023.12.22 11:18:53 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\leftrightouterjoin_streamtostream.scala
2023.12.22 11:19:29 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\leftrightouterjoin_streamtostream.scala
2023.12.22 11:24:19 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\leftrightouterjoin_streamtostream.scala
2023.12.22 17:17:39 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\watermark.scala
2023.12.22 17:21:21 INFO  
2023.12.22 17:21:21 INFO  Template applied in C:\Users\pp255070\OneDrive - Teradata\Documents\scala\.\hello-world
2023.12.22 17:21:21 INFO  
2023.12.22 17:21:21 INFO  time: ran 'giter8.Giter8' in 3.18s
2023.12.22 17:24:41 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala
2023.12.22 17:24:48 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\ratings.scala
2023.12.22 17:24:52 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\salting.scala
2023.12.22 17:24:53 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\misc.scala
2023.12.22 17:24:54 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\linkedin.scala
2023.12.22 17:24:57 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\filter.scala
2023.12.22 17:25:00 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\customer.scala
2023.12.22 17:25:00 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\customer.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.22 17:25:01 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\customer.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.22 17:26:30 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\linkedin.scala
2023.12.22 17:26:32 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\salting.scala
2023.12.22 17:26:33 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\ratings.scala
2023.12.22 17:26:35 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala
2023.12.22 17:26:46 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad3_join.scala
2023.12.22 17:26:48 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad2.scala
2023.12.22 17:26:50 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad1.scala
2023.12.22 18:31:11 INFO  Shutting down server
2023.12.22 18:31:11 INFO  shutting down Metals
2023.12.22 18:31:11 INFO  Exiting server
2023.12.28 18:07:13 INFO  Started: Metals version 1.2.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.1.
2023.12.28 18:07:14 WARN  Build server is not auto-connectable.
2023.12.28 18:07:14 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2023.12.28 18:07:14 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad1.scala
2023.12.28 18:07:17 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\sparkad1.scala. Using presentation compiler with project's scala-library version: 3.3.1
2023.12.28 18:07:19 INFO  time: code lens generation in 4.86s
2023.12.28 18:07:44 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\watermark.scala
2023.12.28 18:07:49 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\rightouterjoin.scala
2023.12.28 18:07:51 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerJoin.scala
2023.12.28 18:07:54 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\sliding_window.scala
2023.12.28 18:09:17 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala
2023.12.28 18:10:21 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\salting.scala
2023.12.28 18:10:34 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\broadcast.scala
Dec 28, 2023 6:10:37 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 82
2023.12.28 18:10:46 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\customer.scala
2023.12.28 18:10:46 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\customer.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.28 18:10:47 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\customer.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2023.12.28 18:10:48 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\cache_persist.scala
2023.12.28 18:11:02 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala
2023.12.28 18:11:27 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2023.12.28 18:12:39 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2023.12.28 18:12:52 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
2023.12.28 18:14:25 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
2023.12.28 18:14:28 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_3.scala
2023.12.28 18:16:06 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_1.scala
2023.12.28 18:16:13 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
2023.12.28 18:17:09 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
2023.12.28 18:18:51 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
2023.12.28 18:51:31 INFO  Shutting down server
2023.12.28 18:51:31 INFO  shutting down Metals
2023.12.28 18:51:31 INFO  Exiting server
2024.01.04 13:09:01 INFO  Started: Metals version 1.2.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.1.
2024.01.04 13:09:04 WARN  Build server is not auto-connectable.
2024.01.04 13:09:04 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala
2024.01.04 13:09:04 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.01.04 13:09:10 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\assingment\week12_2.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.01.04 13:09:15 INFO  time: code lens generation in 10s
2024.01.04 13:58:02 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\amazon\word.scala
2024.01.04 13:58:02 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/amazon/word.scala
2024.01.04 13:58:03 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/amazon/word.scala
2024.01.04 13:58:05 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/amazon/word.scala
2024.01.04 13:58:05 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/amazon/word.scala
2024.01.04 13:58:06 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/amazon/word.scala
2024.01.04 13:58:07 WARN  Could not find semantic tokens for: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/amazon/word.scala
2024.01.04 14:00:05 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\amazon\word.scala
2024.01.04 14:00:17 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\amazon\word.scala
Jan 04, 2024 2:00:57 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 251
Jan 04, 2024 2:00:57 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 252
Jan 04, 2024 2:02:19 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 545
2024.01.04 14:05:05 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\amazon\word.scala
2024.01.04 14:05:26 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\amazon\word.scala
2024.01.04 14:05:46 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\amazon\word.scala
Jan 04, 2024 2:06:42 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1096
2024.01.04 14:06:54 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\amazon\word.scala
2024.01.04 22:29:39 INFO  Shutting down server
2024.01.04 22:29:39 INFO  shutting down Metals
2024.01.04 22:29:39 INFO  Exiting server
2024.01.10 17:33:23 INFO  Started: Metals version 1.2.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.1.
2024.01.10 17:33:25 WARN  Build server is not auto-connectable.
2024.01.10 17:33:25 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.01.10 17:33:25 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\amazon\word.scala
2024.01.10 17:33:37 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\amazon\word.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.01.10 17:33:41 INFO  time: code lens generation in 12s
2024.01.10 17:34:29 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala
Jan 10, 2024 5:34:44 PM org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
2024.01.10 22:08:10 INFO  Shutting down server
2024.01.10 22:08:10 INFO  shutting down Metals
2024.01.10 22:08:10 INFO  Exiting server
2024.01.11 11:44:42 INFO  Started: Metals version 1.2.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.1.
2024.01.11 11:44:45 WARN  Build server is not auto-connectable.
2024.01.11 11:44:45 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.01.11 11:44:45 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala
2024.01.11 11:44:52 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.01.11 11:44:57 INFO  time: code lens generation in 11s
Jan 11, 2024 12:22:58 PM org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
2024.01.11 22:02:56 INFO  Shutting down server
2024.01.11 22:02:56 INFO  shutting down Metals
2024.01.11 22:02:56 INFO  Exiting server
2024.01.13 16:17:56 INFO  Started: Metals version 1.2.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.1.
2024.01.13 16:17:57 WARN  Build server is not auto-connectable.
2024.01.13 16:17:57 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.01.13 16:17:57 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala
2024.01.13 16:18:03 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.01.13 16:18:05 INFO  time: code lens generation in 7.6s
Jan 13, 2024 4:23:30 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 20
2024.01.13 16:25:01 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala
2024.01.13 16:25:17 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala
2024.01.13 16:25:34 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example1.scala
2024.01.13 16:25:53 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerJoin.scala
Jan 13, 2024 4:25:59 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 82
2024.01.13 16:26:24 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\leftouterJoin.scala
2024.01.13 16:26:36 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\leftrightouterjoin_streamtostream.scala
Jan 13, 2024 4:26:42 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 104
2024.01.13 16:27:01 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerJoin.scala
Jan 13, 2024 4:27:30 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 213
Jan 13, 2024 4:27:45 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 259
2024.01.13 16:28:15 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerJoin.scala
2024.01.13 16:28:37 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala
2024.01.13 16:28:38 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\leftouterJoin.scala
Jan 13, 2024 4:29:18 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 385
2024.01.13 16:29:29 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\leftouterJoin.scala
2024.01.13 16:29:40 INFO  Shutting down server
2024.01.13 16:29:40 INFO  shutting down Metals
2024.01.13 16:29:40 INFO  Exiting server
2024.01.15 11:24:53 INFO  Started: Metals version 1.2.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.1.
2024.01.15 11:24:56 WARN  Build server is not auto-connectable.
2024.01.15 11:24:56 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.01.15 11:24:56 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala
2024.01.15 11:25:02 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.01.15 11:25:06 INFO  time: code lens generation in 10s
2024.01.15 21:58:06 INFO  Shutting down server
2024.01.15 21:58:06 INFO  shutting down Metals
2024.01.15 21:58:06 INFO  Exiting server
2024.01.16 10:57:29 INFO  Started: Metals version 1.2.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.1.
2024.01.16 10:57:31 WARN  Build server is not auto-connectable.
2024.01.16 10:57:31 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.01.16 10:57:32 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala
2024.01.16 10:57:37 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.01.16 10:57:41 INFO  time: code lens generation in 9.17s
2024.01.16 21:21:06 INFO  Shutting down server
2024.01.16 21:21:06 INFO  shutting down Metals
2024.01.16 21:21:06 INFO  Exiting server
2024.01.17 16:48:14 INFO  Started: Metals version 1.2.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.1.
2024.01.17 16:48:15 WARN  Build server is not auto-connectable.
2024.01.17 16:48:15 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.01.17 16:48:15 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala
2024.01.17 16:48:18 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.01.17 16:48:24 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\example.scala
2024.01.17 16:49:02 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala
2024.01.17 16:49:15 INFO  Shutting down server
2024.01.17 16:49:15 INFO  shutting down Metals
2024.01.17 16:49:15 INFO  Exiting server
2024.01.18 14:58:24 INFO  Started: Metals version 1.2.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.1.
2024.01.18 14:58:25 WARN  Build server is not auto-connectable.
2024.01.18 14:58:25 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.01.18 14:58:25 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala
2024.01.18 14:58:28 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.01.18 14:58:30 INFO  time: code lens generation in 4.52s
2024.01.18 14:58:33 INFO  Shutting down server
2024.01.18 14:58:33 INFO  shutting down Metals
2024.01.18 14:58:33 INFO  Exiting server
2024.01.24 11:41:55 INFO  Started: Metals version 1.2.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.2.
2024.01.24 11:41:57 WARN  Build server is not auto-connectable.
2024.01.24 11:41:57 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.01.24 11:41:57 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala
2024.01.24 11:42:02 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.01.24 11:42:04 INFO  time: code lens generation in 7.47s
2024.01.24 11:44:04 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\MyProduce.java
Jan 24, 2024 11:44:04 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-44-04-235.md
2024.01.24 11:44:04 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProduce.java. Output:

Jan 24, 2024 11:44:04 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-44-04-819.md
Jan 24, 2024 11:45:09 AM org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
Jan 24, 2024 11:45:10 AM org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
Jan 24, 2024 11:45:14 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-45-14-316.md
Jan 24, 2024 11:45:19 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-45-19-183.md
Jan 24, 2024 11:45:37 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-45-37-351.md
2024.01.24 11:46:42 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\MyProducer.java
Jan 24, 2024 11:46:42 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-46-42-870.md
2024.01.24 11:46:42 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:46:43 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-46-43-402.md
Jan 24, 2024 11:46:50 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-46-50-160.md
Jan 24, 2024 11:46:50 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-46-50-363.md
Jan 24, 2024 11:46:50 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-46-50-864.md
2024.01.24 11:46:50 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:46:51 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-46-51-495.md
2024.01.24 11:46:50 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:46:51 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:46:52 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-46-52-079.md
Jan 24, 2024 11:46:52 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-46-52-506.md
Jan 24, 2024 11:46:52 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-46-52-927.md
2024.01.24 11:46:53 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:46:53 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-46-53-544.md
Jan 24, 2024 11:46:53 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-46-53-710.md
Jan 24, 2024 11:46:54 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-46-54-139.md
Jan 24, 2024 11:46:54 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-46-54-188.md
Jan 24, 2024 11:46:54 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 57
Jan 24, 2024 11:46:54 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-46-54-475.md
Jan 24, 2024 11:46:54 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-46-54-608.md
2024.01.24 11:46:54 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:46:54 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-46-54-918.md
Jan 24, 2024 11:46:55 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-46-55-111.md
Jan 24, 2024 11:46:55 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-46-55-336.md
2024.01.24 11:46:54 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:46:57 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-46-57-006.md
2024.01.24 11:46:57 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:46:57 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-46-57-364.md
Jan 24, 2024 11:46:59 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-46-59-936.md
Jan 24, 2024 11:47:00 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-00-120.md
Jan 24, 2024 11:47:00 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-00-367.md
Jan 24, 2024 11:47:00 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-00-460.md
2024.01.24 11:47:00 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:47:00 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-00-913.md
Jan 24, 2024 11:47:01 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-01-037.md
Jan 24, 2024 11:47:01 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-01-290.md
2024.01.24 11:47:01 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:47:20 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-20-970.md
Jan 24, 2024 11:47:21 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-21-275.md
Jan 24, 2024 11:47:21 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-21-388.md
Jan 24, 2024 11:47:21 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-21-444.md
Jan 24, 2024 11:47:21 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-21-641.md
Jan 24, 2024 11:47:21 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-21-974.md
Jan 24, 2024 11:47:22 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-22-098.md
Jan 24, 2024 11:47:22 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-22-160.md
Jan 24, 2024 11:47:22 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-22-418.md
Jan 24, 2024 11:47:22 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-22-596.md
Jan 24, 2024 11:47:22 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-22-652.md
2024.01.24 11:47:22 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:47:23 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-23-076.md
Jan 24, 2024 11:47:24 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-24-390.md
2024.01.24 11:47:24 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:47:24 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-24-767.md
Jan 24, 2024 11:47:25 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-25-015.md
Jan 24, 2024 11:47:25 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-25-248.md
Jan 24, 2024 11:47:25 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-25-414.md
Jan 24, 2024 11:47:25 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-25-470.md
Jan 24, 2024 11:47:25 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-25-712.md
Jan 24, 2024 11:47:26 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-26-006.md
Jan 24, 2024 11:47:26 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-26-094.md
Jan 24, 2024 11:47:26 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-26-232.md
Jan 24, 2024 11:47:26 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-26-470.md
Jan 24, 2024 11:47:26 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-26-660.md
Jan 24, 2024 11:47:26 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-26-777.md
2024.01.24 11:47:27 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:47:27 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-27-192.md
Jan 24, 2024 11:47:27 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-27-965.md
2024.01.24 11:47:28 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:47:28 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-28-445.md
Jan 24, 2024 11:47:28 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-28-883.md
Jan 24, 2024 11:47:29 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-29-312.md
2024.01.24 11:47:29 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:47:29 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-29-795.md
Jan 24, 2024 11:47:30 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-30-309.md
2024.01.24 11:47:30 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:47:30 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-30-790.md
2024.01.24 11:47:30 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:47:31 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-31-158.md
Jan 24, 2024 11:47:31 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-31-216.md
Jan 24, 2024 11:47:31 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-31-291.md
Jan 24, 2024 11:47:31 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-31-624.md
Jan 24, 2024 11:47:31 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-31-810.md
Jan 24, 2024 11:47:31 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-31-900.md
Jan 24, 2024 11:47:32 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-32-131.md
Jan 24, 2024 11:47:32 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 176
Jan 24, 2024 11:47:32 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-32-337.md
Jan 24, 2024 11:47:32 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-32-398.md
Jan 24, 2024 11:47:32 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-32-727.md
Jan 24, 2024 11:47:32 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-32-809.md
2024.01.24 11:47:33 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:47:34 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:47:34 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-34-620.md
Jan 24, 2024 11:47:35 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-35-833.md
2024.01.24 11:47:36 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:47:57 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:47:57 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-57-322.md
Jan 24, 2024 11:47:57 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-57-532.md
Jan 24, 2024 11:47:57 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-57-965.md
2024.01.24 11:47:58 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:47:58 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-47-58-501.md
2024.01.24 11:48:00 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:00 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-00-402.md
2024.01.24 11:48:01 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:01 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-01-174.md
Jan 24, 2024 11:48:01 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-01-219.md
Jan 24, 2024 11:48:01 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-01-934.md
2024.01.24 11:48:02 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:02 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-02-595.md
Jan 24, 2024 11:48:03 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-02-996.md
Jan 24, 2024 11:48:03 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-03-047.md
Jan 24, 2024 11:48:03 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-03-794.md
2024.01.24 11:48:04 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:04 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-04-327.md
Jan 24, 2024 11:48:06 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-06-628.md
2024.01.24 11:48:06 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:07 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-07-078.md
Jan 24, 2024 11:48:08 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-08-238.md
Jan 24, 2024 11:48:08 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-08-683.md
2024.01.24 11:48:09 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:09 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-09-783.md
Jan 24, 2024 11:48:09 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-09-827.md
Jan 24, 2024 11:48:10 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-10-142.md
Jan 24, 2024 11:48:10 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-10-222.md
Jan 24, 2024 11:48:10 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-10-365.md
2024.01.24 11:48:10 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:10 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-10-797.md
Jan 24, 2024 11:48:10 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-10-982.md
Jan 24, 2024 11:48:11 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-11-097.md
Jan 24, 2024 11:48:11 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-11-354.md
Jan 24, 2024 11:48:11 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-11-398.md
Jan 24, 2024 11:48:11 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-11-666.md
2024.01.24 11:48:12 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:12 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-12-092.md
Jan 24, 2024 11:48:13 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-13-295.md
2024.01.24 11:48:13 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:13 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-13-802.md
Jan 24, 2024 11:48:13 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-13-961.md
Jan 24, 2024 11:48:14 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-14-201.md
Jan 24, 2024 11:48:14 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-14-402.md
Jan 24, 2024 11:48:14 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-14-587.md
2024.01.24 11:48:14 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:15 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-15-022.md
Jan 24, 2024 11:48:15 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-15-182.md
Jan 24, 2024 11:48:15 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-15-432.md
Jan 24, 2024 11:48:15 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-15-671.md
Jan 24, 2024 11:48:15 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-15-714.md
Jan 24, 2024 11:48:15 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-15-881.md
Jan 24, 2024 11:48:16 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-16-233.md
Jan 24, 2024 11:48:16 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-16-319.md
Jan 24, 2024 11:48:16 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-16-608.md
Jan 24, 2024 11:48:16 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-16-834.md
Jan 24, 2024 11:48:17 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-17-043.md
2024.01.24 11:48:17 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:17 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-17-352.md
Jan 24, 2024 11:48:17 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-17-553.md
Jan 24, 2024 11:48:17 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-17-789.md
Jan 24, 2024 11:48:17 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-17-868.md
2024.01.24 11:48:18 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:18 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-18-364.md
Jan 24, 2024 11:48:20 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-20-273.md
2024.01.24 11:48:20 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:20 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-20-717.md
Jan 24, 2024 11:48:20 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-20-765.md
Jan 24, 2024 11:48:20 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-20-957.md
Jan 24, 2024 11:48:21 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-21-229.md
Jan 24, 2024 11:48:21 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-21-473.md
Jan 24, 2024 11:48:21 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-21-526.md
Jan 24, 2024 11:48:21 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-21-799.md
Jan 24, 2024 11:48:21 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-21-922.md
Jan 24, 2024 11:48:22 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-22-093.md
Jan 24, 2024 11:48:22 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-22-299.md
Jan 24, 2024 11:48:22 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-22-555.md
2024.01.24 11:48:22 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:23 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-23-168.md
Jan 24, 2024 11:48:23 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-23-380.md
Jan 24, 2024 11:48:23 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-23-562.md
2024.01.24 11:48:23 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:30 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-30-391.md
2024.01.24 11:48:30 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:30 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-30-859.md
Jan 24, 2024 11:48:31 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-31-004.md
Jan 24, 2024 11:48:31 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-31-206.md
Jan 24, 2024 11:48:31 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-31-390.md
Jan 24, 2024 11:48:31 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-31-479.md
Jan 24, 2024 11:48:31 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-31-627.md
Jan 24, 2024 11:48:31 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-31-832.md
Jan 24, 2024 11:48:32 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-32-077.md
2024.01.24 11:48:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:32 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-32-244.md
Jan 24, 2024 11:48:32 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-32-541.md
Jan 24, 2024 11:48:32 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-32-682.md
2024.01.24 11:48:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:48:35 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:36 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-36-117.md
2024.01.24 11:48:39 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:39 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-39-950.md
Jan 24, 2024 11:48:41 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-41-892.md
Jan 24, 2024 11:48:42 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-42-325.md
Jan 24, 2024 11:48:42 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-42-900.md
Jan 24, 2024 11:48:44 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-44-355.md
Jan 24, 2024 11:48:44 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-44-809.md
2024.01.24 11:48:45 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:45 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-45-372.md
2024.01.24 11:48:45 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:48 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-48-007.md
2024.01.24 11:48:48 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:48 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-48-396.md
Jan 24, 2024 11:48:49 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-49-051.md
2024.01.24 11:48:48 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:49 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-49-824.md
2024.01.24 11:48:50 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:50 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-50-372.md
Jan 24, 2024 11:48:52 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-52-417.md
2024.01.24 11:48:54 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:54 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-54-775.md
Jan 24, 2024 11:48:54 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-54-830.md
Jan 24, 2024 11:48:55 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-55-188.md
Jan 24, 2024 11:48:55 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-55-763.md
Jan 24, 2024 11:48:56 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-56-356.md
2024.01.24 11:48:56 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:48:56 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:57 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-57-009.md
Jan 24, 2024 11:48:57 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-57-299.md
Jan 24, 2024 11:48:57 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-57-731.md
2024.01.24 11:48:58 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:58 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-58-379.md
Jan 24, 2024 11:48:58 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-58-427.md
2024.01.24 11:48:58 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:48:58 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-58-822.md
Jan 24, 2024 11:48:59 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-48-59-323.md
2024.01.24 11:48:59 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:49:00 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:00 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-00-190.md
2024.01.24 11:49:00 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:00 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-00-703.md
Jan 24, 2024 11:49:01 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-01-165.md
Jan 24, 2024 11:49:01 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-01-626.md
Jan 24, 2024 11:49:02 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-02-428.md
Jan 24, 2024 11:49:03 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-03-025.md
2024.01.24 11:49:03 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:03 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-03-857.md
2024.01.24 11:49:04 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:04 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-04-341.md
2024.01.24 11:49:06 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:06 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-06-431.md
Jan 24, 2024 11:49:12 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-12-746.md
2024.01.24 11:49:12 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:16 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-16-785.md
Jan 24, 2024 11:49:17 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-17-229.md
2024.01.24 11:49:17 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:17 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-17-707.md
Jan 24, 2024 11:49:18 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-18-328.md
2024.01.24 11:49:18 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:19 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-19-012.md
Jan 24, 2024 11:49:19 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-19-055.md
2024.01.24 11:49:19 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:19 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-19-535.md
2024.01.24 11:49:19 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:20 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-20-020.md
Jan 24, 2024 11:49:20 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-20-878.md
2024.01.24 11:49:21 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:21 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-21-412.md
Jan 24, 2024 11:49:22 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-22-091.md
2024.01.24 11:49:22 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:22 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-22-514.md
Jan 24, 2024 11:49:23 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-23-714.md
2024.01.24 11:49:24 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:24 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-24-161.md
Jan 24, 2024 11:49:25 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-25-401.md
Jan 24, 2024 11:49:25 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-25-715.md
Jan 24, 2024 11:49:25 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-25-801.md
Jan 24, 2024 11:49:25 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-25-899.md
2024.01.24 11:49:26 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:26 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-26-293.md
Jan 24, 2024 11:49:26 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-26-341.md
Jan 24, 2024 11:49:26 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-26-502.md
Jan 24, 2024 11:49:26 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-26-734.md
Jan 24, 2024 11:49:27 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-27-017.md
Jan 24, 2024 11:49:27 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-27-069.md
Jan 24, 2024 11:49:27 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-27-371.md
Jan 24, 2024 11:49:27 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-27-495.md
2024.01.24 11:49:27 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:49:29 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:29 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-29-560.md
2024.01.24 11:49:30 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:30 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-30-538.md
2024.01.24 11:49:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:32 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-32-402.md
2024.01.24 11:49:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:33 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-33-156.md
2024.01.24 11:49:34 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:34 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-34-297.md
2024.01.24 11:49:36 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:36 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-36-285.md
2024.01.24 11:49:36 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:37 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-37-074.md
Jan 24, 2024 11:49:38 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-38-563.md
Jan 24, 2024 11:49:39 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-39-010.md
2024.01.24 11:49:39 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:39 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-39-559.md
Jan 24, 2024 11:49:40 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-40-164.md
Jan 24, 2024 11:49:40 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-40-446.md
Jan 24, 2024 11:49:40 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-40-652.md
Jan 24, 2024 11:49:41 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-41-221.md
2024.01.24 11:49:41 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:41 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-41-994.md
2024.01.24 11:49:42 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:42 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-42-518.md
Jan 24, 2024 11:49:42 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-42-561.md
2024.01.24 11:49:43 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:43 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-43-145.md
Jan 24, 2024 11:49:43 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-43-677.md
Jan 24, 2024 11:49:44 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-44-152.md
2024.01.24 11:49:44 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:44 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-44-746.md
Jan 24, 2024 11:49:46 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-46-333.md
Jan 24, 2024 11:49:46 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-46-516.md
Jan 24, 2024 11:49:46 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-46-651.md
Jan 24, 2024 11:49:46 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-46-775.md
Jan 24, 2024 11:49:46 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 658
Jan 24, 2024 11:49:46 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-46-912.md
2024.01.24 11:49:47 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:47 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-47-351.md
2024.01.24 11:49:48 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:48 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-48-957.md
Jan 24, 2024 11:49:49 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-49-356.md
Jan 24, 2024 11:49:49 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-49-800.md
2024.01.24 11:49:49 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:53 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-53-501.md
2024.01.24 11:49:53 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:49:54 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:55 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-55-067.md
Jan 24, 2024 11:49:57 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-57-143.md
2024.01.24 11:49:57 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:49:59 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-59-558.md
Jan 24, 2024 11:49:59 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-59-877.md
Jan 24, 2024 11:49:59 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-49-59-972.md
Jan 24, 2024 11:50:00 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-00-083.md
2024.01.24 11:50:00 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:00 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-00-531.md
Jan 24, 2024 11:50:00 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-00-632.md
2024.01.24 11:50:00 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:01 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-01-144.md
2024.01.24 11:50:12 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:12 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-12-192.md
2024.01.24 11:50:17 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:17 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-17-455.md
2024.01.24 11:50:17 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:17 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-17-981.md
2024.01.24 11:50:18 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:18 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-18-423.md
2024.01.24 11:50:18 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:18 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-18-948.md
2024.01.24 11:50:22 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:22 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-22-082.md
2024.01.24 11:50:24 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:25 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-25-148.md
2024.01.24 11:50:26 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:26 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-26-729.md
Jan 24, 2024 11:50:33 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-33-362.md
2024.01.24 11:50:33 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:34 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-34-444.md
2024.01.24 11:50:34 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:35 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-35-339.md
2024.01.24 11:50:35 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:36 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-35-997.md
2024.01.24 11:50:36 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:36 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-36-867.md
2024.01.24 11:50:37 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:37 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-37-545.md
Jan 24, 2024 11:50:38 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-38-303.md
Jan 24, 2024 11:50:38 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-38-824.md
Jan 24, 2024 11:50:39 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-39-416.md
Jan 24, 2024 11:50:39 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-39-912.md
Jan 24, 2024 11:50:39 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 791
Jan 24, 2024 11:50:40 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-40-431.md
Jan 24, 2024 11:50:41 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-41-037.md
2024.01.24 11:50:41 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:42 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-42-492.md
2024.01.24 11:50:42 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:50:45 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:45 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-45-673.md
Jan 24, 2024 11:50:46 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-46-753.md
2024.01.24 11:50:46 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:47 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-47-457.md
Jan 24, 2024 11:50:48 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-48-049.md
2024.01.24 11:50:48 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:50:48 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:49 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-49-024.md
2024.01.24 11:50:49 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:49 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-49-712.md
2024.01.24 11:50:50 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:50 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-50-619.md
Jan 24, 2024 11:50:51 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-51-027.md
Jan 24, 2024 11:50:51 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-51-498.md
Jan 24, 2024 11:50:51 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-51-990.md
2024.01.24 11:50:52 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:52 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-52-626.md
2024.01.24 11:50:52 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:53 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-53-573.md
Jan 24, 2024 11:50:53 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-53-991.md
Jan 24, 2024 11:50:54 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-54-593.md
2024.01.24 11:50:54 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:50:55 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:55 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-55-481.md
Jan 24, 2024 11:50:57 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-57-416.md
2024.01.24 11:50:57 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:57 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-57-843.md
2024.01.24 11:50:58 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:50:58 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-58-496.md
Jan 24, 2024 11:50:59 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-59-038.md
Jan 24, 2024 11:50:59 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-50-59-775.md
2024.01.24 11:51:00 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:51:00 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-00-512.md
Jan 24, 2024 11:51:01 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-01-485.md
2024.01.24 11:51:01 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:51:02 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-02-376.md
2024.01.24 11:51:02 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:51:02 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-02-974.md
Jan 24, 2024 11:51:03 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-03-816.md
2024.01.24 11:51:03 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:51:04 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:51:04 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-04-720.md
2024.01.24 11:51:11 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:51:11 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-11-328.md
Jan 24, 2024 11:51:12 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-12-805.md
Jan 24, 2024 11:51:13 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-13-149.md
Jan 24, 2024 11:51:13 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-13-611.md
2024.01.24 11:51:13 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:51:14 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:51:14 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-14-585.md
2024.01.24 11:51:16 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:51:16 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-16-199.md
Jan 24, 2024 11:51:16 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-16-548.md
Jan 24, 2024 11:51:17 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-17-001.md
Jan 24, 2024 11:51:17 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-17-499.md
2024.01.24 11:51:17 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:51:18 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:51:18 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-18-336.md
2024.01.24 11:51:19 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:51:19 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-19-204.md
Jan 24, 2024 11:51:19 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-19-619.md
Jan 24, 2024 11:51:19 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-19-734.md
Jan 24, 2024 11:51:20 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-20-309.md
2024.01.24 11:51:20 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:51:21 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:51:21 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-21-854.md
Jan 24, 2024 11:51:24 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-24-668.md
2024.01.24 11:51:25 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:51:25 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-25-099.md
2024.01.24 11:51:25 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:51:25 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-25-761.md
2024.01.24 11:51:28 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:51:28 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-28-485.md
Jan 24, 2024 11:51:31 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-31-851.md
2024.01.24 11:51:33 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:51:33 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-33-704.md
2024.01.24 11:51:34 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:51:34 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-34-346.md
Jan 24, 2024 11:51:35 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-35-365.md
Jan 24, 2024 11:51:35 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-35-807.md
2024.01.24 11:51:36 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:51:36 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-36-696.md
Jan 24, 2024 11:51:36 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-36-935.md
Jan 24, 2024 11:51:37 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-37-307.md
Jan 24, 2024 11:51:38 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-38-134.md
2024.01.24 11:51:38 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:51:45 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:51:45 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-45-585.md
Jan 24, 2024 11:51:45 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-45-836.md
Jan 24, 2024 11:51:46 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-46-283.md
Jan 24, 2024 11:51:46 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-46-325.md
2024.01.24 11:51:46 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:51:46 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-46-826.md
Jan 24, 2024 11:51:49 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-49-104.md
Jan 24, 2024 11:51:49 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-49-654.md
Jan 24, 2024 11:51:49 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-49-825.md
2024.01.24 11:51:50 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:51:56 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-56-715.md
Jan 24, 2024 11:51:59 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-59-603.md
Jan 24, 2024 11:51:59 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-51-59-953.md
Jan 24, 2024 11:52:00 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-00-205.md
Jan 24, 2024 11:52:00 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-00-591.md
Jan 24, 2024 11:52:01 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-01-081.md
Jan 24, 2024 11:52:02 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-02-094.md
Jan 24, 2024 11:52:02 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-02-625.md
2024.01.24 11:52:02 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:52:05 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-05-536.md
2024.01.24 11:52:05 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:52:06 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-06-011.md
Jan 24, 2024 11:52:06 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-06-099.md
Jan 24, 2024 11:52:06 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-06-258.md
Jan 24, 2024 11:52:06 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-06-444.md
Jan 24, 2024 11:52:06 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-06-604.md
2024.01.24 11:52:06 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:52:07 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-07-073.md
Jan 24, 2024 11:52:07 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-07-114.md
Jan 24, 2024 11:52:07 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-07-457.md
Jan 24, 2024 11:52:07 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-07-608.md
2024.01.24 11:52:07 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:52:08 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-08-581.md
2024.01.24 11:52:09 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:52:10 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-10-023.md
Jan 24, 2024 11:52:10 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-10-602.md
2024.01.24 11:52:10 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:52:13 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-13-229.md
Jan 24, 2024 11:52:13 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-13-439.md
Jan 24, 2024 11:52:13 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-13-675.md
Jan 24, 2024 11:52:13 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-13-740.md
2024.01.24 11:52:14 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:52:14 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-14-143.md
Jan 24, 2024 11:52:14 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-14-204.md
Jan 24, 2024 11:52:14 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-14-460.md
Jan 24, 2024 11:52:14 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-14-714.md
Jan 24, 2024 11:52:14 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-14-909.md
2024.01.24 11:52:15 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:52:16 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-16-082.md
Jan 24, 2024 11:52:16 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-16-694.md
Jan 24, 2024 11:52:18 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-18-553.md
2024.01.24 11:52:18 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:52:19 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-19-046.md
2024.01.24 11:52:19 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:52:19 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-19-880.md
Jan 24, 2024 11:52:21 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-21-776.md
2024.01.24 11:52:22 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:52:22 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-22-227.md
Jan 24, 2024 11:52:23 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-23-982.md
Jan 24, 2024 11:52:24 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-24-196.md
Jan 24, 2024 11:52:24 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-24-900.md
2024.01.24 11:52:25 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:52:25 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-25-361.md
Jan 24, 2024 11:52:27 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-27-487.md
2024.01.24 11:52:27 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:52:28 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-27-999.md
Jan 24, 2024 11:52:28 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-28-575.md
2024.01.24 11:52:28 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:52:29 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-28-997.md
Jan 24, 2024 11:52:29 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-29-048.md
2024.01.24 11:52:28 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:52:30 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-30-097.md
2024.01.24 11:52:30 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:52:30 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-30-697.md
Jan 24, 2024 11:52:30 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-30-914.md
Jan 24, 2024 11:52:31 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-31-067.md
2024.01.24 11:52:31 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:52:33 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-33-350.md
2024.01.24 11:52:33 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:52:33 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-33-783.md
Jan 24, 2024 11:52:33 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-33-903.md
Jan 24, 2024 11:52:34 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-34-035.md
Jan 24, 2024 11:52:34 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-34-345.md
Jan 24, 2024 11:52:34 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-34-378.md
Jan 24, 2024 11:52:34 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-34-572.md
Jan 24, 2024 11:52:34 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-34-810.md
Jan 24, 2024 11:52:35 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-35-012.md
Jan 24, 2024 11:52:35 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-35-150.md
2024.01.24 11:52:35 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:52:35 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-35-562.md
2024.01.24 11:52:41 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:52:41 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-41-293.md
2024.01.24 11:52:43 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:52:43 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-43-263.md
Jan 24, 2024 11:52:53 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-53-503.md
2024.01.24 11:52:54 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:52:54 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-54-224.md
Jan 24, 2024 11:52:56 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-56-674.md
2024.01.24 11:52:57 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:52:57 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-57-395.md
2024.01.24 11:52:58 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:52:58 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-58-529.md
Jan 24, 2024 11:52:59 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-52-59-211.md
2024.01.24 11:52:59 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:52:59 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:53:00 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-00-076.md
Jan 24, 2024 11:53:09 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-09-643.md
Jan 24, 2024 11:53:09 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-09-828.md
Jan 24, 2024 11:53:11 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-11-463.md
2024.01.24 11:53:11 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:53:13 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:53:13 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-13-305.md
2024.01.24 11:53:16 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:53:16 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-16-347.md
2024.01.24 11:53:30 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:53:30 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-30-432.md
Jan 24, 2024 11:53:30 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-30-990.md
Jan 24, 2024 11:53:31 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-31-433.md
2024.01.24 11:53:31 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:53:31 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-31-988.md
2024.01.24 11:53:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:53:32 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-32-718.md
Jan 24, 2024 11:53:33 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-33-543.md
Jan 24, 2024 11:53:33 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-33-976.md
Jan 24, 2024 11:53:34 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-34-568.md
2024.01.24 11:53:34 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:53:34 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:53:35 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-35-530.md
Jan 24, 2024 11:53:45 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-45-781.md
Jan 24, 2024 11:53:45 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-45-979.md
Jan 24, 2024 11:53:46 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-46-193.md
2024.01.24 11:53:46 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:53:50 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-50-459.md
Jan 24, 2024 11:53:50 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-50-850.md
Jan 24, 2024 11:53:51 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-51-105.md
2024.01.24 11:53:51 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:53:52 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:53:52 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-52-794.md
Jan 24, 2024 11:53:54 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-54-709.md
2024.01.24 11:53:54 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:53:55 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-55-079.md
2024.01.24 11:53:56 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:53:56 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-56-673.md
Jan 24, 2024 11:53:56 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-56-713.md
Jan 24, 2024 11:53:57 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-57-267.md
Jan 24, 2024 11:53:57 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-57-934.md
2024.01.24 11:53:58 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:53:58 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-53-58-604.md
2024.01.24 11:53:58 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:00 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-00-049.md
2024.01.24 11:54:00 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:00 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-00-478.md
Jan 24, 2024 11:54:00 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-00-713.md
Jan 24, 2024 11:54:00 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-00-860.md
Jan 24, 2024 11:54:01 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-01-047.md
Jan 24, 2024 11:54:01 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-01-138.md
Jan 24, 2024 11:54:01 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-01-285.md
Jan 24, 2024 11:54:01 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-01-502.md
Jan 24, 2024 11:54:01 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-01-644.md
Jan 24, 2024 11:54:01 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-01-725.md
2024.01.24 11:54:01 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:03 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-03-030.md
2024.01.24 11:54:03 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:03 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-03-463.md
Jan 24, 2024 11:54:03 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-03-530.md
Jan 24, 2024 11:54:03 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-03-660.md
Jan 24, 2024 11:54:04 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-03-985.md
Jan 24, 2024 11:54:04 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-04-037.md
Jan 24, 2024 11:54:04 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-04-253.md
Jan 24, 2024 11:54:04 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-04-464.md
Jan 24, 2024 11:54:04 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-04-699.md
Jan 24, 2024 11:54:04 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-04-837.md
2024.01.24 11:54:05 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:05 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-05-271.md
2024.01.24 11:54:07 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:07 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-07-857.md
2024.01.24 11:54:08 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:08 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-08-375.md
Jan 24, 2024 11:54:11 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-11-292.md
Jan 24, 2024 11:54:11 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-11-780.md
2024.01.24 11:54:11 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:54:12 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:12 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-12-593.md
Jan 24, 2024 11:54:13 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-13-262.md
2024.01.24 11:54:13 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:15 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-15-118.md
2024.01.24 11:54:15 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:54:15 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:16 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-16-181.md
2024.01.24 11:54:16 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:16 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-16-693.md
2024.01.24 11:54:18 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:18 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-18-466.md
Jan 24, 2024 11:54:19 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-19-603.md
2024.01.24 11:54:19 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:20 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-20-262.md
Jan 24, 2024 11:54:20 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-20-768.md
Jan 24, 2024 11:54:21 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-21-485.md
2024.01.24 11:54:21 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:54:22 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:22 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-22-095.md
Jan 24, 2024 11:54:23 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-23-475.md
2024.01.24 11:54:23 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:24 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-24-144.md
2024.01.24 11:54:24 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:54:24 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:24 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-24-639.md
2024.01.24 11:54:24 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:25 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-25-524.md
2024.01.24 11:54:25 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:54:26 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:26 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-26-434.md
Jan 24, 2024 11:54:26 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-26-931.md
Jan 24, 2024 11:54:27 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-27-481.md
2024.01.24 11:54:27 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:40 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-40-418.md
2024.01.24 11:54:42 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:42 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-42-250.md
Jan 24, 2024 11:54:42 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-42-775.md
Jan 24, 2024 11:54:43 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-43-384.md
2024.01.24 11:54:43 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:43 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-43-817.md
Jan 24, 2024 11:54:44 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-44-577.md
2024.01.24 11:54:44 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:54:45 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:45 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-45-764.md
Jan 24, 2024 11:54:46 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-46-196.md
2024.01.24 11:54:46 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:46 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-46-672.md
2024.01.24 11:54:47 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:47 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-47-133.md
2024.01.24 11:54:49 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:49 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-49-764.md
2024.01.24 11:54:54 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:54 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-54-475.md
Jan 24, 2024 11:54:54 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-54-897.md
2024.01.24 11:54:55 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:55 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-55-338.md
Jan 24, 2024 11:54:55 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-55-901.md
2024.01.24 11:54:56 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:56 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-56-424.md
Jan 24, 2024 11:54:56 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-56-525.md
Jan 24, 2024 11:54:57 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-57-138.md
2024.01.24 11:54:57 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:54:57 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:57 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-57-849.md
2024.01.24 11:54:59 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:54:59 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-59-442.md
Jan 24, 2024 11:54:59 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-54-59-985.md
Jan 24, 2024 11:55:00 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-00-248.md
Jan 24, 2024 11:55:00 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-00-387.md
Jan 24, 2024 11:55:01 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-01-159.md
Jan 24, 2024 11:55:01 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-01-621.md
Jan 24, 2024 11:55:01 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-01-666.md
2024.01.24 11:55:02 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:55:02 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-02-081.md
2024.01.24 11:55:04 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:55:04 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-04-776.md
2024.01.24 11:55:05 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:55:06 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-06-032.md
2024.01.24 11:55:08 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:55:09 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-09-018.md
Jan 24, 2024 11:55:11 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-11-483.md
2024.01.24 11:55:11 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:55:11 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-11-986.md
Jan 24, 2024 11:55:14 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-14-593.md
Jan 24, 2024 11:55:14 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-14-732.md
2024.01.24 11:55:15 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:55:15 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-15-223.md
Jan 24, 2024 11:55:17 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-17-017.md
2024.01.24 11:55:17 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:55:17 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-17-509.md
Jan 24, 2024 11:55:17 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-17-605.md
Jan 24, 2024 11:55:17 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-17-850.md
Jan 24, 2024 11:55:18 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-18-056.md
Jan 24, 2024 11:55:18 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-18-136.md
2024.01.24 11:55:18 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:55:18 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-18-563.md
Jan 24, 2024 11:55:18 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-18-826.md
Jan 24, 2024 11:55:19 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-19-039.md
Jan 24, 2024 11:55:19 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-19-234.md
Jan 24, 2024 11:55:19 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-19-265.md
Jan 24, 2024 11:55:19 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-19-486.md
Jan 24, 2024 11:55:19 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-19-780.md
Jan 24, 2024 11:55:19 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-19-915.md
2024.01.24 11:55:20 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:55:20 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-20-152.md
Jan 24, 2024 11:55:20 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-20-359.md
Jan 24, 2024 11:55:20 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-20-583.md
2024.01.24 11:55:20 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:55:23 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-23-242.md
2024.01.24 11:55:23 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:55:23 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-23-726.md
Jan 24, 2024 11:55:23 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-23-779.md
Jan 24, 2024 11:55:23 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-23-971.md
Jan 24, 2024 11:55:24 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-24-181.md
Jan 24, 2024 11:55:24 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-24-215.md
Jan 24, 2024 11:55:24 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-24-471.md
Jan 24, 2024 11:55:24 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-24-652.md
Jan 24, 2024 11:55:24 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-24-912.md
2024.01.24 11:55:25 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:55:25 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-25-191.md
2024.01.24 11:55:25 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:55:25 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-25-623.md
Jan 24, 2024 11:55:25 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-25-681.md
Jan 24, 2024 11:55:25 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-25-793.md
Jan 24, 2024 11:55:26 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-26-062.md
Jan 24, 2024 11:55:26 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-26-231.md
Jan 24, 2024 11:55:26 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-26-430.md
Jan 24, 2024 11:55:26 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-26-631.md
Jan 24, 2024 11:55:26 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-26-928.md
Jan 24, 2024 11:55:26 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-26-972.md
2024.01.24 11:55:27 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:55:27 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-27-393.md
2024.01.24 11:55:31 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:55:31 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-31-516.md
2024.01.24 11:55:38 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:55:38 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-38-943.md
2024.01.24 11:55:45 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:55:45 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-45-750.md
Jan 24, 2024 11:55:46 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-46-811.md
Jan 24, 2024 11:55:47 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-47-269.md
2024.01.24 11:55:47 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:55:48 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-48-065.md
Jan 24, 2024 11:55:48 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-48-108.md
Jan 24, 2024 11:55:48 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-48-757.md
2024.01.24 11:55:48 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:55:51 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:55:51 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-51-776.md
Jan 24, 2024 11:55:53 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-53-667.md
2024.01.24 11:55:54 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:55:54 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-54-119.md
Jan 24, 2024 11:55:56 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-56-879.md
Jan 24, 2024 11:55:57 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-57-141.md
2024.01.24 11:55:57 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:55:57 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-57-646.md
2024.01.24 11:55:59 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:55:59 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-55-59-301.md
Jan 24, 2024 11:56:02 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-02-964.md
2024.01.24 11:56:03 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:56:03 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-03-403.md
Jan 24, 2024 11:56:04 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-04-312.md
2024.01.24 11:56:04 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:56:05 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-05-804.md
2024.01.24 11:56:05 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:56:08 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:56:09 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-08-997.md
2024.01.24 11:56:10 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:56:11 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-11-090.md
2024.01.24 11:56:11 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:56:11 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-11-806.md
Jan 24, 2024 11:56:13 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-13-278.md
2024.01.24 11:56:22 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:56:22 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-22-759.md
Jan 24, 2024 11:56:23 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-23-812.md
Jan 24, 2024 11:56:27 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-27-301.md
2024.01.24 11:56:27 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:56:27 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-27-849.md
Jan 24, 2024 11:56:28 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-28-820.md
Jan 24, 2024 11:56:29 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-29-197.md
2024.01.24 11:56:29 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:56:30 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-30-013.md
2024.01.24 11:56:30 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:56:30 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-30-548.md
Jan 24, 2024 11:56:31 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-31-749.md
Jan 24, 2024 11:56:31 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-31-906.md
Jan 24, 2024 11:56:32 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-32-188.md
Jan 24, 2024 11:56:32 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-32-454.md
Jan 24, 2024 11:56:35 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-35-252.md
Jan 24, 2024 11:56:35 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-35-786.md
2024.01.24 11:56:36 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:56:36 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:56:36 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-36-580.md
Jan 24, 2024 11:56:37 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-37-131.md
2024.01.24 11:56:37 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:56:37 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-37-488.md
2024.01.24 11:56:37 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:56:38 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-38-025.md
Jan 24, 2024 11:56:38 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-38-583.md
2024.01.24 11:56:37 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:56:44 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-44-133.md
2024.01.24 11:56:44 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:56:44 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:56:45 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-45-087.md
Jan 24, 2024 11:56:47 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-47-115.md
Jan 24, 2024 11:56:49 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-49-659.md
2024.01.24 11:56:49 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:56:50 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:56:50 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-50-701.md
Jan 24, 2024 11:56:51 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-51-151.md
2024.01.24 11:56:51 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:56:51 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-51-877.md
Jan 24, 2024 11:56:52 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-52-726.md
2024.01.24 11:56:53 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:56:53 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-53-333.md
Jan 24, 2024 11:56:55 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-55-562.md
Jan 24, 2024 11:56:56 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-56-061.md
Jan 24, 2024 11:56:56 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-56-596.md
Jan 24, 2024 11:56:57 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-57-055.md
Jan 24, 2024 11:56:57 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-57-528.md
2024.01.24 11:56:58 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:56:58 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-58-131.md
2024.01.24 11:56:58 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:56:58 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-58-631.md
2024.01.24 11:56:59 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:56:59 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-56-59-085.md
Jan 24, 2024 11:57:00 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-00-519.md
2024.01.24 11:57:00 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:01 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-01-385.md
2024.01.24 11:57:01 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:02 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-02-304.md
2024.01.24 11:57:01 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:57:03 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:03 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-03-368.md
2024.01.24 11:57:03 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:03 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-03-982.md
Jan 24, 2024 11:57:04 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-04-576.md
Jan 24, 2024 11:57:05 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-05-127.md
2024.01.24 11:57:05 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:57:06 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:06 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-06-418.md
Jan 24, 2024 11:57:08 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-08-279.md
Jan 24, 2024 11:57:08 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-08-720.md
2024.01.24 11:57:08 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:57:11 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:11 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-11-858.md
Jan 24, 2024 11:57:12 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-12-385.md
2024.01.24 11:57:12 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:14 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-14-186.md
2024.01.24 11:57:14 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:14 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-14-561.md
2024.01.24 11:57:15 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:15 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-15-144.md
2024.01.24 11:57:15 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:15 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-15-872.md
2024.01.24 11:57:17 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:17 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-17-601.md
2024.01.24 11:57:19 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:19 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-19-913.md
2024.01.24 11:57:20 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:20 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-20-920.md
Jan 24, 2024 11:57:21 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-21-775.md
Jan 24, 2024 11:57:22 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-22-217.md
Jan 24, 2024 11:57:22 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-22-822.md
Jan 24, 2024 11:57:23 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-23-343.md
2024.01.24 11:57:23 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:57:25 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:25 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-25-256.md
Jan 24, 2024 11:57:25 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-25-318.md
2024.01.24 11:57:25 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:25 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-25-804.md
Jan 24, 2024 11:57:26 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-26-230.md
2024.01.24 11:57:26 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:57:27 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:27 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-27-309.md
2024.01.24 11:57:30 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:30 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-30-394.md
2024.01.24 11:57:30 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:31 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-31-103.md
2024.01.24 11:57:31 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:31 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-31-875.md
2024.01.24 11:57:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:32 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-32-626.md
Jan 24, 2024 11:57:33 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-33-948.md
Jan 24, 2024 11:57:34 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-34-344.md
Jan 24, 2024 11:57:35 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-35-084.md
Jan 24, 2024 11:57:35 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-35-616.md
2024.01.24 11:57:36 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:36 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-36-121.md
2024.01.24 11:57:42 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:42 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-42-619.md
Jan 24, 2024 11:57:43 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-43-724.md
2024.01.24 11:57:43 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:44 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-44-101.md
Jan 24, 2024 11:57:44 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-44-484.md
2024.01.24 11:57:45 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:45 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-45-125.md
Jan 24, 2024 11:57:45 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-45-692.md
Jan 24, 2024 11:57:46 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-46-110.md
Jan 24, 2024 11:57:46 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-46-405.md
Jan 24, 2024 11:57:49 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-49-252.md
Jan 24, 2024 11:57:49 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-49-911.md
Jan 24, 2024 11:57:50 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-50-294.md
2024.01.24 11:57:51 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:57:51 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-57-51-731.md
2024.01.24 11:58:01 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:58:01 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-01-227.md
Jan 24, 2024 11:58:01 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-01-311.md
Jan 24, 2024 11:58:01 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-01-749.md
2024.01.24 11:58:02 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:58:02 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-02-436.md
2024.01.24 11:58:02 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:58:05 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-05-787.md
Jan 24, 2024 11:58:16 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-16-944.md
Jan 24, 2024 11:58:26 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-26-935.md
2024.01.24 11:58:28 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:58:28 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-28-955.md
2024.01.24 11:58:29 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:58:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:58:32 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-32-993.md
Jan 24, 2024 11:58:35 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-35-055.md
2024.01.24 11:58:35 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:58:36 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:58:36 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-36-206.md
Jan 24, 2024 11:58:36 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-36-751.md
2024.01.24 11:58:37 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:58:37 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-37-298.md
Jan 24, 2024 11:58:38 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-37-999.md
2024.01.24 11:58:38 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:58:38 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-38-549.md
2024.01.24 11:58:40 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:58:40 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-40-867.md
Jan 24, 2024 11:58:41 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-41-500.md
Jan 24, 2024 11:58:42 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-42-123.md
Jan 24, 2024 11:58:42 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-42-856.md
Jan 24, 2024 11:58:43 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-43-367.md
Jan 24, 2024 11:58:43 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-43-880.md
Jan 24, 2024 11:58:44 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-44-565.md
Jan 24, 2024 11:58:45 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-45-078.md
2024.01.24 11:58:45 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:58:45 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-45-621.md
2024.01.24 11:58:45 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:58:46 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:58:46 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-46-672.md
Jan 24, 2024 11:58:47 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-47-348.md
Jan 24, 2024 11:58:47 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-47-933.md
Jan 24, 2024 11:58:48 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-48-381.md
Jan 24, 2024 11:58:49 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-49-022.md
Jan 24, 2024 11:58:49 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-49-511.md
Jan 24, 2024 11:58:50 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-50-015.md
Jan 24, 2024 11:58:50 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-50-650.md
Jan 24, 2024 11:58:51 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-51-084.md
2024.01.24 11:58:51 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:58:51 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-51-544.md
2024.01.24 11:58:54 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:58:54 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-58-54-297.md
2024.01.24 11:59:02 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:59:02 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-02-195.md
Jan 24, 2024 11:59:02 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-02-226.md
Jan 24, 2024 11:59:02 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-02-799.md
Jan 24, 2024 11:59:03 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-03-316.md
Jan 24, 2024 11:59:04 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-04-051.md
2024.01.24 11:59:04 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:59:05 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-05-052.md
Jan 24, 2024 11:59:05 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-05-439.md
Jan 24, 2024 11:59:05 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-05-622.md
2024.01.24 11:59:05 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:59:06 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-06-051.md
2024.01.24 11:59:06 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:59:08 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:59:08 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-08-481.md
Jan 24, 2024 11:59:10 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-10-289.md
Jan 24, 2024 11:59:10 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-10-730.md
2024.01.24 11:59:11 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:59:11 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-11-522.md
2024.01.24 11:59:11 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:59:11 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-11-949.md
Jan 24, 2024 11:59:12 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-12-461.md
Jan 24, 2024 11:59:12 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-12-966.md
2024.01.24 11:59:13 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:59:14 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-14-766.md
2024.01.24 11:59:15 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:59:15 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-15-225.md
2024.01.24 11:59:16 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:59:16 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-16-521.md
Jan 24, 2024 11:59:18 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-18-911.md
2024.01.24 11:59:19 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:59:19 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-19-508.md
2024.01.24 11:59:19 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:59:20 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-20-028.md
Jan 24, 2024 11:59:22 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-22-323.md
Jan 24, 2024 11:59:22 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-22-548.md
Jan 24, 2024 11:59:23 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-23-373.md
Jan 24, 2024 11:59:27 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-27-448.md
Jan 24, 2024 11:59:28 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-28-081.md
2024.01.24 11:59:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:59:32 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-32-188.md
Jan 24, 2024 11:59:32 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-32-330.md
Jan 24, 2024 11:59:32 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-32-781.md
Jan 24, 2024 11:59:33 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-33-239.md
Jan 24, 2024 11:59:33 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-33-881.md
2024.01.24 11:59:33 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 11:59:35 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:59:35 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-35-799.md
Jan 24, 2024 11:59:35 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-35-833.md
2024.01.24 11:59:35 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:59:36 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-36-245.md
Jan 24, 2024 11:59:36 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-36-889.md
Jan 24, 2024 11:59:37 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-37-420.md
2024.01.24 11:59:37 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:59:37 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-37-912.md
2024.01.24 11:59:41 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:59:41 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-41-701.md
Jan 24, 2024 11:59:47 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-47-928.md
Jan 24, 2024 11:59:48 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-48-545.md
Jan 24, 2024 11:59:52 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-52-825.md
2024.01.24 11:59:56 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:59:56 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-56-695.md
2024.01.24 11:59:58 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 11:59:58 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_11-59-58-332.md
Jan 24, 2024 12:00:02 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-02-695.md
Jan 24, 2024 12:00:03 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-03-419.md
2024.01.24 12:00:03 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 12:00:04 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 12:00:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-04-700.md
Jan 24, 2024 12:00:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-05-204.md
Jan 24, 2024 12:00:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-05-667.md
2024.01.24 12:00:05 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 12:00:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-09-669.md
2024.01.24 12:00:10 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 12:00:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-10-142.md
Jan 24, 2024 12:00:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-10-865.md
2024.01.24 12:00:11 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 12:00:14 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 12:00:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-14-638.md
Jan 24, 2024 12:00:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-15-350.md
Jan 24, 2024 12:00:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-15-807.md
Jan 24, 2024 12:00:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-16-439.md
Jan 24, 2024 12:00:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-17-012.md
2024.01.24 12:00:17 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 12:00:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-17-584.md
Jan 24, 2024 12:00:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-18-636.md
Jan 24, 2024 12:00:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-19-199.md
2024.01.24 12:00:19 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 12:00:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-19-638.md
Jan 24, 2024 12:00:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-20-481.md
Jan 24, 2024 12:00:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-20-986.md
Jan 24, 2024 12:00:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-21-455.md
2024.01.24 12:00:21 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 12:00:22 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-22-042.md
2024.01.24 12:00:26 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 12:00:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-26-793.md
Jan 24, 2024 12:00:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-28-209.md
2024.01.24 12:00:28 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 12:00:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-30-021.md
2024.01.24 12:00:30 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 12:00:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-31-231.md
2024.01.24 12:00:31 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 12:00:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-32-608.md
2024.01.24 12:00:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 12:00:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 12:00:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-33-207.md
Jan 24, 2024 12:00:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-35-027.md
Jan 24, 2024 12:00:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-35-544.md
2024.01.24 12:00:35 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 12:00:36 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 12:00:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-36-362.md
Jan 24, 2024 12:00:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-36-813.md
2024.01.24 12:00:36 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 12:00:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-38-298.md
Jan 24, 2024 12:00:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-38-827.md
Jan 24, 2024 12:00:39 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-39-625.md
Jan 24, 2024 12:00:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-40-074.md
Jan 24, 2024 12:00:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-40-575.md
Jan 24, 2024 12:00:41 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-41-054.md
Jan 24, 2024 12:00:41 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-41-598.md
2024.01.24 12:00:42 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 12:00:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-42-355.md
Jan 24, 2024 12:00:43 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-43-071.md
Jan 24, 2024 12:00:43 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-43-532.md
Jan 24, 2024 12:00:44 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-44-106.md
2024.01.24 12:00:44 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 12:00:45 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 12:00:45 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-45-829.md
Jan 24, 2024 12:00:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-46-223.md
Jan 24, 2024 12:00:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-46-666.md
2024.01.24 12:00:46 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 12:00:47 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 12:00:47 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-47-817.md
2024.01.24 12:00:48 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 12:00:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-49-088.md
Jan 24, 2024 12:00:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-49-703.md
Jan 24, 2024 12:00:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-50-026.md
Jan 24, 2024 12:00:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-50-097.md
Jan 24, 2024 12:00:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-50-664.md
2024.01.24 12:00:51 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 12:00:51 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-51-153.md
2024.01.24 12:00:52 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 12:00:52 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-52-508.md
2024.01.24 12:00:54 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 12:00:54 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-54-835.md
2024.01.24 12:00:55 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\MyProducer.java
Jan 24, 2024 12:00:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-00-55-662.md
Jan 24, 2024 12:01:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-01-10-351.md
Jan 24, 2024 12:01:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-01-15-919.md
2024.01.24 12:01:33 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Myproducer1.java
2024.01.24 12:01:33 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:01:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-01-33-871.md
2024.01.24 12:01:34 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:01:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-01-34-365.md
2024.01.24 12:01:40 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:01:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-01-40-471.md
Jan 24, 2024 12:01:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-01-48-290.md
2024.01.24 12:01:53 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:01:54 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-01-54-067.md
2024.01.24 12:01:55 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:01:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-01-55-558.md
2024.01.24 12:01:55 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:01:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-01-56-733.md
2024.01.24 12:01:58 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:01:58 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-01-58-877.md
Jan 24, 2024 12:01:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-01-59-919.md
2024.01.24 12:02:00 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:02:00 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-00-367.md
Jan 24, 2024 12:02:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-04-133.md
Jan 24, 2024 12:02:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-05-274.md
Jan 24, 2024 12:02:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-06-124.md
2024.01.24 12:02:06 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:02:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-06-624.md
Jan 24, 2024 12:02:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-07-420.md
Jan 24, 2024 12:02:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-10-753.md
Jan 24, 2024 12:02:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-10-956.md
2024.01.24 12:02:12 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:02:12 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-12-302.md
2024.01.24 12:02:12 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

2024.01.24 12:02:12 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Myproducer1.java
Jan 24, 2024 12:02:12 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-12-840.md
Jan 24, 2024 12:02:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-15-060.md
Jan 24, 2024 12:02:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-16-328.md
Jan 24, 2024 12:02:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-17-786.md
2024.01.24 12:02:19 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:02:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-19-646.md
Jan 24, 2024 12:02:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-20-287.md
Jan 24, 2024 12:02:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-20-445.md
Jan 24, 2024 12:02:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-20-903.md
2024.01.24 12:02:21 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

2024.01.24 12:02:23 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:02:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-23-248.md
Jan 24, 2024 12:02:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-23-360.md
Jan 24, 2024 12:02:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-23-844.md
2024.01.24 12:02:23 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:02:24 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-24-650.md
2024.01.24 12:02:24 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

2024.01.24 12:02:25 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:02:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-25-836.md
Jan 24, 2024 12:02:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-33-736.md
Jan 24, 2024 12:02:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-34-027.md
Jan 24, 2024 12:02:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-34-886.md
Jan 24, 2024 12:02:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-35-601.md
Jan 24, 2024 12:02:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-36-037.md
2024.01.24 12:02:36 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:02:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-36-509.md
2024.01.24 12:02:37 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:02:37 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-37-472.md
Jan 24, 2024 12:02:37 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-37-923.md
2024.01.24 12:02:39 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:02:39 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-39-234.md
2024.01.24 12:02:39 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

2024.01.24 12:02:41 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:02:41 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-41-201.md
2024.01.24 12:02:42 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:02:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-42-194.md
2024.01.24 12:02:42 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:02:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-48-738.md
Jan 24, 2024 12:02:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-49-952.md
Jan 24, 2024 12:02:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-50-389.md
2024.01.24 12:02:50 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:02:51 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-51-309.md
2024.01.24 12:02:51 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

2024.01.24 12:02:52 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:02:52 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-52-485.md
Jan 24, 2024 12:02:53 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-53-325.md
Jan 24, 2024 12:02:53 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-53-914.md
2024.01.24 12:02:54 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:02:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-55-452.md
2024.01.24 12:02:56 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:02:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-56-117.md
Jan 24, 2024 12:02:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-56-682.md
2024.01.24 12:02:56 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:02:57 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-57-068.md
Jan 24, 2024 12:02:57 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-02-57-742.md
2024.01.24 12:02:57 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

2024.01.24 12:03:00 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:03:00 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-00-653.md
2024.01.24 12:03:01 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:03:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-01-207.md
2024.01.24 12:03:02 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:03:02 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-02-298.md
2024.01.24 12:03:02 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:03:02 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-02-700.md
Jan 24, 2024 12:03:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-06-932.md
2024.01.24 12:03:07 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:03:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-07-750.md
Jan 24, 2024 12:03:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-09-576.md
2024.01.24 12:03:09 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

2024.01.24 12:03:10 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:03:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-10-915.md
2024.01.24 12:03:12 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Myproducer1.java
Jan 24, 2024 12:03:12 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-12-399.md
Jan 24, 2024 12:03:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-13-754.md
Jan 24, 2024 12:03:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-14-162.md
2024.01.24 12:03:15 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:03:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-16-021.md
Jan 24, 2024 12:03:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-16-068.md
2024.01.24 12:03:16 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:03:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-18-009.md
Jan 24, 2024 12:03:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-18-670.md
Jan 24, 2024 12:03:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-19-434.md
Jan 24, 2024 12:03:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-20-098.md
Jan 24, 2024 12:03:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-20-540.md
Jan 24, 2024 12:03:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-21-239.md
Jan 24, 2024 12:03:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-21-774.md
2024.01.24 12:03:22 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:03:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-25-815.md
Jan 24, 2024 12:03:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-26-423.md
2024.01.24 12:03:26 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

2024.01.24 12:03:27 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:03:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-27-602.md
Jan 24, 2024 12:03:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-28-159.md
2024.01.24 12:03:28 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Myproducer1.java
Jan 24, 2024 12:03:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-28-615.md
Jan 24, 2024 12:03:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-29-215.md
2024.01.24 12:03:30 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:03:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-30-643.md
2024.01.24 12:03:35 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:03:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-35-697.md
Jan 24, 2024 12:03:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-36-210.md
2024.01.24 12:03:36 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:03:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-36-646.md
2024.01.24 12:03:37 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Myproducer1.java
Jan 24, 2024 12:03:37 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-37-781.md
2024.01.24 12:03:42 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Myproducer1.java
Jan 24, 2024 12:03:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-42-927.md
2024.01.24 12:03:44 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:03:44 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-44-333.md
2024.01.24 12:03:45 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Myproducer1.java
Jan 24, 2024 12:03:45 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-45-291.md
Jan 24, 2024 12:03:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-03-48-875.md
2024.01.24 12:07:28 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\ConstConfig.java
2024.01.24 12:07:28 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:07:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-07-28-245.md
Jan 24, 2024 12:07:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-07-28-944.md
2024.01.24 12:07:28 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:07:45 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-07-45-419.md
2024.01.24 12:07:45 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:07:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-07-46-316.md
Jan 24, 2024 12:07:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-07-46-758.md
Jan 24, 2024 12:07:47 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-07-47-391.md
Jan 24, 2024 12:07:47 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-07-47-563.md
Jan 24, 2024 12:07:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-07-48-019.md
2024.01.24 12:07:48 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:07:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-07-48-538.md
2024.01.24 12:07:49 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:07:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-07-49-182.md
Jan 24, 2024 12:07:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-07-49-735.md
2024.01.24 12:07:49 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:07:57 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-07-57-605.md
2024.01.24 12:07:57 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:07:58 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-07-58-049.md
Jan 24, 2024 12:07:58 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-07-58-520.md
2024.01.24 12:07:58 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:07:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-07-59-321.md
2024.01.24 12:07:59 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:07:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-07-59-910.md
2024.01.24 12:08:00 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:00 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-00-680.md
Jan 24, 2024 12:08:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-01-099.md
Jan 24, 2024 12:08:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-01-136.md
2024.01.24 12:08:01 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-01-508.md
Jan 24, 2024 12:08:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-01-925.md
Jan 24, 2024 12:08:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-01-950.md
2024.01.24 12:08:02 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:02 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-02-617.md
Jan 24, 2024 12:08:02 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-02-831.md
Jan 24, 2024 12:08:03 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-03-342.md
2024.01.24 12:08:03 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

2024.01.24 12:08:04 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-04-931.md
Jan 24, 2024 12:08:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-06-090.md
2024.01.24 12:08:06 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-07-649.md
2024.01.24 12:08:07 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-08-373.md
Jan 24, 2024 12:08:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-08-883.md
Jan 24, 2024 12:08:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-09-408.md
2024.01.24 12:08:09 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-09-943.md
2024.01.24 12:08:10 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-10-559.md
Jan 24, 2024 12:08:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-19-288.md
Jan 24, 2024 12:08:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-19-834.md
Jan 24, 2024 12:08:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-20-390.md
Jan 24, 2024 12:08:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-20-879.md
2024.01.24 12:08:20 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

2024.01.24 12:08:21 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-21-456.md
Jan 24, 2024 12:08:22 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-22-361.md
Jan 24, 2024 12:08:22 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-22-810.md
2024.01.24 12:08:22 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-23-704.md
Jan 24, 2024 12:08:24 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-24-256.md
2024.01.24 12:08:24 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-25-008.md
2024.01.24 12:08:25 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-25-557.md
Jan 24, 2024 12:08:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-26-087.md
2024.01.24 12:08:26 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

2024.01.24 12:08:27 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-27-930.md
2024.01.24 12:08:28 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-28-438.md
Jan 24, 2024 12:08:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-31-150.md
Jan 24, 2024 12:08:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-31-281.md
Jan 24, 2024 12:08:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-31-581.md
Jan 24, 2024 12:08:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-31-741.md
Jan 24, 2024 12:08:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-32-047.md
Jan 24, 2024 12:08:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-32-070.md
2024.01.24 12:08:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-33-627.md
2024.01.24 12:08:33 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-34-428.md
Jan 24, 2024 12:08:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-34-872.md
2024.01.24 12:08:35 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-35-454.md
Jan 24, 2024 12:08:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-36-081.md
Jan 24, 2024 12:08:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-36-520.md
2024.01.24 12:08:36 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:37 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-37-121.md
Jan 24, 2024 12:08:37 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-37-596.md
2024.01.24 12:08:37 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

2024.01.24 12:08:38 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-38-922.md
Jan 24, 2024 12:08:39 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-39-942.md
2024.01.24 12:08:40 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-40-370.md
Jan 24, 2024 12:08:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-40-869.md
2024.01.24 12:08:40 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

2024.01.24 12:08:41 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:41 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-41-658.md
Jan 24, 2024 12:08:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-42-407.md
2024.01.24 12:08:42 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:43 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-43-053.md
Jan 24, 2024 12:08:44 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-44-335.md
2024.01.24 12:08:44 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:44 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-44-774.md
Jan 24, 2024 12:08:45 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-45-598.md
2024.01.24 12:08:45 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

2024.01.24 12:08:46 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-46-230.md
Jan 24, 2024 12:08:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-46-894.md
Jan 24, 2024 12:08:47 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-47-395.md
2024.01.24 12:08:47 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

2024.01.24 12:08:48 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-48-246.md
Jan 24, 2024 12:08:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-49-051.md
Jan 24, 2024 12:08:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-49-740.md
2024.01.24 12:08:50 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

2024.01.24 12:08:50 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:51 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-51-096.md
Jan 24, 2024 12:08:51 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-51-559.md
2024.01.24 12:08:51 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

2024.01.24 12:08:52 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:52 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-52-281.md
Jan 24, 2024 12:08:53 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-53-731.md
Jan 24, 2024 12:08:54 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-54-267.md
2024.01.24 12:08:54 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:54 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-54-724.md
2024.01.24 12:08:55 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-55-313.md
Jan 24, 2024 12:08:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-55-926.md
2024.01.24 12:08:56 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

2024.01.24 12:08:56 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-56-873.md
Jan 24, 2024 12:08:57 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-57-530.md
2024.01.24 12:08:58 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:08:58 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-58-305.md
Jan 24, 2024 12:08:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-08-59-609.md
2024.01.24 12:08:59 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:00 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-00-608.md
Jan 24, 2024 12:09:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-01-116.md
Jan 24, 2024 12:09:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-01-915.md
Jan 24, 2024 12:09:02 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-02-493.md
2024.01.24 12:09:02 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:03 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-03-326.md
2024.01.24 12:09:03 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:03 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-03-842.md
2024.01.24 12:09:04 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-04-344.md
Jan 24, 2024 12:09:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-04-963.md
2024.01.24 12:09:05 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

2024.01.24 12:09:05 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-05-712.md
2024.01.24 12:09:08 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-08-419.md
2024.01.24 12:09:09 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-09-820.md
2024.01.24 12:09:10 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-10-423.md
2024.01.24 12:09:10 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-11-049.md
Jan 24, 2024 12:09:12 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-12-183.md
Jan 24, 2024 12:09:12 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-12-559.md
Jan 24, 2024 12:09:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-13-152.md
2024.01.24 12:09:13 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

2024.01.24 12:09:13 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-14-056.md
Jan 24, 2024 12:09:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-14-260.md
Jan 24, 2024 12:09:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-14-689.md
2024.01.24 12:09:15 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-15-282.md
2024.01.24 12:09:15 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-15-904.md
2024.01.24 12:09:15 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-16-725.md
2024.01.24 12:09:17 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-17-152.md
Jan 24, 2024 12:09:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-17-645.md
2024.01.24 12:09:18 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-18-073.md
Jan 24, 2024 12:09:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-18-574.md
Jan 24, 2024 12:09:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-19-114.md
2024.01.24 12:09:19 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

2024.01.24 12:09:19 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-19-861.md
2024.01.24 12:09:19 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-23-045.md
2024.01.24 12:09:23 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-23-480.md
Jan 24, 2024 12:09:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-23-677.md
2024.01.24 12:09:24 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:24 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-24-115.md
Jan 24, 2024 12:09:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-25-682.md
Jan 24, 2024 12:09:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-25-942.md
Jan 24, 2024 12:09:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-26-120.md
2024.01.24 12:09:26 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-26-440.md
2024.01.24 12:09:26 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-26-836.md
Jan 24, 2024 12:09:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-26-935.md
Jan 24, 2024 12:09:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-27-168.md
Jan 24, 2024 12:09:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-27-302.md
Jan 24, 2024 12:09:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-27-369.md
Jan 24, 2024 12:09:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-27-554.md
2024.01.24 12:09:27 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-28-000.md
Jan 24, 2024 12:09:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-29-412.md
2024.01.24 12:09:29 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

2024.01.24 12:09:30 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-30-393.md
Jan 24, 2024 12:09:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-30-916.md
2024.01.24 12:09:31 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-32-300.md
2024.01.24 12:09:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-33-201.md
Jan 24, 2024 12:09:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-33-862.md
2024.01.24 12:09:34 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

2024.01.24 12:09:35 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-36-117.md
2024.01.24 12:09:36 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-36-536.md
Jan 24, 2024 12:09:44 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-44-932.md
2024.01.24 12:09:45 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\ConstConfig.java
Jan 24, 2024 12:09:45 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-45-685.md
2024.01.24 12:09:48 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-48-884.md
2024.01.24 12:09:50 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:09:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-50-203.md
2024.01.24 12:09:50 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

2024.01.24 12:09:52 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\ConstConfig.java
Jan 24, 2024 12:09:52 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-52-154.md
Jan 24, 2024 12:09:53 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-53-875.md
Jan 24, 2024 12:09:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-09-56-719.md
Jan 24, 2024 12:10:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-01-036.md
2024.01.24 12:10:12 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:10:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-13-057.md
2024.01.24 12:10:13 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:10:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-13-727.md
Jan 24, 2024 12:10:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-15-543.md
Jan 24, 2024 12:10:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-15-980.md
2024.01.24 12:10:16 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:10:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-16-458.md
2024.01.24 12:10:17 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:10:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-17-213.md
2024.01.24 12:10:17 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:10:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-18-040.md
Jan 24, 2024 12:10:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-19-202.md
Jan 24, 2024 12:10:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-19-649.md
2024.01.24 12:10:20 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:10:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-20-586.md
2024.01.24 12:10:20 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

2024.01.24 12:10:21 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\ConstConfig.java
Jan 24, 2024 12:10:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-21-583.md
Jan 24, 2024 12:10:22 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-22-445.md
2024.01.24 12:10:24 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\ConstConfig.java
Jan 24, 2024 12:10:24 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-24-283.md
Jan 24, 2024 12:10:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-25-191.md
2024.01.24 12:10:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConstConfig.java. Output:

Jan 24, 2024 12:10:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-32-742.md
2024.01.24 12:10:33 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\ConstConfig.java
Jan 24, 2024 12:10:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-33-051.md
Jan 24, 2024 12:10:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-38-081.md
Jan 24, 2024 12:10:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-38-660.md
Jan 24, 2024 12:10:39 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-39-946.md
Jan 24, 2024 12:10:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-40-230.md
2024.01.24 12:10:45 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:10:45 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-45-281.md
2024.01.24 12:10:49 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:10:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-49-523.md
Jan 24, 2024 12:10:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-50-440.md
Jan 24, 2024 12:10:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-50-881.md
2024.01.24 12:10:51 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:10:52 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-52-505.md
2024.01.24 12:10:52 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:10:52 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-52-933.md
2024.01.24 12:10:54 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:10:54 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-54-320.md
Jan 24, 2024 12:10:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-55-140.md
2024.01.24 12:10:55 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:10:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-55-665.md
2024.01.24 12:10:57 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:10:57 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-57-755.md
Jan 24, 2024 12:10:58 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-10-58-915.md
Jan 24, 2024 12:11:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-01-142.md
Jan 24, 2024 12:11:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-01-477.md
Jan 24, 2024 12:11:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-01-649.md
Jan 24, 2024 12:11:02 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-02-075.md
2024.01.24 12:11:06 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:11:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-06-296.md
Jan 24, 2024 12:11:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-07-559.md
2024.01.24 12:11:07 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:11:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-08-004.md
Jan 24, 2024 12:11:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-08-730.md
2024.01.24 12:11:09 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:11:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-09-202.md
Jan 24, 2024 12:11:09 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3608
2024.01.24 12:11:09 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:11:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-09-934.md
Jan 24, 2024 12:11:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-10-933.md
2024.01.24 12:11:11 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:11:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-11-452.md
2024.01.24 12:11:13 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:11:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-13-620.md
Jan 24, 2024 12:11:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-14-433.md
Jan 24, 2024 12:11:22 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-22-900.md
Jan 24, 2024 12:11:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-23-117.md
Jan 24, 2024 12:11:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-23-834.md
Jan 24, 2024 12:11:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-26-967.md
Jan 24, 2024 12:11:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-27-424.md
2024.01.24 12:11:27 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:11:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-28-978.md
2024.01.24 12:11:29 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:11:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-29-764.md
2024.01.24 12:11:30 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:11:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-30-153.md
2024.01.24 12:11:30 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

2024.01.24 12:11:35 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:11:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-35-957.md
Jan 24, 2024 12:11:37 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-37-324.md
2024.01.24 12:11:37 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:11:37 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-37-772.md
2024.01.24 12:11:39 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:11:39 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-39-774.md
2024.01.24 12:11:40 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Myproducer1.java
Jan 24, 2024 12:11:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-40-730.md
2024.01.24 12:11:44 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:11:44 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-44-939.md
Jan 24, 2024 12:11:47 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-47-036.md
2024.01.24 12:11:47 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:11:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-48-185.md
2024.01.24 12:11:48 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:11:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-49-175.md
Jan 24, 2024 12:11:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-49-674.md
Jan 24, 2024 12:11:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-50-257.md
Jan 24, 2024 12:11:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-50-754.md
2024.01.24 12:11:50 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:11:51 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 3702
Jan 24, 2024 12:11:51 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-51-521.md
2024.01.24 12:11:52 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:11:52 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-52-110.md
2024.01.24 12:11:52 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:11:53 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-53-584.md
Jan 24, 2024 12:11:54 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-54-086.md
Jan 24, 2024 12:11:54 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-54-570.md
2024.01.24 12:11:55 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:11:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-55-279.md
Jan 24, 2024 12:11:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-55-748.md
Jan 24, 2024 12:11:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-56-296.md
2024.01.24 12:11:56 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:11:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-11-59-973.md
2024.01.24 12:12:06 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:12:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-12-06-555.md
2024.01.24 12:12:07 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:12:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-12-07-178.md
2024.01.24 12:12:07 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:12:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-12-07-610.md
Jan 24, 2024 12:12:12 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-12-12-403.md
2024.01.24 12:12:13 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Myproducer1.java
Jan 24, 2024 12:12:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-12-13-814.md
Jan 24, 2024 12:13:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-13-31-150.md
Jan 24, 2024 12:13:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-13-31-320.md
Jan 24, 2024 12:13:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-13-31-662.md
Jan 24, 2024 12:13:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-13-33-085.md
Jan 24, 2024 12:13:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-13-33-285.md
Jan 24, 2024 12:13:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-13-33-930.md
Jan 24, 2024 12:13:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-13-40-483.md
Jan 24, 2024 12:13:41 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-13-41-113.md
Jan 24, 2024 12:13:41 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-13-41-603.md
Jan 24, 2024 12:13:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-13-42-168.md
Jan 24, 2024 12:13:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-13-42-742.md
Jan 24, 2024 12:13:43 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-13-43-272.md
Jan 24, 2024 12:13:43 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-13-43-862.md
2024.01.24 12:13:44 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:13:44 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-13-44-438.md
2024.01.24 12:13:44 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:14:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-14-28-570.md
Jan 24, 2024 12:14:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-14-31-200.md
Jan 24, 2024 12:14:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-14-32-290.md
Jan 24, 2024 12:14:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-14-32-581.md
Jan 24, 2024 12:14:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-14-35-370.md
2024.01.24 12:14:38 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:14:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-14-38-520.md
2024.01.24 12:14:38 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myproducer1.java. Output:

Jan 24, 2024 12:14:39 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-14-39-044.md
Jan 24, 2024 12:14:43 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-14-43-718.md
2024.01.24 12:14:44 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Myproducer1.java
Jan 24, 2024 12:14:44 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-14-44-715.md
Jan 24, 2024 12:14:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_12-14-46-542.md
2024.01.24 14:55:06 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Myconsumer.java
2024.01.24 14:55:06 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:55:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-07-025.md
2024.01.24 14:55:07 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:55:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-07-512.md
2024.01.24 14:55:11 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:55:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-11-394.md
2024.01.24 14:55:13 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:55:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-13-977.md
2024.01.24 14:55:18 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:55:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-18-117.md
Jan 24, 2024 2:55:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-19-387.md
Jan 24, 2024 2:55:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-26-694.md
Jan 24, 2024 2:55:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-27-789.md
Jan 24, 2024 2:55:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-28-602.md
2024.01.24 14:55:29 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:55:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-29-657.md
2024.01.24 14:55:29 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:55:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-36-672.md
2024.01.24 14:55:36 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 14:55:38 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:55:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-38-868.md
Jan 24, 2024 2:55:39 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-39-281.md
Jan 24, 2024 2:55:39 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-39-724.md
2024.01.24 14:55:40 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:55:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-40-234.md
Jan 24, 2024 2:55:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-40-896.md
2024.01.24 14:55:41 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 14:55:41 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:55:41 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-41-609.md
Jan 24, 2024 2:55:41 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-41-632.md
Jan 24, 2024 2:55:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-42-186.md
2024.01.24 14:55:42 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:55:43 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-43-168.md
Jan 24, 2024 2:55:43 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-43-561.md
Jan 24, 2024 2:55:43 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-43-997.md
Jan 24, 2024 2:55:44 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-44-747.md
2024.01.24 14:55:44 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:55:45 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-45-010.md
Jan 24, 2024 2:55:45 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-45-451.md
2024.01.24 14:55:46 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:55:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-46-154.md
Jan 24, 2024 2:55:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-49-397.md
Jan 24, 2024 2:55:51 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-51-464.md
Jan 24, 2024 2:55:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-55-079.md
2024.01.24 14:55:56 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:55:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-56-725.md
Jan 24, 2024 2:55:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-56-850.md
2024.01.24 14:55:56 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:55:57 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-57-299.md
Jan 24, 2024 2:55:57 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-57-831.md
Jan 24, 2024 2:55:58 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-58-369.md
2024.01.24 14:55:58 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:55:58 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-58-900.md
2024.01.24 14:55:59 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:55:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-55-59-641.md
Jan 24, 2024 2:56:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-01-646.md
Jan 24, 2024 2:56:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-01-880.md
Jan 24, 2024 2:56:02 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-02-468.md
2024.01.24 14:56:02 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 14:56:06 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:56:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-06-574.md
2024.01.24 14:56:07 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:56:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-07-475.md
2024.01.24 14:56:08 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:56:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-08-174.md
2024.01.24 14:56:08 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:56:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-08-716.md
2024.01.24 14:56:09 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:56:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-09-213.md
2024.01.24 14:56:10 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:56:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-11-050.md
Jan 24, 2024 2:56:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-40-238.md
Jan 24, 2024 2:56:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-42-312.md
Jan 24, 2024 2:56:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-46-222.md
2024.01.24 14:56:46 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:56:47 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-47-775.md
Jan 24, 2024 2:56:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-48-723.md
Jan 24, 2024 2:56:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-49-260.md
Jan 24, 2024 2:56:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-49-569.md
Jan 24, 2024 2:56:51 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-51-104.md
Jan 24, 2024 2:56:52 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-52-345.md
2024.01.24 14:56:52 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 14:56:52 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:56:53 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-53-060.md
Jan 24, 2024 2:56:53 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-53-641.md
Jan 24, 2024 2:56:54 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-54-124.md
Jan 24, 2024 2:56:54 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-54-692.md
2024.01.24 14:56:55 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:56:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-55-265.md
Jan 24, 2024 2:56:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-55-759.md
2024.01.24 14:56:55 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:56:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-56-800.md
2024.01.24 14:56:57 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:56:57 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-57-302.md
Jan 24, 2024 2:56:58 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-58-252.md
2024.01.24 14:56:58 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:56:58 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-58-839.md
Jan 24, 2024 2:56:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-56-59-624.md
2024.01.24 14:57:00 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:57:00 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-00-196.md
Jan 24, 2024 2:57:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-01-513.md
2024.01.24 14:57:01 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:57:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-04-960.md
Jan 24, 2024 2:57:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-05-364.md
2024.01.24 14:57:05 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:57:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-05-881.md
Jan 24, 2024 2:57:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-08-998.md
Jan 24, 2024 2:57:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-09-462.md
2024.01.24 14:57:09 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:57:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-09-983.md
2024.01.24 14:57:11 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:57:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-11-135.md
Jan 24, 2024 2:57:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-15-979.md
Jan 24, 2024 2:57:24 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-24-697.md
Jan 24, 2024 2:57:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-26-348.md
Jan 24, 2024 2:57:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-26-892.md
Jan 24, 2024 2:57:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-27-460.md
2024.01.24 14:57:27 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:57:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-28-592.md
Jan 24, 2024 2:57:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-28-992.md
Jan 24, 2024 2:57:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-29-480.md
Jan 24, 2024 2:57:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-29-991.md
2024.01.24 14:57:30 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 14:57:31 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:57:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-31-381.md
2024.01.24 14:57:34 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:57:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-34-504.md
2024.01.24 14:57:35 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:57:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-35-925.md
Jan 24, 2024 2:57:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-36-511.md
Jan 24, 2024 2:57:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-36-955.md
Jan 24, 2024 2:57:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-36-985.md
Jan 24, 2024 2:57:37 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-37-317.md
Jan 24, 2024 2:57:37 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-37-471.md
2024.01.24 14:57:37 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:57:37 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-37-864.md
Jan 24, 2024 2:57:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-38-238.md
Jan 24, 2024 2:57:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-38-313.md
Jan 24, 2024 2:57:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-38-453.md
Jan 24, 2024 2:57:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-38-662.md
Jan 24, 2024 2:57:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-38-891.md
2024.01.24 14:57:39 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:57:39 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-39-912.md
2024.01.24 14:57:40 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:57:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-40-334.md
Jan 24, 2024 2:57:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-40-665.md
2024.01.24 14:57:41 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:57:41 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-41-105.md
Jan 24, 2024 2:57:43 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-43-767.md
2024.01.24 14:57:44 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:57:44 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-44-259.md
Jan 24, 2024 2:57:44 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-44-280.md
Jan 24, 2024 2:57:44 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-44-708.md
2024.01.24 14:57:45 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:57:45 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-45-210.md
Jan 24, 2024 2:57:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-48-083.md
Jan 24, 2024 2:57:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-48-512.md
Jan 24, 2024 2:57:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-49-145.md
Jan 24, 2024 2:57:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-49-769.md
Jan 24, 2024 2:57:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-49-892.md
Jan 24, 2024 2:57:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-50-338.md
2024.01.24 14:57:50 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:57:51 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-51-021.md
2024.01.24 14:57:53 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:57:53 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-53-758.md
2024.01.24 14:57:55 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:57:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-55-278.md
Jan 24, 2024 2:57:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-56-719.md
Jan 24, 2024 2:57:58 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-58-746.md
2024.01.24 14:57:59 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:57:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-57-59-857.md
Jan 24, 2024 2:58:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-33-366.md
Jan 24, 2024 2:58:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-33-810.md
2024.01.24 14:58:34 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 14:58:35 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:58:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-35-334.md
2024.01.24 14:58:36 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:58:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-36-818.md
Jan 24, 2024 2:58:37 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-37-856.md
Jan 24, 2024 2:58:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-38-296.md
Jan 24, 2024 2:58:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-38-935.md
2024.01.24 14:58:39 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 14:58:45 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:58:45 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-45-465.md
Jan 24, 2024 2:58:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-46-038.md
Jan 24, 2024 2:58:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-46-471.md
2024.01.24 14:58:46 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:58:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-46-949.md
Jan 24, 2024 2:58:47 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-47-536.md
Jan 24, 2024 2:58:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-48-190.md
2024.01.24 14:58:48 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:58:52 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-52-235.md
Jan 24, 2024 2:58:53 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-53-927.md
Jan 24, 2024 2:58:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-55-404.md
2024.01.24 14:58:55 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:58:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-55-847.md
Jan 24, 2024 2:58:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-55-889.md
Jan 24, 2024 2:58:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-56-135.md
2024.01.24 14:58:56 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:58:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-56-580.md
Jan 24, 2024 2:58:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-56-600.md
Jan 24, 2024 2:58:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-56-688.md
2024.01.24 14:58:57 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:58:57 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-57-126.md
Jan 24, 2024 2:58:57 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-57-184.md
2024.01.24 14:58:57 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:58:57 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-57-629.md
Jan 24, 2024 2:58:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-58-59-464.md
Jan 24, 2024 2:59:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-06-330.md
2024.01.24 14:59:06 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:59:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-06-811.md
Jan 24, 2024 2:59:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-07-747.md
Jan 24, 2024 2:59:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-07-973.md
2024.01.24 14:59:08 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:59:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-08-676.md
2024.01.24 14:59:09 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:59:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-09-346.md
Jan 24, 2024 2:59:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-09-832.md
2024.01.24 14:59:10 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:59:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-10-457.md
2024.01.24 14:59:11 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:59:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-11-094.md
Jan 24, 2024 2:59:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-11-694.md
Jan 24, 2024 2:59:12 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-12-193.md
2024.01.24 14:59:12 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:59:12 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-12-759.md
2024.01.24 14:59:13 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 14:59:15 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:59:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-15-196.md
2024.01.24 14:59:15 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:59:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-15-723.md
2024.01.24 14:59:16 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:59:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-16-995.md
Jan 24, 2024 2:59:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-20-234.md
2024.01.24 14:59:20 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:59:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-20-664.md
2024.01.24 14:59:21 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:59:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-23-547.md
2024.01.24 14:59:23 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:59:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-25-491.md
2024.01.24 14:59:25 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:59:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-25-940.md
2024.01.24 14:59:26 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:59:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-26-499.md
2024.01.24 14:59:29 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:59:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-29-469.md
Jan 24, 2024 2:59:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-30-575.md
Jan 24, 2024 2:59:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-31-032.md
2024.01.24 14:59:31 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:59:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-31-663.md
2024.01.24 14:59:33 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:59:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-33-441.md
2024.01.24 14:59:33 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:59:37 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-37-212.md
Jan 24, 2024 2:59:41 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-41-018.md
2024.01.24 14:59:41 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:59:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-42-806.md
2024.01.24 14:59:43 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:59:43 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-43-472.md
2024.01.24 14:59:45 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:59:45 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-45-514.md
Jan 24, 2024 2:59:47 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-47-078.md
Jan 24, 2024 2:59:47 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4476
Jan 24, 2024 2:59:47 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-47-316.md
Jan 24, 2024 2:59:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-47-982.md
Jan 24, 2024 2:59:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-48-315.md
Jan 24, 2024 2:59:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-48-919.md
Jan 24, 2024 2:59:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-49-168.md
Jan 24, 2024 2:59:51 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-51-179.md
Jan 24, 2024 2:59:51 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-51-684.md
2024.01.24 14:59:51 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:59:52 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-52-337.md
Jan 24, 2024 2:59:52 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-52-812.md
Jan 24, 2024 2:59:53 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-53-381.md
2024.01.24 14:59:53 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 2:59:53 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_14-59-53-917.md
Jan 24, 2024 3:00:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-00-04-774.md
2024.01.24 15:00:05 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:00:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-00-05-211.md
Jan 24, 2024 3:00:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-00-05-755.md
Jan 24, 2024 3:00:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-00-06-269.md
Jan 24, 2024 3:00:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-00-06-731.md
2024.01.24 15:00:07 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:00:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-00-07-299.md
2024.01.24 15:00:07 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:00:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-00-08-083.md
Jan 24, 2024 3:00:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-00-08-751.md
2024.01.24 15:00:09 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:00:09 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:00:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-00-09-732.md
Jan 24, 2024 3:00:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-00-10-184.md
Jan 24, 2024 3:00:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-00-10-889.md
2024.01.24 15:00:11 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:00:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-00-11-549.md
Jan 24, 2024 3:00:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-00-14-859.md
Jan 24, 2024 3:00:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-00-17-852.md
Jan 24, 2024 3:00:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-00-18-324.md
Jan 24, 2024 3:00:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-00-19-755.md
Jan 24, 2024 3:00:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-00-20-292.md
2024.01.24 15:00:20 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:00:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-00-20-873.md
Jan 24, 2024 3:00:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-00-21-456.md
2024.01.24 15:00:21 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:00:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-00-21-909.md
2024.01.24 15:00:22 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:00:22 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-00-22-945.md
2024.01.24 15:00:29 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:00:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-00-29-339.md
2024.01.24 15:00:29 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:00:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-00-29-872.md
Jan 24, 2024 3:00:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-00-30-929.md
Jan 24, 2024 3:01:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-04-813.md
Jan 24, 2024 3:01:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-05-354.md
Jan 24, 2024 3:01:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-06-004.md
2024.01.24 15:01:07 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:01:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-07-702.md
Jan 24, 2024 3:01:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-08-216.md
Jan 24, 2024 3:01:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-08-668.md
Jan 24, 2024 3:01:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-09-268.md
Jan 24, 2024 3:01:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-09-774.md
2024.01.24 15:01:10 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:01:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-13-153.md
2024.01.24 15:01:13 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:01:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-13-550.md
2024.01.24 15:01:13 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:01:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-14-271.md
2024.01.24 15:01:14 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:01:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-14-956.md
Jan 24, 2024 3:01:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-15-190.md
Jan 24, 2024 3:01:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-15-420.md
Jan 24, 2024 3:01:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-15-654.md
Jan 24, 2024 3:01:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-15-679.md
Jan 24, 2024 3:01:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-15-897.md
Jan 24, 2024 3:01:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-16-100.md
2024.01.24 15:01:16 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:01:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-16-480.md
Jan 24, 2024 3:01:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-16-771.md
Jan 24, 2024 3:01:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-16-915.md
Jan 24, 2024 3:01:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-16-954.md
Jan 24, 2024 3:01:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-17-170.md
Jan 24, 2024 3:01:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-17-408.md
Jan 24, 2024 3:01:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-17-619.md
Jan 24, 2024 3:01:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-17-765.md
Jan 24, 2024 3:01:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-18-007.md
Jan 24, 2024 3:01:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-18-192.md
2024.01.24 15:01:18 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:01:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-21-094.md
2024.01.24 15:01:21 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:01:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-21-545.md
Jan 24, 2024 3:01:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-28-039.md
Jan 24, 2024 3:01:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-28-192.md
Jan 24, 2024 3:01:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-28-418.md
Jan 24, 2024 3:01:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-28-441.md
Jan 24, 2024 3:01:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-28-691.md
Jan 24, 2024 3:01:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-28-850.md
Jan 24, 2024 3:01:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-29-138.md
2024.01.24 15:01:29 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:01:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-29-558.md
2024.01.24 15:01:29 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:01:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-29-983.md
Jan 24, 2024 3:01:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-30-039.md
Jan 24, 2024 3:01:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-30-245.md
Jan 24, 2024 3:01:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-30-481.md
Jan 24, 2024 3:01:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-30-502.md
Jan 24, 2024 3:01:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-30-815.md
Jan 24, 2024 3:01:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-31-007.md
Jan 24, 2024 3:01:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-31-255.md
Jan 24, 2024 3:01:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-31-411.md
2024.01.24 15:01:31 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:01:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-31-806.md
Jan 24, 2024 3:01:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-38-905.md
2024.01.24 15:01:40 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:01:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-40-725.md
Jan 24, 2024 3:01:41 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-41-249.md
Jan 24, 2024 3:01:41 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-41-718.md
Jan 24, 2024 3:01:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-42-241.md
2024.01.24 15:01:42 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:01:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-42-694.md
Jan 24, 2024 3:01:43 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-43-817.md
2024.01.24 15:01:44 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:01:45 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-45-034.md
Jan 24, 2024 3:01:45 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-45-477.md
2024.01.24 15:01:45 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:01:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-46-881.md
Jan 24, 2024 3:01:47 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-47-353.md
2024.01.24 15:01:47 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:01:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-49-713.md
Jan 24, 2024 3:01:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-49-945.md
Jan 24, 2024 3:01:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-50-160.md
Jan 24, 2024 3:01:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-50-219.md
2024.01.24 15:01:50 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:01:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-01-50-661.md
Jan 24, 2024 3:02:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-06-354.md
Jan 24, 2024 3:02:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-08-982.md
Jan 24, 2024 3:02:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-10-770.md
2024.01.24 15:02:11 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:02:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-11-203.md
2024.01.24 15:02:12 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:02:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-13-017.md
Jan 24, 2024 3:02:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-13-041.md
Jan 24, 2024 3:02:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-13-219.md
2024.01.24 15:02:13 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:02:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-13-655.md
Jan 24, 2024 3:02:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-13-762.md
Jan 24, 2024 3:02:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-13-980.md
Jan 24, 2024 3:02:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-14-124.md
Jan 24, 2024 3:02:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-14-241.md
Jan 24, 2024 3:02:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-14-383.md
2024.01.24 15:02:14 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:02:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-14-818.md
Jan 24, 2024 3:02:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-15-304.md
Jan 24, 2024 3:02:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-15-516.md
Jan 24, 2024 3:02:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-15-727.md
Jan 24, 2024 3:02:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-15-761.md
2024.01.24 15:02:16 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:02:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-16-193.md
Jan 24, 2024 3:02:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-30-026.md
2024.01.24 15:02:30 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:02:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-30-593.md
Jan 24, 2024 3:02:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-31-277.md
Jan 24, 2024 3:02:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-31-583.md
Jan 24, 2024 3:02:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-31-718.md
Jan 24, 2024 3:02:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-31-782.md
2024.01.24 15:02:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:02:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-32-237.md
Jan 24, 2024 3:02:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-34-009.md
Jan 24, 2024 3:02:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-34-412.md
Jan 24, 2024 3:02:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-34-491.md
Jan 24, 2024 3:02:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-34-925.md
2024.01.24 15:02:35 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:02:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-35-627.md
Jan 24, 2024 3:02:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-35-647.md
2024.01.24 15:02:36 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:02:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-40-850.md
2024.01.24 15:02:41 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:02:41 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-41-298.md
2024.01.24 15:02:42 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:02:43 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-43-015.md
2024.01.24 15:02:43 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:02:43 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-43-682.md
2024.01.24 15:02:44 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:02:44 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-44-390.md
Jan 24, 2024 3:02:45 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-45-936.md
Jan 24, 2024 3:02:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-02-46-798.md
Jan 24, 2024 3:03:12 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-12-154.md
2024.01.24 15:03:15 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:03:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-15-120.md
Jan 24, 2024 3:03:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-17-470.md
2024.01.24 15:03:18 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:03:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-18-224.md
2024.01.24 15:03:19 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:03:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-19-442.md
2024.01.24 15:03:20 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:03:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-20-201.md
Jan 24, 2024 3:03:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-20-869.md
Jan 24, 2024 3:03:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-21-163.md
Jan 24, 2024 3:03:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-21-421.md
Jan 24, 2024 3:03:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-23-873.md
Jan 24, 2024 3:03:24 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-24-554.md
Jan 24, 2024 3:03:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-25-133.md
2024.01.24 15:03:25 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:03:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-28-301.md
2024.01.24 15:03:28 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:03:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-28-745.md
Jan 24, 2024 3:03:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-29-254.md
2024.01.24 15:03:29 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:03:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-30-001.md
2024.01.24 15:03:30 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:03:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-30-503.md
Jan 24, 2024 3:03:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-32-287.md
Jan 24, 2024 3:03:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-32-699.md
Jan 24, 2024 3:03:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-34-106.md
2024.01.24 15:03:34 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:03:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-34-656.md
Jan 24, 2024 3:03:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-35-115.md
Jan 24, 2024 3:03:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-35-550.md
2024.01.24 15:03:35 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:03:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-36-393.md
2024.01.24 15:03:36 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:03:37 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-37-034.md
Jan 24, 2024 3:03:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-38-966.md
Jan 24, 2024 3:03:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-42-565.md
Jan 24, 2024 3:03:43 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-43-182.md
Jan 24, 2024 3:03:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-50-224.md
Jan 24, 2024 3:03:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-50-965.md
2024.01.24 15:03:52 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:03:52 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-52-667.md
2024.01.24 15:03:54 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:03:54 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-54-245.md
Jan 24, 2024 3:03:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-55-437.md
Jan 24, 2024 3:03:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-55-768.md
Jan 24, 2024 3:03:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-56-374.md
Jan 24, 2024 3:03:58 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-58-312.md
Jan 24, 2024 3:03:58 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-58-757.md
2024.01.24 15:03:59 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:03:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-03-59-565.md
Jan 24, 2024 3:04:00 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-00-161.md
2024.01.24 15:04:00 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:04:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-01-793.md
Jan 24, 2024 3:04:02 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-02-027.md
Jan 24, 2024 3:04:02 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-02-525.md
Jan 24, 2024 3:04:03 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-03-892.md
Jan 24, 2024 3:04:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-05-082.md
Jan 24, 2024 3:04:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-06-403.md
Jan 24, 2024 3:04:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-07-677.md
Jan 24, 2024 3:04:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-08-116.md
2024.01.24 15:04:08 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:04:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-09-040.md
Jan 24, 2024 3:04:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-09-607.md
2024.01.24 15:04:09 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:04:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-11-038.md
Jan 24, 2024 3:04:12 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-12-582.md
Jan 24, 2024 3:04:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-13-052.md
Jan 24, 2024 3:04:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-13-794.md
Jan 24, 2024 3:04:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-14-387.md
2024.01.24 15:04:14 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:04:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-16-249.md
Jan 24, 2024 3:04:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-16-520.md
Jan 24, 2024 3:04:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-19-814.md
Jan 24, 2024 3:04:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-21-272.md
Jan 24, 2024 3:04:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-21-948.md
Jan 24, 2024 3:04:22 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-22-616.md
Jan 24, 2024 3:04:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-23-498.md
Jan 24, 2024 3:04:24 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-24-024.md
2024.01.24 15:04:24 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:04:24 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-24-556.md
2024.01.24 15:04:25 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:04:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-25-125.md
Jan 24, 2024 3:04:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-25-496.md
2024.01.24 15:04:25 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:04:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-25-945.md
Jan 24, 2024 3:04:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-26-698.md
Jan 24, 2024 3:04:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-27-360.md
2024.01.24 15:04:27 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:04:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-29-055.md
Jan 24, 2024 3:04:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-29-687.md
Jan 24, 2024 3:04:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-30-937.md
Jan 24, 2024 3:04:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-31-552.md
Jan 24, 2024 3:04:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-32-167.md
2024.01.24 15:04:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:04:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-33-146.md
2024.01.24 15:04:33 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:04:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-33-594.md
Jan 24, 2024 3:04:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-34-081.md
Jan 24, 2024 3:04:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-34-653.md
Jan 24, 2024 3:04:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-35-348.md
2024.01.24 15:04:35 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:04:37 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-37-368.md
Jan 24, 2024 3:04:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-38-111.md
Jan 24, 2024 3:04:39 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-39-449.md
Jan 24, 2024 3:04:39 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-39-976.md
Jan 24, 2024 3:04:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-40-495.md
2024.01.24 15:04:40 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:04:41 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-41-354.md
2024.01.24 15:04:41 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:04:41 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-41-853.md
Jan 24, 2024 3:04:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-42-068.md
Jan 24, 2024 3:04:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-42-280.md
Jan 24, 2024 3:04:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-42-331.md
Jan 24, 2024 3:04:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-42-508.md
Jan 24, 2024 3:04:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-42-730.md
Jan 24, 2024 3:04:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-42-788.md
Jan 24, 2024 3:04:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-42-956.md
Jan 24, 2024 3:04:43 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-43-159.md
Jan 24, 2024 3:04:43 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-43-406.md
2024.01.24 15:04:43 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:04:46 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Myconsumer.java
Jan 24, 2024 3:04:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-46-618.md
Jan 24, 2024 3:04:52 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-04-52-066.md
Jan 24, 2024 3:05:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-11-230.md
Jan 24, 2024 3:05:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-11-659.md
Jan 24, 2024 3:05:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-13-009.md
2024.01.24 15:05:15 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:05:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-15-476.md
Jan 24, 2024 3:05:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-16-283.md
2024.01.24 15:05:16 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:05:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-17-153.md
Jan 24, 2024 3:05:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-17-852.md
2024.01.24 15:05:18 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:05:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-18-598.md
Jan 24, 2024 3:05:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-19-049.md
2024.01.24 15:05:19 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:05:19 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:05:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-19-911.md
2024.01.24 15:05:22 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:05:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-23-051.md
Jan 24, 2024 3:05:24 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-24-090.md
2024.01.24 15:05:24 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:05:25 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:05:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-25-669.md
Jan 24, 2024 3:05:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-26-479.md
Jan 24, 2024 3:05:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-27-023.md
2024.01.24 15:05:27 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:05:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-27-549.md
Jan 24, 2024 3:05:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-28-160.md
Jan 24, 2024 3:05:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-28-709.md
2024.01.24 15:05:29 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:05:29 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:05:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-29-935.md
Jan 24, 2024 3:05:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-40-441.md
Jan 24, 2024 3:05:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-40-885.md
Jan 24, 2024 3:05:41 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-41-620.md
Jan 24, 2024 3:05:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-42-237.md
2024.01.24 15:05:42 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:05:43 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:05:43 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-43-360.md
Jan 24, 2024 3:05:44 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-44-006.md
Jan 24, 2024 3:05:44 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-44-463.md
2024.01.24 15:05:44 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:05:45 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-45-132.md
2024.01.24 15:05:45 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:05:46 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:05:47 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-47-015.md
Jan 24, 2024 3:05:47 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-47-062.md
Jan 24, 2024 3:05:47 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-47-512.md
Jan 24, 2024 3:05:47 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-47-565.md
2024.01.24 15:05:48 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:05:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-48-180.md
Jan 24, 2024 3:05:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-48-715.md
Jan 24, 2024 3:05:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-49-287.md
2024.01.24 15:05:49 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:05:51 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-51-410.md
2024.01.24 15:05:51 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:05:51 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-51-836.md
2024.01.24 15:05:52 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:05:52 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-52-618.md
Jan 24, 2024 3:05:54 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-54-028.md
2024.01.24 15:05:54 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:05:54 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-05-54-470.md
Jan 24, 2024 3:06:00 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-00-423.md
Jan 24, 2024 3:06:00 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-00-676.md
Jan 24, 2024 3:06:00 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-00-820.md
2024.01.24 15:06:01 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:06:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-01-324.md
Jan 24, 2024 3:06:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-01-562.md
Jan 24, 2024 3:06:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-01-753.md
2024.01.24 15:06:01 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:06:02 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-02-032.md
Jan 24, 2024 3:06:02 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-02-432.md
Jan 24, 2024 3:06:02 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-02-477.md
2024.01.24 15:06:02 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:06:03 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-03-190.md
Jan 24, 2024 3:06:03 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-03-575.md
Jan 24, 2024 3:06:03 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-03-680.md
2024.01.24 15:06:03 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:06:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-04-216.md
2024.01.24 15:06:04 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:06:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-04-656.md
Jan 24, 2024 3:06:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-04-685.md
2024.01.24 15:06:05 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:06:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-05-109.md
Jan 24, 2024 3:06:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-05-332.md
Jan 24, 2024 3:06:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-05-498.md
Jan 24, 2024 3:06:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-05-680.md
2024.01.24 15:06:06 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:06:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-06-127.md
Jan 24, 2024 3:06:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-06-237.md
Jan 24, 2024 3:06:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-06-486.md
Jan 24, 2024 3:06:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-06-630.md
2024.01.24 15:06:06 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:06:09 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:06:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-09-807.md
2024.01.24 15:06:09 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:06:15 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:06:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-15-986.md
Jan 24, 2024 3:06:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-16-478.md
2024.01.24 15:06:16 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:06:17 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:06:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-17-123.md
Jan 24, 2024 3:06:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-17-623.md
2024.01.24 15:06:17 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:06:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-18-293.md
2024.01.24 15:06:18 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:06:18 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:06:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-18-923.md
Jan 24, 2024 3:06:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-19-492.md
2024.01.24 15:06:19 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:06:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-20-359.md
2024.01.24 15:06:20 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:06:20 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:06:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-20-999.md
Jan 24, 2024 3:06:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-23-171.md
2024.01.24 15:06:23 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:06:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-27-128.md
Jan 24, 2024 3:06:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-27-551.md
2024.01.24 15:06:28 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:06:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-29-011.md
2024.01.24 15:06:30 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:06:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-30-975.md
Jan 24, 2024 3:06:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-31-828.md
Jan 24, 2024 3:06:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-32-264.md
2024.01.24 15:06:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:06:34 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:06:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-34-579.md
Jan 24, 2024 3:06:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-35-035.md
Jan 24, 2024 3:06:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-35-494.md
Jan 24, 2024 3:06:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-36-035.md
2024.01.24 15:06:36 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:06:37 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:06:37 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-37-864.md
Jan 24, 2024 3:06:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-38-093.md
Jan 24, 2024 3:06:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-38-580.md
2024.01.24 15:06:38 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:06:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-40-531.md
Jan 24, 2024 3:06:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-40-969.md
Jan 24, 2024 3:06:41 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-41-558.md
2024.01.24 15:06:41 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:06:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-42-047.md
2024.01.24 15:06:42 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:06:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-42-495.md
2024.01.24 15:06:42 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:06:42 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:06:43 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-43-455.md
Jan 24, 2024 3:06:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-46-064.md
2024.01.24 15:06:46 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:06:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-06-46-523.md
Jan 24, 2024 3:07:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-01-430.md
2024.01.24 15:07:01 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:07:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-01-907.md
Jan 24, 2024 3:07:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-01-941.md
Jan 24, 2024 3:07:02 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-02-159.md
Jan 24, 2024 3:07:02 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-02-375.md
2024.01.24 15:07:02 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:07:02 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-02-744.md
2024.01.24 15:07:03 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:07:03 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-03-196.md
Jan 24, 2024 3:07:03 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-03-286.md
Jan 24, 2024 3:07:03 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-03-476.md
2024.01.24 15:07:03 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:07:03 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-03-863.md
Jan 24, 2024 3:07:03 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-03-896.md
Jan 24, 2024 3:07:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-04-031.md
Jan 24, 2024 3:07:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-04-362.md
Jan 24, 2024 3:07:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-04-475.md
Jan 24, 2024 3:07:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-04-526.md
2024.01.24 15:07:04 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:07:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-04-966.md
Jan 24, 2024 3:07:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-04-992.md
Jan 24, 2024 3:07:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-05-356.md
Jan 24, 2024 3:07:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-05-536.md
Jan 24, 2024 3:07:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-05-779.md
Jan 24, 2024 3:07:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-05-814.md
Jan 24, 2024 3:07:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-06-018.md
2024.01.24 15:07:06 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:07:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-06-428.md
Jan 24, 2024 3:07:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-06-471.md
2024.01.24 15:07:06 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:07:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-07-191.md
2024.01.24 15:07:06 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:07:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-07-583.md
Jan 24, 2024 3:07:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-07-690.md
2024.01.24 15:07:08 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:07:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-08-122.md
Jan 24, 2024 3:07:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-08-214.md
Jan 24, 2024 3:07:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-08-407.md
Jan 24, 2024 3:07:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-08-580.md
Jan 24, 2024 3:07:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-08-733.md
2024.01.24 15:07:09 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:07:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-09-171.md
Jan 24, 2024 3:07:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-09-244.md
Jan 24, 2024 3:07:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-09-602.md
Jan 24, 2024 3:07:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-09-681.md
2024.01.24 15:07:09 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:07:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-11-248.md
Jan 24, 2024 3:07:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-11-537.md
2024.01.24 15:07:15 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:07:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-15-873.md
Jan 24, 2024 3:07:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-17-110.md
Jan 24, 2024 3:07:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-17-786.md
2024.01.24 15:07:19 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:07:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-19-951.md
2024.01.24 15:07:20 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:07:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-20-609.md
Jan 24, 2024 3:07:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-29-741.md
2024.01.24 15:07:29 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:07:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-30-627.md
Jan 24, 2024 3:07:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-31-034.md
2024.01.24 15:07:31 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:07:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-33-393.md
2024.01.24 15:07:35 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:07:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-35-615.md
2024.01.24 15:07:37 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:07:37 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-37-742.md
2024.01.24 15:07:38 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:07:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-38-878.md
2024.01.24 15:07:38 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:07:39 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-39-499.md
Jan 24, 2024 3:07:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-40-713.md
2024.01.24 15:07:40 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:07:45 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-45-800.md
Jan 24, 2024 3:07:52 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-52-827.md
2024.01.24 15:07:55 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:07:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-55-453.md
Jan 24, 2024 3:07:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-55-959.md
Jan 24, 2024 3:07:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-56-551.md
Jan 24, 2024 3:07:57 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-57-351.md
Jan 24, 2024 3:07:57 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-57-958.md
Jan 24, 2024 3:07:58 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-58-511.md
Jan 24, 2024 3:07:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-59-140.md
Jan 24, 2024 3:07:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-07-59-670.md
2024.01.24 15:07:59 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:08:03 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-03-275.md
2024.01.24 15:08:03 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:08:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-04-289.md
Jan 24, 2024 3:08:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-04-798.md
Jan 24, 2024 3:08:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-05-494.md
Jan 24, 2024 3:08:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-06-148.md
2024.01.24 15:08:06 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:08:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-07-216.md
2024.01.24 15:08:07 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:08:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-09-743.md
2024.01.24 15:08:10 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:08:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-10-219.md
Jan 24, 2024 3:08:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-11-146.md
2024.01.24 15:08:11 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:08:12 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-12-056.md
2024.01.24 15:08:12 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:08:12 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-12-380.md
Jan 24, 2024 3:08:12 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-12-815.md
2024.01.24 15:08:13 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:08:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-13-467.md
2024.01.24 15:08:16 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:08:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-16-425.md
2024.01.24 15:08:19 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:08:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-19-441.md
Jan 24, 2024 3:08:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-20-060.md
Jan 24, 2024 3:08:20 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 5742
Jan 24, 2024 3:08:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-20-512.md
Jan 24, 2024 3:08:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-20-984.md
2024.01.24 15:08:21 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:08:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-21-625.md
Jan 24, 2024 3:08:22 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-22-187.md
2024.01.24 15:08:22 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:08:22 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-22-371.md
2024.01.24 15:08:22 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:08:22 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-22-809.md
Jan 24, 2024 3:08:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-23-431.md
Jan 24, 2024 3:08:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-23-951.md
2024.01.24 15:08:24 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:08:26 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:08:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-26-565.md
2024.01.24 15:08:26 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:08:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-27-084.md
Jan 24, 2024 3:08:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-27-719.md
Jan 24, 2024 3:08:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-28-165.md
2024.01.24 15:08:28 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:08:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-28-649.md
Jan 24, 2024 3:08:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-29-280.md
2024.01.24 15:08:29 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:08:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-29-878.md
2024.01.24 15:08:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:08:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-32-197.md
2024.01.24 15:08:33 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:08:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-33-410.md
Jan 24, 2024 3:08:39 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-39-361.md
Jan 24, 2024 3:08:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-39-978.md
Jan 24, 2024 3:08:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-40-182.md
Jan 24, 2024 3:08:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-42-729.md
2024.01.24 15:08:45 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:08:45 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-45-540.md
Jan 24, 2024 3:08:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-46-010.md
Jan 24, 2024 3:08:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-46-111.md
Jan 24, 2024 3:08:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-46-563.md
2024.01.24 15:08:47 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:08:47 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-47-230.md
Jan 24, 2024 3:08:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-48-914.md
Jan 24, 2024 3:08:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-49-385.md
Jan 24, 2024 3:08:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-49-532.md
2024.01.24 15:08:56 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:08:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-56-186.md
Jan 24, 2024 3:08:58 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-08-58-729.md
2024.01.24 15:09:09 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:09:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-09-09-632.md
2024.01.24 15:09:10 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:09:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-09-10-486.md
Jan 24, 2024 3:09:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-09-10-634.md
Jan 24, 2024 3:09:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-09-11-106.md
2024.01.24 15:09:11 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:09:13 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:09:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-09-14-014.md
Jan 24, 2024 3:09:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-09-16-087.md
2024.01.24 15:09:16 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:09:16 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:09:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-09-16-966.md
Jan 24, 2024 3:09:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-09-18-202.md
2024.01.24 15:09:18 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:09:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-09-21-340.md
Jan 24, 2024 3:09:22 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-09-22-688.md
2024.01.24 15:09:23 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:09:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-09-23-335.md
2024.01.24 15:09:23 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:09:24 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-09-24-034.md
2024.01.24 15:09:23 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:09:24 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-09-24-484.md
Jan 24, 2024 3:09:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-09-25-095.md
2024.01.24 15:09:25 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:09:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-09-27-114.md
Jan 24, 2024 3:09:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-09-29-363.md
Jan 24, 2024 3:10:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-10-397.md
Jan 24, 2024 3:10:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-10-940.md
2024.01.24 15:10:11 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:10:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-11-553.md
2024.01.24 15:10:11 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:10:12 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:10:12 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-12-272.md
2024.01.24 15:10:12 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:10:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-13-040.md
Jan 24, 2024 3:10:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-14-110.md
Jan 24, 2024 3:10:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-14-634.md
Jan 24, 2024 3:10:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-15-140.md
Jan 24, 2024 3:10:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-15-753.md
Jan 24, 2024 3:10:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-16-354.md
Jan 24, 2024 3:10:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-16-864.md
Jan 24, 2024 3:10:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-17-400.md
2024.01.24 15:10:17 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:10:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-18-039.md
Jan 24, 2024 3:10:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-18-670.md
Jan 24, 2024 3:10:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-19-131.md
2024.01.24 15:10:19 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:10:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-20-473.md
2024.01.24 15:10:20 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:10:22 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-22-326.md
Jan 24, 2024 3:10:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-23-718.md
2024.01.24 15:10:27 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 3:10:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-27-607.md
Jan 24, 2024 3:10:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-28-161.md
Jan 24, 2024 3:10:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-28-681.md
2024.01.24 15:10:28 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 15:10:29 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 3:10:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-29-672.md
Jan 24, 2024 3:10:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-30-132.md
Jan 24, 2024 3:10:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-30-772.md
Jan 24, 2024 3:10:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-31-340.md
2024.01.24 15:10:31 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

Jan 24, 2024 3:10:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-32-306.md
Jan 24, 2024 3:10:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-33-047.md
2024.01.24 15:10:33 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/MyProducer.java. Output:

2024.01.24 15:10:35 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\MyProducer.java
Jan 24, 2024 3:10:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-35-796.md
Jan 24, 2024 3:10:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-36-926.md
Jan 24, 2024 3:10:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-46-012.md
Jan 24, 2024 3:10:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-46-441.md
Jan 24, 2024 3:10:47 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-47-142.md
Jan 24, 2024 3:10:47 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-47-742.md
2024.01.24 15:10:47 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:10:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-48-173.md
2024.01.24 15:10:48 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:10:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-48-655.md
Jan 24, 2024 3:10:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-49-007.md
Jan 24, 2024 3:10:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-49-178.md
Jan 24, 2024 3:10:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-49-748.md
2024.01.24 15:10:49 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:10:50 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:10:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-50-343.md
2024.01.24 15:10:51 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:10:51 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-51-156.md
2024.01.24 15:10:59 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:10:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-59-074.md
Jan 24, 2024 3:10:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-59-101.md
Jan 24, 2024 3:10:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-59-557.md
Jan 24, 2024 3:10:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-59-814.md
Jan 24, 2024 3:10:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-10-59-851.md
2024.01.24 15:11:00 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:11:00 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-00-283.md
Jan 24, 2024 3:11:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-01-509.md
Jan 24, 2024 3:11:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-01-654.md
Jan 24, 2024 3:11:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-01-891.md
2024.01.24 15:11:02 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:11:02 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-02-279.md
Jan 24, 2024 3:11:02 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-02-751.md
2024.01.24 15:11:03 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:11:03 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-03-702.md
2024.01.24 15:11:04 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:11:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-04-308.md
2024.01.24 15:11:05 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:11:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-05-567.md
2024.01.24 15:11:16 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:11:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-16-743.md
2024.01.24 15:11:17 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:11:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-17-973.md
2024.01.24 15:11:18 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:11:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-19-684.md
2024.01.24 15:11:19 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:11:21 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:11:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-21-519.md
2024.01.24 15:11:21 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:11:22 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-22-051.md
Jan 24, 2024 3:11:22 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-22-643.md
2024.01.24 15:11:23 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:11:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-23-258.md
2024.01.24 15:11:24 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:11:24 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-24-137.md
2024.01.24 15:11:28 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:11:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-28-181.md
Jan 24, 2024 3:11:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-29-523.md
Jan 24, 2024 3:11:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-29-720.md
Jan 24, 2024 3:11:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-30-485.md
Jan 24, 2024 3:11:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-30-663.md
Jan 24, 2024 3:11:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-31-010.md
2024.01.24 15:11:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:11:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-32-887.md
2024.01.24 15:11:33 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:11:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-33-514.md
2024.01.24 15:11:34 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:11:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-34-294.md
2024.01.24 15:11:34 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:11:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-35-820.md
2024.01.24 15:11:49 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:11:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-49-774.md
2024.01.24 15:11:50 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:11:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-11-50-439.md
Jan 24, 2024 3:13:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-08-502.md
Jan 24, 2024 3:13:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-11-584.md
Jan 24, 2024 3:13:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-14-790.md
Jan 24, 2024 3:13:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-16-018.md
Jan 24, 2024 3:13:22 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-22-612.md
Jan 24, 2024 3:13:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-23-548.md
Jan 24, 2024 3:13:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-25-449.md
Jan 24, 2024 3:13:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-26-345.md
Jan 24, 2024 3:13:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-33-156.md
2024.01.24 15:13:35 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:13:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-35-762.md
Jan 24, 2024 3:13:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-36-277.md
Jan 24, 2024 3:13:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-36-693.md
2024.01.24 15:13:37 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:13:37 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-37-348.md
2024.01.24 15:13:39 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:13:39 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-39-410.md
Jan 24, 2024 3:13:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-40-498.md
2024.01.24 15:13:40 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:13:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-40-894.md
Jan 24, 2024 3:13:44 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-44-424.md
Jan 24, 2024 3:13:44 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-44-975.md
2024.01.24 15:13:45 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:13:46 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:13:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-46-129.md
Jan 24, 2024 3:13:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-46-848.md
2024.01.24 15:13:47 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:13:47 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-47-302.md
2024.01.24 15:13:49 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:13:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-49-424.md
2024.01.24 15:13:50 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Myconsumer.java
Jan 24, 2024 3:13:51 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-51-060.md
Jan 24, 2024 3:13:53 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-53-878.md
Jan 24, 2024 3:13:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-55-011.md
2024.01.24 15:13:58 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:13:58 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-58-619.md
2024.01.24 15:13:59 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Myconsumer.java
Jan 24, 2024 3:13:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-13-59-684.md
Jan 24, 2024 3:14:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-14-01-663.md
2024.01.24 15:14:01 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:17:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-17-56-932.md
Jan 24, 2024 3:17:57 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-17-57-452.md
Jan 24, 2024 3:17:57 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-17-57-930.md
Jan 24, 2024 3:17:58 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-17-58-538.md
Jan 24, 2024 3:17:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-17-59-134.md
2024.01.24 15:17:59 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:17:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-17-59-659.md
Jan 24, 2024 3:18:00 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-00-286.md
2024.01.24 15:18:00 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:18:00 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-00-993.md
Jan 24, 2024 3:18:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-01-510.md
2024.01.24 15:18:01 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:18:02 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-02-570.md
2024.01.24 15:18:02 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:18:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-04-771.md
Jan 24, 2024 3:18:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-05-250.md
Jan 24, 2024 3:18:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-05-673.md
Jan 24, 2024 3:18:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-06-187.md
2024.01.24 15:18:06 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:18:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-13-015.md
2024.01.24 15:18:13 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:18:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-13-189.md
Jan 24, 2024 3:18:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-13-625.md
2024.01.24 15:18:14 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:18:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-14-159.md
2024.01.24 15:18:15 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:18:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-15-469.md
2024.01.24 15:18:16 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:18:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-16-076.md
Jan 24, 2024 3:18:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-16-115.md
Jan 24, 2024 3:18:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-16-723.md
Jan 24, 2024 3:18:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-17-309.md
2024.01.24 15:18:17 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:18:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-18-248.md
2024.01.24 15:18:18 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:18:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-18-508.md
Jan 24, 2024 3:18:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-18-901.md
Jan 24, 2024 3:18:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-19-447.md
Jan 24, 2024 3:18:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-20-000.md
2024.01.24 15:18:20 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:18:22 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-22-512.md
2024.01.24 15:18:22 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:18:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-33-739.md
Jan 24, 2024 3:18:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-34-178.md
2024.01.24 15:18:34 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:18:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-34-956.md
Jan 24, 2024 3:18:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-35-587.md
2024.01.24 15:18:35 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:18:36 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:18:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-36-321.md
Jan 24, 2024 3:18:37 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-37-239.md
2024.01.24 15:18:37 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:18:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-38-921.md
Jan 24, 2024 3:18:39 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-39-408.md
Jan 24, 2024 3:18:39 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-39-924.md
2024.01.24 15:18:40 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:18:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-49-784.md
Jan 24, 2024 3:18:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-50-619.md
Jan 24, 2024 3:18:58 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-18-58-662.md
Jan 24, 2024 3:19:00 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-00-325.md
2024.01.24 15:19:00 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:19:00 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-00-965.md
Jan 24, 2024 3:19:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-01-923.md
Jan 24, 2024 3:19:02 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-02-363.md
2024.01.24 15:19:02 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:19:03 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-03-334.md
Jan 24, 2024 3:19:03 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-03-865.md
2024.01.24 15:19:04 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:19:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-04-363.md
Jan 24, 2024 3:19:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-05-664.md
2024.01.24 15:19:05 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:19:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-06-111.md
Jan 24, 2024 3:19:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-07-710.md
Jan 24, 2024 3:19:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-07-840.md
Jan 24, 2024 3:19:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-08-063.md
Jan 24, 2024 3:19:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-08-229.md
Jan 24, 2024 3:19:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-08-500.md
2024.01.24 15:19:08 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:19:09 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:19:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-09-803.md
Jan 24, 2024 3:19:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-10-259.md
2024.01.24 15:19:10 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:19:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-10-809.md
2024.01.24 15:19:11 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:19:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-11-812.md
2024.01.24 15:19:25 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:19:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-25-163.md
Jan 24, 2024 3:19:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-25-328.md
Jan 24, 2024 3:19:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-25-768.md
Jan 24, 2024 3:19:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-26-256.md
2024.01.24 15:19:26 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:19:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-26-817.md
2024.01.24 15:19:27 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:19:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-27-360.md
2024.01.24 15:19:27 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:19:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-28-099.md
Jan 24, 2024 3:19:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-28-191.md
Jan 24, 2024 3:19:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-28-645.md
2024.01.24 15:19:28 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:19:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-29-405.md
2024.01.24 15:19:29 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:19:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:19:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-32-260.md
2024.01.24 15:19:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:19:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-32-754.md
Jan 24, 2024 3:19:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-40-876.md
Jan 24, 2024 3:19:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-42-558.md
Jan 24, 2024 3:19:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-42-730.md
Jan 24, 2024 3:19:44 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-44-206.md
2024.01.24 15:19:44 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:19:44 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-44-760.md
Jan 24, 2024 3:19:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-48-050.md
2024.01.24 15:19:48 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:19:49 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:19:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-49-284.md
Jan 24, 2024 3:19:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-49-376.md
Jan 24, 2024 3:19:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-50-186.md
Jan 24, 2024 3:19:54 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-54-411.md
Jan 24, 2024 3:19:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-55-285.md
Jan 24, 2024 3:19:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-55-549.md
2024.01.24 15:19:56 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:19:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-56-155.md
Jan 24, 2024 3:19:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-56-244.md
2024.01.24 15:19:56 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:19:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-19-56-689.md
2024.01.24 15:20:10 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:20:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-20-10-720.md
2024.01.24 15:20:11 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:20:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-20-11-618.md
Jan 24, 2024 3:20:12 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-20-12-035.md
2024.01.24 15:20:12 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:20:12 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-20-12-652.md
Jan 24, 2024 3:20:12 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-20-12-740.md
Jan 24, 2024 3:20:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-20-13-167.md
2024.01.24 15:20:13 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:20:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-20-14-180.md
2024.01.24 15:20:14 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:21:53 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-21-53-080.md
Jan 24, 2024 3:21:53 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-21-53-314.md
Jan 24, 2024 3:21:54 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-21-54-743.md
Jan 24, 2024 3:21:57 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-21-57-085.md
Jan 24, 2024 3:21:58 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-21-58-590.md
2024.01.24 15:22:00 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:00 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-00-210.md
2024.01.24 15:22:01 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-01-242.md
Jan 24, 2024 3:22:02 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-02-989.md
2024.01.24 15:22:03 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-04-466.md
Jan 24, 2024 3:22:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-04-916.md
2024.01.24 15:22:05 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-05-791.md
Jan 24, 2024 3:22:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-06-383.md
2024.01.24 15:22:06 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-09-291.md
2024.01.24 15:22:14 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-14-763.md
2024.01.24 15:22:15 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-15-403.md
2024.01.24 15:22:16 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-17-026.md
Jan 24, 2024 3:22:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-21-177.md
Jan 24, 2024 3:22:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-21-626.md
2024.01.24 15:22:21 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:22:22 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:22 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-22-599.md
Jan 24, 2024 3:22:22 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-22-907.md
Jan 24, 2024 3:22:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-23-346.md
2024.01.24 15:22:23 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:24 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-24-201.md
2024.01.24 15:22:24 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:22:24 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:24 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-24-921.md
Jan 24, 2024 3:22:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-26-159.md
2024.01.24 15:22:26 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-26-617.md
Jan 24, 2024 3:22:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-27-238.md
Jan 24, 2024 3:22:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-27-318.md
Jan 24, 2024 3:22:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-27-758.md
2024.01.24 15:22:28 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-28-311.md
2024.01.24 15:22:28 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-28-970.md
Jan 24, 2024 3:22:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-30-874.md
Jan 24, 2024 3:22:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-31-073.md
Jan 24, 2024 3:22:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-31-317.md
Jan 24, 2024 3:22:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-31-440.md
Jan 24, 2024 3:22:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-31-681.md
Jan 24, 2024 3:22:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-31-888.md
2024.01.24 15:22:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-32-090.md
2024.01.24 15:22:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-32-558.md
2024.01.24 15:22:33 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-33-351.md
2024.01.24 15:22:33 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-34-039.md
2024.01.24 15:22:34 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-34-604.md
2024.01.24 15:22:41 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:41 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-41-613.md
2024.01.24 15:22:42 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-42-813.md
Jan 24, 2024 3:22:47 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-47-915.md
2024.01.24 15:22:48 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-48-368.md
Jan 24, 2024 3:22:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-48-682.md
Jan 24, 2024 3:22:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-48-882.md
Jan 24, 2024 3:22:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-49-090.md
Jan 24, 2024 3:22:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-49-159.md
Jan 24, 2024 3:22:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-49-355.md
2024.01.24 15:22:49 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-49-795.md
Jan 24, 2024 3:22:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-50-373.md
2024.01.24 15:22:50 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-50-844.md
Jan 24, 2024 3:22:53 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-53-933.md
Jan 24, 2024 3:22:54 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-54-605.md
Jan 24, 2024 3:22:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-55-572.md
2024.01.24 15:22:55 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-56-024.md
2024.01.24 15:22:58 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:22:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-22-59-022.md
2024.01.24 15:23:00 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:23:00 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-23-00-166.md
Jan 24, 2024 3:23:00 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-23-00-650.md
Jan 24, 2024 3:23:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-23-01-203.md
2024.01.24 15:23:01 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:23:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-23-01-664.md
Jan 24, 2024 3:23:03 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-23-03-034.md
2024.01.24 15:23:09 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:23:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-23-09-747.md
2024.01.24 15:23:10 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:23:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-23-10-839.md
2024.01.24 15:23:11 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:23:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-23-11-737.md
Jan 24, 2024 3:23:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-23-36-369.md
Jan 24, 2024 3:23:37 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-23-37-555.md
Jan 24, 2024 3:23:39 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-23-39-056.md
Jan 24, 2024 3:23:39 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-23-39-630.md
Jan 24, 2024 3:23:43 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-23-43-624.md
Jan 24, 2024 3:23:43 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6852
Jan 24, 2024 3:25:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-25-16-088.md
2024.01.24 15:25:16 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:25:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-25-17-803.md
Jan 24, 2024 3:25:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-25-18-092.md
Jan 24, 2024 3:25:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-25-18-519.md
Jan 24, 2024 3:25:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-25-18-560.md
2024.01.24 15:25:19 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:25:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-25-19-226.md
Jan 24, 2024 3:25:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-25-19-814.md
Jan 24, 2024 3:25:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-25-20-387.md
Jan 24, 2024 3:25:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-25-20-505.md
Jan 24, 2024 3:25:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-25-20-894.md
Jan 24, 2024 3:25:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-25-20-938.md
Jan 24, 2024 3:25:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-25-21-127.md
2024.01.24 15:25:21 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:25:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-25-21-595.md
Jan 24, 2024 3:25:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-25-26-788.md
2024.01.24 15:25:26 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:25:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-25-27-720.md
2024.01.24 15:25:27 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:25:31 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:25:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-25-31-448.md
Jan 24, 2024 3:25:37 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-25-37-302.md
Jan 24, 2024 3:25:39 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-25-39-702.md
Jan 24, 2024 3:25:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-25-42-792.md
Jan 24, 2024 3:26:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-07-709.md
Jan 24, 2024 3:26:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-09-993.md
2024.01.24 15:26:11 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:26:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-11-511.md
2024.01.24 15:26:12 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:26:12 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-12-195.md
2024.01.24 15:26:12 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:26:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-13-058.md
Jan 24, 2024 3:26:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-14-039.md
Jan 24, 2024 3:26:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-14-324.md
Jan 24, 2024 3:26:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-14-861.md
Jan 24, 2024 3:26:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-15-779.md
Jan 24, 2024 3:26:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-16-350.md
Jan 24, 2024 3:26:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-16-790.md
Jan 24, 2024 3:26:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-17-565.md
Jan 24, 2024 3:26:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-18-047.md
2024.01.24 15:26:18 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:26:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-18-596.md
Jan 24, 2024 3:26:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-19-808.md
Jan 24, 2024 3:26:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-20-096.md
Jan 24, 2024 3:26:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-20-883.md
Jan 24, 2024 3:26:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-21-560.md
Jan 24, 2024 3:26:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-21-984.md
Jan 24, 2024 3:26:22 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-22-520.md
Jan 24, 2024 3:26:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-23-155.md
2024.01.24 15:26:23 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:26:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-23-783.md
Jan 24, 2024 3:26:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-25-080.md
Jan 24, 2024 3:26:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-25-236.md
Jan 24, 2024 3:26:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-25-971.md
Jan 24, 2024 3:26:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-26-577.md
2024.01.24 15:26:26 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:26:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-27-020.md
2024.01.24 15:26:27 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:26:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-27-474.md
2024.01.24 15:26:27 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:26:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-27-965.md
Jan 24, 2024 3:26:28 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 6999
2024.01.24 15:26:28 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:26:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-28-728.md
Jan 24, 2024 3:26:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-30-443.md
2024.01.24 15:26:30 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:26:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-31-001.md
2024.01.24 15:26:31 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:26:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-31-545.md
Jan 24, 2024 3:26:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-32-288.md
Jan 24, 2024 3:26:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-34-055.md
Jan 24, 2024 3:26:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-34-500.md
2024.01.24 15:26:34 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:26:35 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:26:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-35-993.md
Jan 24, 2024 3:26:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-36-630.md
Jan 24, 2024 3:26:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-38-246.md
Jan 24, 2024 3:26:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-38-648.md
Jan 24, 2024 3:26:39 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-39-121.md
2024.01.24 15:26:39 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:26:40 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:26:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-40-800.md
Jan 24, 2024 3:26:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-46-075.md
Jan 24, 2024 3:26:46 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-46-252.md
Jan 24, 2024 3:26:47 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-47-295.md
Jan 24, 2024 3:26:47 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-47-645.md
Jan 24, 2024 3:26:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-48-549.md
Jan 24, 2024 3:26:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-49-790.md
Jan 24, 2024 3:26:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-50-224.md
Jan 24, 2024 3:26:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-50-829.md
Jan 24, 2024 3:26:51 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-51-400.md
2024.01.24 15:26:51 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:26:51 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-26-51-857.md
Jan 24, 2024 3:27:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-27-20-207.md
Jan 24, 2024 3:27:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-27-25-362.md
2024.01.24 15:27:25 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:27:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-27-27-369.md
Jan 24, 2024 3:27:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-27-27-527.md
Jan 24, 2024 3:27:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-27-29-224.md
2024.01.24 15:27:29 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:27:38 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:27:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-27-38-690.md
2024.01.24 15:27:39 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:27:39 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-27-39-251.md
Jan 24, 2024 3:27:43 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-27-43-753.md
Jan 24, 2024 3:27:47 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-27-47-599.md
Jan 24, 2024 3:27:58 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-27-58-247.md
Jan 24, 2024 3:27:58 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-27-58-721.md
Jan 24, 2024 3:27:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-27-59-361.md
Jan 24, 2024 3:27:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-27-59-874.md
2024.01.24 15:28:00 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:28:00 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-00-344.md
Jan 24, 2024 3:28:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-01-259.md
Jan 24, 2024 3:28:01 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 7128
Jan 24, 2024 3:28:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-01-714.md
Jan 24, 2024 3:28:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-01-952.md
Jan 24, 2024 3:28:02 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-02-395.md
2024.01.24 15:28:02 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:28:03 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:28:03 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-03-365.md
Jan 24, 2024 3:28:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-05-850.md
Jan 24, 2024 3:28:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-09-868.md
Jan 24, 2024 3:28:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-11-550.md
Jan 24, 2024 3:28:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-11-994.md
2024.01.24 15:28:12 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:28:12 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-12-554.md
2024.01.24 15:28:13 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:28:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-13-373.md
2024.01.24 15:28:16 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:28:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-16-570.md
Jan 24, 2024 3:28:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-17-048.md
Jan 24, 2024 3:28:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-17-487.md
Jan 24, 2024 3:28:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-18-202.md
Jan 24, 2024 3:28:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-18-712.md
2024.01.24 15:28:19 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:28:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-19-208.md
Jan 24, 2024 3:28:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-20-951.md
2024.01.24 15:28:21 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:28:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-21-468.md
Jan 24, 2024 3:28:22 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-22-200.md
2024.01.24 15:28:22 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:28:25 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:28:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-25-108.md
Jan 24, 2024 3:28:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-25-401.md
Jan 24, 2024 3:28:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-25-814.md
Jan 24, 2024 3:28:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-26-289.md
Jan 24, 2024 3:28:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-26-831.md
2024.01.24 15:28:27 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:28:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-27-296.md
Jan 24, 2024 3:28:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-28-001.md
2024.01.24 15:28:28 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:28:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-28-225.md
2024.01.24 15:28:28 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:28:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-28-636.md
2024.01.24 15:28:29 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:28:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-29-258.md
Jan 24, 2024 3:28:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-29-747.md
2024.01.24 15:28:30 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:28:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-30-309.md
2024.01.24 15:28:33 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:28:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-33-774.md
2024.01.24 15:28:34 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:28:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-34-637.md
Jan 24, 2024 3:28:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-36-080.md
Jan 24, 2024 3:28:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-38-009.md
2024.01.24 15:28:51 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:28:51 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-51-095.md
2024.01.24 15:28:51 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:28:52 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-52-016.md
2024.01.24 15:28:53 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:28:53 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-53-248.md
Jan 24, 2024 3:28:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-56-069.md
Jan 24, 2024 3:28:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-56-588.md
2024.01.24 15:28:56 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:28:57 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-57-775.md
2024.01.24 15:28:57 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:28:58 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-58-492.md
2024.01.24 15:28:59 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:28:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-28-59-148.md
2024.01.24 15:28:59 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:29:00 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-00-081.md
Jan 24, 2024 3:29:00 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-00-664.md
2024.01.24 15:29:01 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:29:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-01-186.md
2024.01.24 15:29:01 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:29:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-01-909.md
2024.01.24 15:29:02 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:29:03 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-03-324.md
2024.01.24 15:29:03 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:29:03 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-03-809.md
Jan 24, 2024 3:29:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-04-712.md
2024.01.24 15:29:05 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:29:07 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:29:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-07-785.md
Jan 24, 2024 3:29:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-10-107.md
2024.01.24 15:29:10 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:29:10 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:29:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-10-789.md
Jan 24, 2024 3:29:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-11-256.md
2024.01.24 15:29:11 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:29:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-11-781.md
2024.01.24 15:29:12 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:29:12 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-12-316.md
Jan 24, 2024 3:29:12 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-12-729.md
2024.01.24 15:29:13 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:29:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-13-219.md
Jan 24, 2024 3:29:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-13-754.md
Jan 24, 2024 3:29:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-14-239.md
2024.01.24 15:29:14 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:29:14 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:29:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-15-520.md
Jan 24, 2024 3:29:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-17-351.md
Jan 24, 2024 3:29:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-27-167.md
Jan 24, 2024 3:29:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-28-580.md
Jan 24, 2024 3:29:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-29-689.md
2024.01.24 15:29:31 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:29:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-31-802.md
Jan 24, 2024 3:29:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-35-230.md
2024.01.24 15:29:36 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:29:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-36-926.md
Jan 24, 2024 3:29:39 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-39-351.md
2024.01.24 15:29:41 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:29:41 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-41-335.md
2024.01.24 15:29:47 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:29:47 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-47-272.md
Jan 24, 2024 3:29:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-48-006.md
Jan 24, 2024 3:29:48 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-48-436.md
2024.01.24 15:29:48 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:29:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-49-029.md
Jan 24, 2024 3:29:51 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-51-209.md
2024.01.24 15:29:51 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:29:51 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-51-858.md
2024.01.24 15:29:52 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:29:52 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-52-857.md
2024.01.24 15:29:53 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:29:53 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-53-647.md
Jan 24, 2024 3:29:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-55-074.md
Jan 24, 2024 3:29:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-55-286.md
Jan 24, 2024 3:29:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-29-55-585.md
2024.01.24 15:30:00 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:30:00 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-30-00-990.md
Jan 24, 2024 3:30:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-30-04-178.md
Jan 24, 2024 3:30:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-30-04-432.md
Jan 24, 2024 3:30:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-30-04-881.md
Jan 24, 2024 3:30:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-30-06-358.md
Jan 24, 2024 3:30:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-30-06-863.md
2024.01.24 15:30:07 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:30:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-30-08-247.md
Jan 24, 2024 3:30:08 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-30-08-738.md
Jan 24, 2024 3:30:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-30-09-201.md
2024.01.24 15:30:09 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:30:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-30-09-724.md
2024.01.24 15:30:15 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Myconsumer.java
Jan 24, 2024 3:30:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-30-15-340.md
Jan 24, 2024 3:30:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-30-18-655.md
Jan 24, 2024 3:30:24 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-30-24-495.md
Jan 24, 2024 3:30:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-30-24-997.md
2024.01.24 15:30:30 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:30:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-30-30-365.md
2024.01.24 15:30:31 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:30:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-30-31-433.md
Jan 24, 2024 3:30:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-30-32-207.md
Jan 24, 2024 3:30:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-30-32-421.md
Jan 24, 2024 3:30:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-30-32-845.md
2024.01.24 15:30:33 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Myconsumer.java
Jan 24, 2024 3:30:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-30-33-567.md
Jan 24, 2024 3:30:54 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-30-54-110.md
Jan 24, 2024 3:30:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-30-59-863.md
2024.01.24 15:31:05 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:31:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-05-674.md
Jan 24, 2024 3:31:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-06-559.md
Jan 24, 2024 3:31:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-10-341.md
2024.01.24 15:31:10 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:31:10 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-10-911.md
2024.01.24 15:31:10 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:31:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-11-449.md
Jan 24, 2024 3:31:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-11-901.md
Jan 24, 2024 3:31:12 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-12-453.md
2024.01.24 15:31:12 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:31:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-13-718.md
Jan 24, 2024 3:31:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-14-314.md
Jan 24, 2024 3:31:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-14-838.md
Jan 24, 2024 3:31:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-15-265.md
2024.01.24 15:31:15 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:31:15 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:31:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-16-065.md
2024.01.24 15:31:16 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:31:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-16-899.md
2024.01.24 15:31:17 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:31:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-17-476.md
Jan 24, 2024 3:31:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-21-732.md
2024.01.24 15:31:21 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:31:22 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-22-478.md
2024.01.24 15:31:22 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:31:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-23-048.md
Jan 24, 2024 3:31:23 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-23-714.md
2024.01.24 15:31:23 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:31:24 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-24-393.md
Jan 24, 2024 3:31:24 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-24-943.md
2024.01.24 15:31:25 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:31:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-25-640.md
Jan 24, 2024 3:31:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-26-098.md
2024.01.24 15:31:26 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:31:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-26-787.md
2024.01.24 15:31:27 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:31:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-27-795.md
Jan 24, 2024 3:31:28 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-28-512.md
Jan 24, 2024 3:31:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-29-041.md
Jan 24, 2024 3:31:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-29-639.md
2024.01.24 15:31:30 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:31:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-30-278.md
Jan 24, 2024 3:31:30 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-30-762.md
Jan 24, 2024 3:31:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-31-279.md
Jan 24, 2024 3:31:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-31-830.md
2024.01.24 15:31:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:31:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-32-401.md
Jan 24, 2024 3:31:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-33-186.md
2024.01.24 15:31:33 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:31:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-33-783.md
2024.01.24 15:31:34 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

2024.01.24 15:31:35 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:31:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-35-620.md
Jan 24, 2024 3:31:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-36-780.md
Jan 24, 2024 3:31:37 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-37-267.md
Jan 24, 2024 3:31:37 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-37-730.md
Jan 24, 2024 3:31:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-38-302.md
Jan 24, 2024 3:31:38 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-38-778.md
2024.01.24 15:31:39 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:31:39 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-39-255.md
Jan 24, 2024 3:31:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-40-898.md
2024.01.24 15:31:42 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Myconsumer.java. Output:

Jan 24, 2024 3:31:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-42-233.md
2024.01.24 15:31:44 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Myconsumer.java
Jan 24, 2024 3:31:44 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-31-44-634.md
Jan 24, 2024 3:33:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-33-05-748.md
Jan 24, 2024 3:33:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-33-13-431.md
Jan 24, 2024 3:35:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-35-26-365.md
Jan 24, 2024 3:35:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-35-34-879.md
Jan 24, 2024 3:35:47 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-35-47-493.md
2024.01.24 15:35:55 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Consumer\Myconsumer.java
2024.01.24 15:35:55 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Consumer/Myconsumer.java. Output:

Jan 24, 2024 3:35:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-35-55-593.md
Jan 24, 2024 3:35:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-35-56-588.md
Jan 24, 2024 3:36:00 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-36-00-132.md
Jan 24, 2024 3:36:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-36-09-127.md
Jan 24, 2024 3:36:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-36-14-508.md
Jan 24, 2024 3:36:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-36-17-448.md
Jan 24, 2024 3:36:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-36-18-116.md
Jan 24, 2024 3:36:24 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-36-24-529.md
Jan 24, 2024 3:36:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-36-25-254.md
Jan 24, 2024 3:36:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-36-25-635.md
2024.01.24 15:36:26 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Producer\MyProducer.java
2024.01.24 15:36:26 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Producer/MyProducer.java. Output:

Jan 24, 2024 3:36:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-36-26-392.md
2024.01.24 15:36:26 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Producer\ConstConfig.java
2024.01.24 15:36:26 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Producer\Myproducer1.java
2024.01.24 15:36:26 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Producer/ConstConfig.java. Output:

2024.01.24 15:36:26 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Producer/Myproducer1.java. Output:

Jan 24, 2024 3:36:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-36-27-487.md
Jan 24, 2024 3:36:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-36-31-924.md
Jan 24, 2024 3:36:37 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-36-37-938.md
Jan 24, 2024 3:36:40 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-36-40-214.md
2024.01.24 15:36:49 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Consumer\ConstConfig.java
2024.01.24 15:36:49 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Consumer/ConstConfig.java. Output:

Jan 24, 2024 3:36:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-36-49-291.md
2024.01.24 15:36:49 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Consumer/ConstConfig.java. Output:

Jan 24, 2024 3:36:49 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-36-49-809.md
Jan 24, 2024 3:36:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-36-56-361.md
Jan 24, 2024 3:36:59 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-36-59-395.md
Jan 24, 2024 3:37:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-37-01-599.md
2024.01.24 15:37:03 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Consumer/ConstConfig.java. Output:

Jan 24, 2024 3:37:03 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-37-03-317.md
2024.01.24 15:37:03 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Consumer\ConstConfig.java
Jan 24, 2024 3:37:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-37-04-068.md
Jan 24, 2024 3:37:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-37-05-630.md
Jan 24, 2024 3:37:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-37-06-443.md
2024.01.24 15:37:10 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Consumer/ConstConfig.java. Output:

Jan 24, 2024 3:37:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-37-11-068.md
Jan 24, 2024 3:37:12 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-37-12-243.md
2024.01.24 15:37:12 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Consumer/ConstConfig.java. Output:

Jan 24, 2024 3:37:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-37-13-662.md
Jan 24, 2024 3:37:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-37-13-850.md
Jan 24, 2024 3:37:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-37-16-062.md
Jan 24, 2024 3:37:16 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-37-16-619.md
Jan 24, 2024 3:37:17 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-37-17-172.md
2024.01.24 15:37:17 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Consumer/ConstConfig.java. Output:

Jan 24, 2024 3:37:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-37-18-233.md
Jan 24, 2024 3:37:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-37-18-883.md
Jan 24, 2024 3:37:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-37-19-527.md
2024.01.24 15:37:19 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Consumer/ConstConfig.java. Output:

Jan 24, 2024 3:37:21 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-37-21-528.md
Jan 24, 2024 3:37:24 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-37-24-203.md
Jan 24, 2024 3:37:24 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-37-24-626.md
Jan 24, 2024 3:37:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-37-25-260.md
Jan 24, 2024 3:37:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-37-25-851.md
2024.01.24 15:37:26 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Consumer/ConstConfig.java. Output:

Jan 24, 2024 3:37:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-37-26-421.md
2024.01.24 15:37:27 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Consumer\ConstConfig.java
Jan 24, 2024 3:37:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-37-27-480.md
Jan 24, 2024 3:38:58 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-38-58-231.md
Jan 24, 2024 3:39:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-39-01-394.md
Jan 24, 2024 3:39:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-39-01-574.md
Jan 24, 2024 3:39:01 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-39-01-745.md
Jan 24, 2024 3:39:03 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-39-03-750.md
Jan 24, 2024 3:39:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-39-04-210.md
2024.01.24 15:39:04 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Producer/ConstConfig.java. Output:

Jan 24, 2024 3:39:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-39-04-813.md
Jan 24, 2024 3:39:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-39-05-383.md
2024.01.24 15:39:05 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Producer/ConstConfig.java. Output:

2024.01.24 15:39:07 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/Producer/ConstConfig.java. Output:

Jan 24, 2024 3:39:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-39-07-379.md
2024.01.24 15:39:09 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\Producer\ConstConfig.java
Jan 24, 2024 3:39:09 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-39-09-030.md
Jan 24, 2024 3:39:12 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-39-12-149.md
Jan 24, 2024 3:39:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-39-19-981.md
Jan 24, 2024 3:39:20 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-39-20-843.md
2024.01.24 15:42:44 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\ConsumerApp\ConstConfig.java
2024.01.24 15:42:44 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\ConsumerApp\Myconsumer.java
2024.01.24 15:42:44 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConsumerApp/ConstConfig.java. Output:

2024.01.24 15:42:44 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ConsumerApp/Myconsumer.java. Output:

Jan 24, 2024 3:42:44 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-42-44-427.md
Jan 24, 2024 3:42:45 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-42-45-624.md
Jan 24, 2024 3:42:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-42-55-144.md
Jan 24, 2024 3:42:57 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-42-57-909.md
Jan 24, 2024 3:43:02 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-43-02-362.md
Jan 24, 2024 3:43:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-43-06-963.md
Jan 24, 2024 3:43:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-43-11-578.md
Jan 24, 2024 3:43:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-43-13-937.md
Jan 24, 2024 3:43:15 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-43-15-987.md
2024.01.24 15:43:18 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\ProducerApp\MyProducer.java
2024.01.24 15:43:18 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\ProducerApp\Myproducer1.java
2024.01.24 15:43:18 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\ProducerApp\ConstConfig.java
Jan 24, 2024 3:43:18 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-43-18-653.md
2024.01.24 15:43:18 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ProducerApp/MyProducer.java. Output:

2024.01.24 15:43:18 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ProducerApp/ConstConfig.java. Output:

2024.01.24 15:43:18 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ProducerApp/Myproducer1.java. Output:

Jan 24, 2024 3:43:31 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-43-31-100.md
2024.01.24 15:43:39 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\ProducerApp\ConstConfig.java
Jan 24, 2024 3:43:39 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-43-39-849.md
Jan 24, 2024 3:43:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-43-42-053.md
Jan 24, 2024 3:43:42 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-43-42-789.md
2024.01.24 15:43:43 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\ProducerApp\Myproducer1.java
Jan 24, 2024 3:43:43 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-43-43-389.md
Jan 24, 2024 3:43:44 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-43-44-888.md
Jan 24, 2024 3:43:45 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-43-45-158.md
2024.01.24 15:43:45 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\ProducerApp\MyProducer.java
Jan 24, 2024 3:43:45 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-43-45-940.md
Jan 24, 2024 3:43:55 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-43-55-748.md
Jan 24, 2024 3:43:56 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-43-56-891.md
Jan 24, 2024 3:43:58 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-43-58-172.md
2024.01.24 15:44:13 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\ProducerApp\MyProducer.java
2024.01.24 15:44:13 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ProducerApp/MyProducer.java. Output:

Jan 24, 2024 3:44:13 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-44-13-541.md
Jan 24, 2024 3:44:14 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-44-14-061.md
Jan 24, 2024 3:44:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-44-19-218.md
Jan 24, 2024 3:44:22 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-44-22-098.md
Jan 24, 2024 3:44:24 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-44-24-920.md
2024.01.24 15:44:25 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ProducerApp/MyProducer.java. Output:

Jan 24, 2024 3:44:25 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-44-25-437.md
2024.01.24 15:44:26 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ProducerApp/MyProducer.java. Output:

Jan 24, 2024 3:44:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-44-26-192.md
Jan 24, 2024 3:44:26 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-44-26-795.md
2024.01.24 15:44:27 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ProducerApp/MyProducer.java. Output:

Jan 24, 2024 3:44:27 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-44-27-425.md
Jan 24, 2024 3:44:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-44-29-011.md
Jan 24, 2024 3:44:29 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-44-29-451.md
Jan 24, 2024 3:44:32 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-44-32-877.md
2024.01.24 15:44:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ProducerApp/MyProducer.java. Output:

2024.01.24 15:44:32 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ProducerApp/MyProducer.java. Output:

Jan 24, 2024 3:44:33 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-44-33-973.md
Jan 24, 2024 3:44:34 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-44-34-519.md
2024.01.24 15:44:34 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ProducerApp/MyProducer.java. Output:

2024.01.24 15:44:35 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ProducerApp/MyProducer.java. Output:

Jan 24, 2024 3:44:35 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-44-35-947.md
Jan 24, 2024 3:44:36 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-44-36-718.md
2024.01.24 15:44:36 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ProducerApp/MyProducer.java. Output:

2024.01.24 15:44:37 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ProducerApp/MyProducer.java. Output:

Jan 24, 2024 3:44:37 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-44-37-823.md
2024.01.24 15:44:44 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ProducerApp/MyProducer.java. Output:

Jan 24, 2024 3:44:44 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-44-44-124.md
2024.01.24 15:44:44 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ProducerApp/MyProducer.java. Output:

2024.01.24 15:44:45 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ProducerApp/MyProducer.java. Output:

Jan 24, 2024 3:44:45 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-44-45-649.md
2024.01.24 15:44:50 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ProducerApp/MyProducer.java. Output:

Jan 24, 2024 3:44:50 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-44-50-526.md
2024.01.24 15:44:52 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ProducerApp/MyProducer.java. Output:

Jan 24, 2024 3:44:52 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-44-52-286.md
Jan 24, 2024 3:46:03 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-46-03-446.md
Jan 24, 2024 3:46:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-46-03-983.md
2024.01.24 15:46:04 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ProducerApp/MyProducer.java. Output:

2024.01.24 15:46:04 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ProducerApp/MyProducer.java. Output:

Jan 24, 2024 3:46:04 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-46-04-702.md
2024.01.24 15:46:05 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ProducerApp/MyProducer.java. Output:

Jan 24, 2024 3:46:05 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-46-05-597.md
Jan 24, 2024 3:46:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-46-06-259.md
2024.01.24 15:46:06 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ProducerApp/MyProducer.java. Output:

Jan 24, 2024 3:46:06 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-46-06-789.md
Jan 24, 2024 3:46:07 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-46-07-416.md
2024.01.24 15:46:07 WARN  Running javac-semanticdb failed for file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/Kafka/ProducerApp/MyProducer.java. Output:

2024.01.24 15:46:11 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\ProducerApp\MyProducer.java
Jan 24, 2024 3:46:11 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-46-11-119.md
Jan 24, 2024 3:46:19 PM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-01-24\r_compiler-error_15-46-19-018.md
2024.01.24 21:53:15 INFO  Shutting down server
2024.01.24 21:53:15 INFO  shutting down Metals
2024.01.24 21:53:15 INFO  Exiting server
2024.01.30 21:27:57 INFO  Started: Metals version 1.2.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.2.
2024.01.30 21:27:59 WARN  Build server is not auto-connectable.
2024.01.30 21:27:59 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.01.30 21:27:59 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala
2024.01.30 21:28:03 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.01.30 21:28:05 INFO  time: code lens generation in 6.19s
2024.01.30 21:31:00 INFO  Shutting down server
2024.01.30 21:31:00 INFO  shutting down Metals
2024.01.30 21:31:00 INFO  Exiting server
2024.01.31 10:59:01 INFO  Started: Metals version 1.2.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.2.
2024.01.31 10:59:04 WARN  Build server is not auto-connectable.
2024.01.31 10:59:04 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.01.31 10:59:04 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala
2024.01.31 10:59:09 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.01.31 10:59:13 INFO  time: code lens generation in 9.02s
2024.01.31 21:32:55 INFO  Shutting down server
2024.01.31 21:32:55 INFO  shutting down Metals
2024.01.31 21:32:55 INFO  Exiting server
2024.02.01 10:44:01 INFO  Started: Metals version 1.2.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.85.2.
2024.02.01 10:44:04 WARN  Build server is not auto-connectable.
2024.02.01 10:44:04 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.02.01 10:44:04 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala
2024.02.01 10:44:12 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.02.01 10:44:16 INFO  time: code lens generation in 5.01s
2024.02.01 10:44:16 INFO  time: code lens generation in 11s
2024.02.01 22:03:07 INFO  Shutting down server
2024.02.01 22:03:07 INFO  shutting down Metals
2024.02.01 22:03:07 INFO  Exiting server
2024.02.02 10:35:18 INFO  Started: Metals version 1.2.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.86.0.
2024.02.02 10:35:19 WARN  Build server is not auto-connectable.
2024.02.02 10:35:19 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.02.02 10:35:19 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala
2024.02.02 10:35:21 INFO  Shutting down server
2024.02.02 10:35:21 INFO  shutting down Metals
2024.02.05 11:03:11 INFO  Started: Metals version 1.2.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.86.0.
2024.02.05 11:03:13 WARN  Build server is not auto-connectable.
2024.02.05 11:03:13 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.02.05 11:03:13 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala
2024.02.05 11:03:20 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.02.05 11:03:23 INFO  time: code lens generation in 10s
2024.02.05 11:04:50 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\ratings.scala
2024.02.05 11:05:19 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\filter.scala
2024.02.05 11:05:35 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\filter.scala
2024.02.05 11:05:40 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\filter.scala
2024.02.05 11:05:55 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\linkedin.scala
2024.02.05 11:09:42 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala
2024.02.05 11:10:10 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
2024.02.05 11:11:36 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
2024.02.05 11:16:31 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala
2024.02.05 11:22:35 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
2024.02.05 11:52:36 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2024.02.05 11:53:15 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala
2024.02.05 11:54:45 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala
2024.02.05 11:57:16 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12.scala
2024.02.05 11:58:16 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\Df andDs.scala
2024.02.05 12:00:16 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2024.02.05 12:00:37 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\columnDfandDS.scala
2024.02.05 12:00:41 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala
2024.02.05 12:01:09 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\week12_DfBroadcastJoin.scala
2024.02.05 12:01:43 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala
2024.02.05 12:04:13 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv2RddtoDF(case class).scala
2024.02.05 12:06:23 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\example.scala
2024.02.05 19:21:30 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala
2024.02.05 22:20:23 INFO  Shutting down server
2024.02.05 22:20:23 INFO  shutting down Metals
2024.02.05 22:20:23 INFO  Exiting server
2024.02.14 17:15:05 INFO  Started: Metals version 1.2.1 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.86.1.
Downloading https://repo1.maven.org/maven2/com/h2database/h2/2.1.214/h2-2.1.214.jar
2024.02.14 17:15:07 INFO  Upgraded H2 database.
17:15:07.642 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- Flyway Community Edition 9.22.3 by Redgate
17:15:07.642 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- See release notes here: https://rd.gt/416ObMi
17:15:07.642 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- 
17:15:07.650 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classpath resources at 'classpath:db/callback' ...
17:15:07.650 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Determining location urls for classpath:db/callback using ClassLoader jdk.internal.loader.ClassLoaders$AppClassLoader@70dea4e ...
17:15:07.650 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Unable to resolve location classpath:db/callback.
17:15:07.650 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classpath resources at 'classpath:db/migration' ...
17:15:07.650 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Determining location urls for classpath:db/migration using ClassLoader jdk.internal.loader.ClassLoaders$AppClassLoader@70dea4e ...
17:15:07.650 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning URL: jar:file:/C:/Users/pp255070/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/scalameta/metals_2.13/1.2.1/metals_2.13-1.2.1.jar!/db/migration
17:15:07.658 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/
17:15:07.658 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V1__Create_tables.sql
17:15:07.658 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V2__Server_discovery.sql
17:15:07.658 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V3__Jar_symbols.sql
17:15:07.658 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V4__Fingerprints.sql
17:15:07.658 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classes at classpath:db/migration
17:15:07.658 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
17:15:07.658 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V3__Jar_symbols.sql
17:15:07.666 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V2__Server_discovery.sql
17:15:07.666 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V4__Fingerprints.sql
17:15:07.666 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V1__Create_tables.sql
17:15:07.753 [pool-1-thread-1] INFO org.flywaydb.core.FlywayExecutor -- Database: jdbc:h2:file:C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\metals (H2 2.2)
17:15:07.753 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- Driver: H2 JDBC Driver 2.2.224 (2023-09-17)
17:15:07.753 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- DDL Transactions Supported: false
17:15:07.753 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.schemahistory.SchemaHistoryFactory -- Schemas: 
17:15:07.753 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.schemahistory.SchemaHistoryFactory -- Default schema: null
17:15:07.763 [pool-1-thread-1] WARN org.flywaydb.core.internal.database.base.Database -- Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
17:15:07.764 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.callback.SqlScriptCallbackFactory -- Scanning for SQL callbacks ...
17:15:07.764 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
17:15:07.770 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.command.DbValidate -- Validating migrations ...
17:15:07.770 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
17:15:07.778 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
17:15:07.778 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V3__Jar_symbols.sql (filename: V3__Jar_symbols.sql)
17:15:07.778 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V2__Server_discovery.sql (filename: V2__Server_discovery.sql)
17:15:07.778 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V4__Fingerprints.sql (filename: V4__Fingerprints.sql)
17:15:07.778 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V1__Create_tables.sql (filename: V1__Create_tables.sql)
17:15:07.778 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
17:15:07.778 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V3__Jar_symbols.sql (filename: V3__Jar_symbols.sql)
17:15:07.778 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V2__Server_discovery.sql (filename: V2__Server_discovery.sql)
17:15:07.778 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V4__Fingerprints.sql (filename: V4__Fingerprints.sql)
17:15:07.778 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V1__Create_tables.sql (filename: V1__Create_tables.sql)
17:15:07.803 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbValidate -- Successfully validated 4 migrations (execution time 00:00.031s)
17:15:07.803 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.command.DbSchemas -- Skipping creation of existing schema: "PUBLIC"
17:15:07.803 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbMigrate -- Current version of schema "PUBLIC": 4
17:15:07.803 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbMigrate -- Schema "PUBLIC" is up to date. No migration necessary.
17:15:07.819 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- Memory usage: 58 of 100M
2024.02.14 17:15:09 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.02.14 17:15:09 WARN  Build server is not auto-connectable.
2024.02.14 17:15:23 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala. Using presentation compiler with project's scala-library version: 3.3.1
Feb 14, 2024 5:15:23 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2
Feb 14, 2024 5:15:23 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1
Feb 14, 2024 5:15:24 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 9
Feb 14, 2024 5:15:24 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 8
2024.02.14 17:15:26 INFO  time: code lens generation in 2.46s
2024.02.14 17:15:26 INFO  time: code lens generation in 2.63s
2024.02.14 18:11:48 INFO  Shutting down server
2024.02.14 18:11:48 INFO  shutting down Metals
2024.02.14 18:11:48 INFO  Exiting server
2024.03.05 18:10:11 INFO  Started: Metals version 1.2.2 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.87.0.
18:10:11.811 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- Flyway Community Edition 9.22.3 by Redgate
18:10:11.813 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- See release notes here: https://rd.gt/416ObMi
18:10:11.813 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- 
18:10:11.815 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classpath resources at 'classpath:db/callback' ...
18:10:11.815 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Determining location urls for classpath:db/callback using ClassLoader jdk.internal.loader.ClassLoaders$AppClassLoader@70dea4e ...
18:10:11.815 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Unable to resolve location classpath:db/callback.
18:10:11.815 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classpath resources at 'classpath:db/migration' ...
18:10:11.815 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Determining location urls for classpath:db/migration using ClassLoader jdk.internal.loader.ClassLoaders$AppClassLoader@70dea4e ...
18:10:11.815 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning URL: jar:file:/C:/Users/pp255070/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/scalameta/metals_2.13/1.2.2/metals_2.13-1.2.2.jar!/db/migration
18:10:11.820 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/
18:10:11.821 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V1__Create_tables.sql
18:10:11.821 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V2__Server_discovery.sql
18:10:11.821 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V3__Jar_symbols.sql
18:10:11.821 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V4__Fingerprints.sql
18:10:11.821 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classes at classpath:db/migration
18:10:11.826 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
18:10:11.826 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V1__Create_tables.sql
18:10:11.826 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V3__Jar_symbols.sql
18:10:11.826 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V4__Fingerprints.sql
18:10:11.827 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V2__Server_discovery.sql
18:10:11.896 [pool-1-thread-1] INFO org.flywaydb.core.FlywayExecutor -- Database: jdbc:h2:file:C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\metals (H2 2.2)
18:10:11.896 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- Driver: H2 JDBC Driver 2.2.224 (2023-09-17)
18:10:11.896 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- DDL Transactions Supported: false
18:10:11.897 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.schemahistory.SchemaHistoryFactory -- Schemas: 
18:10:11.897 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.schemahistory.SchemaHistoryFactory -- Default schema: null
18:10:11.899 [pool-1-thread-1] WARN org.flywaydb.core.internal.database.base.Database -- Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
18:10:11.900 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.callback.SqlScriptCallbackFactory -- Scanning for SQL callbacks ...
18:10:11.901 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
18:10:11.907 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.command.DbValidate -- Validating migrations ...
18:10:11.909 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
18:10:11.913 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
18:10:11.913 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V1__Create_tables.sql (filename: V1__Create_tables.sql)
18:10:11.913 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V3__Jar_symbols.sql (filename: V3__Jar_symbols.sql)
18:10:11.913 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V4__Fingerprints.sql (filename: V4__Fingerprints.sql)
18:10:11.914 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V2__Server_discovery.sql (filename: V2__Server_discovery.sql)
18:10:11.914 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
18:10:11.914 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V1__Create_tables.sql (filename: V1__Create_tables.sql)
18:10:11.914 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V3__Jar_symbols.sql (filename: V3__Jar_symbols.sql)
18:10:11.914 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V4__Fingerprints.sql (filename: V4__Fingerprints.sql)
18:10:11.914 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V2__Server_discovery.sql (filename: V2__Server_discovery.sql)
18:10:11.920 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbValidate -- Successfully validated 4 migrations (execution time 00:00.013s)
18:10:11.921 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.command.DbSchemas -- Skipping creation of existing schema: "PUBLIC"
18:10:11.924 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbMigrate -- Current version of schema "PUBLIC": 4
18:10:11.928 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbMigrate -- Schema "PUBLIC" is up to date. No migration necessary.
18:10:11.933 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- Memory usage: 35 of 100M
2024.03.05 18:10:12 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.03.05 18:10:12 WARN  Build server is not auto-connectable.
2024.03.05 18:10:21 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala. Using presentation compiler with project's scala-library version: 3.3.1
Mar 05, 2024 6:10:22 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2
Mar 05, 2024 6:10:22 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1
Mar 05, 2024 6:10:22 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 4
2024.03.05 18:10:23 INFO  time: code lens generation in 1.48s
2024.03.05 18:11:59 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala
2024.03.05 18:15:47 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala
2024.03.05 18:15:51 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\word.scala
2024.03.05 21:41:56 INFO  Shutting down server
2024.03.05 21:41:56 INFO  shutting down Metals
2024.03.07 16:34:35 INFO  Started: Metals version 1.2.2 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.87.0.
16:34:35.704 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- Flyway Community Edition 9.22.3 by Redgate
16:34:35.707 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- See release notes here: https://rd.gt/416ObMi
16:34:35.707 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- 
16:34:35.710 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classpath resources at 'classpath:db/callback' ...
16:34:35.710 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Determining location urls for classpath:db/callback using ClassLoader jdk.internal.loader.ClassLoaders$AppClassLoader@70dea4e ...
16:34:35.710 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Unable to resolve location classpath:db/callback.
16:34:35.711 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classpath resources at 'classpath:db/migration' ...
16:34:35.711 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Determining location urls for classpath:db/migration using ClassLoader jdk.internal.loader.ClassLoaders$AppClassLoader@70dea4e ...
16:34:35.711 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning URL: jar:file:/C:/Users/pp255070/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/scalameta/metals_2.13/1.2.2/metals_2.13-1.2.2.jar!/db/migration
16:34:35.714 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/
16:34:35.714 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V1__Create_tables.sql
16:34:35.714 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V2__Server_discovery.sql
16:34:35.714 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V3__Jar_symbols.sql
16:34:35.715 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V4__Fingerprints.sql
16:34:35.715 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classes at classpath:db/migration
16:34:35.717 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
16:34:35.717 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V1__Create_tables.sql
16:34:35.718 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V3__Jar_symbols.sql
16:34:35.718 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V4__Fingerprints.sql
16:34:35.718 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V2__Server_discovery.sql
16:34:35.783 [pool-1-thread-1] INFO org.flywaydb.core.FlywayExecutor -- Database: jdbc:h2:file:C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\metals (H2 2.2)
16:34:35.783 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- Driver: H2 JDBC Driver 2.2.224 (2023-09-17)
16:34:35.783 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- DDL Transactions Supported: false
16:34:35.784 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.schemahistory.SchemaHistoryFactory -- Schemas: 
16:34:35.784 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.schemahistory.SchemaHistoryFactory -- Default schema: null
16:34:35.787 [pool-1-thread-1] WARN org.flywaydb.core.internal.database.base.Database -- Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
16:34:35.787 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.callback.SqlScriptCallbackFactory -- Scanning for SQL callbacks ...
16:34:35.787 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
16:34:35.793 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.command.DbValidate -- Validating migrations ...
16:34:35.795 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
16:34:35.801 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
16:34:35.801 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V1__Create_tables.sql (filename: V1__Create_tables.sql)
16:34:35.801 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V3__Jar_symbols.sql (filename: V3__Jar_symbols.sql)
16:34:35.801 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V4__Fingerprints.sql (filename: V4__Fingerprints.sql)
16:34:35.801 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V2__Server_discovery.sql (filename: V2__Server_discovery.sql)
16:34:35.801 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
16:34:35.802 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V1__Create_tables.sql (filename: V1__Create_tables.sql)
16:34:35.802 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V3__Jar_symbols.sql (filename: V3__Jar_symbols.sql)
16:34:35.802 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V4__Fingerprints.sql (filename: V4__Fingerprints.sql)
16:34:35.802 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V2__Server_discovery.sql (filename: V2__Server_discovery.sql)
16:34:35.809 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbValidate -- Successfully validated 4 migrations (execution time 00:00.015s)
16:34:35.810 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.command.DbSchemas -- Skipping creation of existing schema: "PUBLIC"
16:34:35.814 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbMigrate -- Current version of schema "PUBLIC": 4
16:34:35.817 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbMigrate -- Schema "PUBLIC" is up to date. No migration necessary.
16:34:35.824 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- Memory usage: 35 of 100M
2024.03.07 16:34:36 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.03.07 16:34:36 WARN  Build server is not auto-connectable.
2024.03.07 16:34:43 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\1.word.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.03.07 16:34:45 INFO  time: code lens generation in 8.62s
2024.03.07 22:25:42 INFO  Shutting down server
2024.03.07 22:25:42 INFO  shutting down Metals
2024.03.07 22:25:42 INFO  Exiting server
2024.03.12 14:12:42 INFO  Started: Metals version 1.2.2 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.87.1.
14:12:42.816 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- Flyway Community Edition 9.22.3 by Redgate
14:12:42.817 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- See release notes here: https://rd.gt/416ObMi
14:12:42.817 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- 
14:12:42.820 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classpath resources at 'classpath:db/callback' ...
14:12:42.820 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Determining location urls for classpath:db/callback using ClassLoader jdk.internal.loader.ClassLoaders$AppClassLoader@70dea4e ...
14:12:42.820 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Unable to resolve location classpath:db/callback.
14:12:42.820 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classpath resources at 'classpath:db/migration' ...
14:12:42.820 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Determining location urls for classpath:db/migration using ClassLoader jdk.internal.loader.ClassLoaders$AppClassLoader@70dea4e ...
14:12:42.821 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning URL: jar:file:/C:/Users/pp255070/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/scalameta/metals_2.13/1.2.2/metals_2.13-1.2.2.jar!/db/migration
14:12:42.825 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/
14:12:42.825 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V1__Create_tables.sql
14:12:42.825 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V2__Server_discovery.sql
14:12:42.825 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V3__Jar_symbols.sql
14:12:42.825 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V4__Fingerprints.sql
14:12:42.825 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classes at classpath:db/migration
14:12:42.828 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
14:12:42.828 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V1__Create_tables.sql
14:12:42.829 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V3__Jar_symbols.sql
14:12:42.829 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V4__Fingerprints.sql
14:12:42.829 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V2__Server_discovery.sql
14:12:42.894 [pool-1-thread-1] INFO org.flywaydb.core.FlywayExecutor -- Database: jdbc:h2:file:C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\metals (H2 2.2)
14:12:42.894 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- Driver: H2 JDBC Driver 2.2.224 (2023-09-17)
14:12:42.894 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- DDL Transactions Supported: false
14:12:42.895 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.schemahistory.SchemaHistoryFactory -- Schemas: 
14:12:42.895 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.schemahistory.SchemaHistoryFactory -- Default schema: null
14:12:42.897 [pool-1-thread-1] WARN org.flywaydb.core.internal.database.base.Database -- Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
14:12:42.898 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.callback.SqlScriptCallbackFactory -- Scanning for SQL callbacks ...
14:12:42.898 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
14:12:42.904 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.command.DbValidate -- Validating migrations ...
14:12:42.906 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
14:12:42.916 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
14:12:42.916 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V1__Create_tables.sql (filename: V1__Create_tables.sql)
14:12:42.916 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V3__Jar_symbols.sql (filename: V3__Jar_symbols.sql)
14:12:42.916 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V4__Fingerprints.sql (filename: V4__Fingerprints.sql)
14:12:42.916 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V2__Server_discovery.sql (filename: V2__Server_discovery.sql)
14:12:42.916 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
14:12:42.916 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V1__Create_tables.sql (filename: V1__Create_tables.sql)
14:12:42.916 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V3__Jar_symbols.sql (filename: V3__Jar_symbols.sql)
14:12:42.916 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V4__Fingerprints.sql (filename: V4__Fingerprints.sql)
14:12:42.916 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V2__Server_discovery.sql (filename: V2__Server_discovery.sql)
14:12:42.923 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbValidate -- Successfully validated 4 migrations (execution time 00:00.018s)
14:12:42.924 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.command.DbSchemas -- Skipping creation of existing schema: "PUBLIC"
14:12:42.927 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbMigrate -- Current version of schema "PUBLIC": 4
14:12:42.930 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbMigrate -- Schema "PUBLIC" is up to date. No migration necessary.
14:12:42.940 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- Memory usage: 36 of 100M
2024.03.12 14:12:43 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.03.12 14:12:44 WARN  Build server is not auto-connectable.
2024.03.12 14:12:51 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\1.word.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.03.12 14:12:53 INFO  time: code lens generation in 9.38s
2024.03.12 16:28:52 INFO  Shutting down server
2024.03.12 16:28:52 INFO  shutting down Metals
2024.03.12 16:28:52 INFO  Exiting server
2024.03.12 16:29:40 INFO  Started: Metals version 1.2.2 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.87.1.
16:29:40.816 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- Flyway Community Edition 9.22.3 by Redgate
16:29:40.818 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- See release notes here: https://rd.gt/416ObMi
16:29:40.818 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- 
16:29:40.820 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classpath resources at 'classpath:db/callback' ...
16:29:40.820 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Determining location urls for classpath:db/callback using ClassLoader jdk.internal.loader.ClassLoaders$AppClassLoader@70dea4e ...
16:29:40.820 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Unable to resolve location classpath:db/callback.
16:29:40.820 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classpath resources at 'classpath:db/migration' ...
16:29:40.820 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Determining location urls for classpath:db/migration using ClassLoader jdk.internal.loader.ClassLoaders$AppClassLoader@70dea4e ...
16:29:40.820 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning URL: jar:file:/C:/Users/pp255070/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/scalameta/metals_2.13/1.2.2/metals_2.13-1.2.2.jar!/db/migration
16:29:40.824 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/
16:29:40.824 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V1__Create_tables.sql
16:29:40.824 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V2__Server_discovery.sql
16:29:40.824 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V3__Jar_symbols.sql
16:29:40.824 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V4__Fingerprints.sql
16:29:40.824 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classes at classpath:db/migration
16:29:40.826 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
16:29:40.827 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V1__Create_tables.sql
16:29:40.827 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V3__Jar_symbols.sql
16:29:40.827 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V4__Fingerprints.sql
16:29:40.827 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V2__Server_discovery.sql
16:29:40.887 [pool-1-thread-1] INFO org.flywaydb.core.FlywayExecutor -- Database: jdbc:h2:file:C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\metals (H2 2.2)
16:29:40.887 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- Driver: H2 JDBC Driver 2.2.224 (2023-09-17)
16:29:40.887 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- DDL Transactions Supported: false
16:29:40.888 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.schemahistory.SchemaHistoryFactory -- Schemas: 
16:29:40.888 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.schemahistory.SchemaHistoryFactory -- Default schema: null
16:29:40.891 [pool-1-thread-1] WARN org.flywaydb.core.internal.database.base.Database -- Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
16:29:40.891 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.callback.SqlScriptCallbackFactory -- Scanning for SQL callbacks ...
16:29:40.891 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
16:29:40.896 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.command.DbValidate -- Validating migrations ...
16:29:40.897 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
16:29:40.901 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
16:29:40.901 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V1__Create_tables.sql (filename: V1__Create_tables.sql)
16:29:40.901 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V3__Jar_symbols.sql (filename: V3__Jar_symbols.sql)
16:29:40.901 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V4__Fingerprints.sql (filename: V4__Fingerprints.sql)
16:29:40.901 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V2__Server_discovery.sql (filename: V2__Server_discovery.sql)
16:29:40.902 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
16:29:40.902 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V1__Create_tables.sql (filename: V1__Create_tables.sql)
16:29:40.902 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V3__Jar_symbols.sql (filename: V3__Jar_symbols.sql)
16:29:40.902 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V4__Fingerprints.sql (filename: V4__Fingerprints.sql)
16:29:40.902 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V2__Server_discovery.sql (filename: V2__Server_discovery.sql)
16:29:40.907 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbValidate -- Successfully validated 4 migrations (execution time 00:00.011s)
16:29:40.908 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.command.DbSchemas -- Skipping creation of existing schema: "PUBLIC"
16:29:40.912 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbMigrate -- Current version of schema "PUBLIC": 4
16:29:40.914 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbMigrate -- Schema "PUBLIC" is up to date. No migration necessary.
16:29:40.921 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- Memory usage: 36 of 100M
2024.03.12 16:29:41 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.03.12 16:29:41 WARN  Build server is not auto-connectable.
2024.03.12 16:29:45 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\1.word.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.03.12 16:29:47 INFO  time: code lens generation in 5.62s
2024.03.12 16:34:02 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\1.word.scala
Mar 12, 2024 4:44:57 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 40
Mar 12, 2024 4:52:45 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 41
Mar 12, 2024 4:52:48 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 42
2024.03.12 16:54:26 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\customer.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.12 17:05:26 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\customer.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

Mar 12, 2024 5:05:32 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: java.lang.reflect.InvocationTargetException
java.lang.RuntimeException: java.lang.reflect.InvocationTargetException
	at org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint.lambda$null$0(GenericEndpoint.java:67)
	at org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint.request(GenericEndpoint.java:120)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.handleRequest(RemoteEndpoint.java:261)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.consume(RemoteEndpoint.java:190)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at org.eclipse.lsp4j.jsonrpc.json.ConcurrentMessageProcessor.run(ConcurrentMessageProcessor.java:113)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.lang.reflect.InvocationTargetException
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:118)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint.lambda$null$0(GenericEndpoint.java:65)
	... 11 more
Caused by: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/customer.scala:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.mtags.ScalaToplevelMtags.acceptBalancedDelimeters(ScalaToplevelMtags.scala:691)
	at scala.meta.internal.mtags.ScalaToplevelMtags.loop(ScalaToplevelMtags.scala:437)
	at scala.meta.internal.mtags.ScalaToplevelMtags.indexRoot(ScalaToplevelMtags.scala:56)
	at scala.meta.internal.mtags.MtagsIndexer.index(MtagsIndexer.scala:19)
	at scala.meta.internal.mtags.MtagsIndexer.index$(MtagsIndexer.scala:18)
	at scala.meta.internal.mtags.ScalaToplevelMtags.index(ScalaToplevelMtags.scala:43)
	at scala.meta.internal.mtags.Mtags$.allToplevels(Mtags.scala:125)
	at scala.meta.internal.metals.DefinitionProvider.fromMtags(DefinitionProvider.scala:376)
	at scala.meta.internal.metals.DefinitionProvider.$anonfun$positionOccurrence$4(DefinitionProvider.scala:296)
	at scala.Option.orElse(Option.scala:477)
	at scala.meta.internal.metals.DefinitionProvider.$anonfun$positionOccurrence$1(DefinitionProvider.scala:296)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.DefinitionProvider.positionOccurrence(DefinitionProvider.scala:288)
	at scala.meta.internal.metals.MetalsLspService.$anonfun$definitionOrReferences$1(MetalsLspService.scala:2564)
	at scala.Option.map(Option.scala:242)
	at scala.meta.internal.metals.MetalsLspService.definitionOrReferences(MetalsLspService.scala:2560)
	at scala.meta.internal.metals.MetalsLspService.$anonfun$definition$1(MetalsLspService.scala:1404)
	at scala.meta.internal.metals.CancelTokens$.future(CancelTokens.scala:38)
	at scala.meta.internal.metals.MetalsLspService.definition(MetalsLspService.scala:1403)
	at scala.meta.internal.metals.WorkspaceLspService.definition(WorkspaceLspService.scala:373)
	at scala.meta.metals.lsp.DelegatingScalaService.definition(DelegatingScalaService.scala:69)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	... 13 more

Mar 12, 2024 5:05:32 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint fallbackResponseError
SEVERE: Internal error: java.lang.reflect.InvocationTargetException
java.lang.RuntimeException: java.lang.reflect.InvocationTargetException
	at org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint.lambda$null$0(GenericEndpoint.java:67)
	at org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint.request(GenericEndpoint.java:120)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.handleRequest(RemoteEndpoint.java:261)
	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.consume(RemoteEndpoint.java:190)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
	at org.eclipse.lsp4j.jsonrpc.json.ConcurrentMessageProcessor.run(ConcurrentMessageProcessor.java:113)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:317)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Caused by: java.lang.reflect.InvocationTargetException
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:118)
	at java.base/java.lang.reflect.Method.invoke(Method.java:580)
	at org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint.lambda$null$0(GenericEndpoint.java:65)
	... 11 more
Caused by: file:///C:/Users/pp255070/OneDrive%20-%20Teradata/Documents/sparklearning/rdds/customer.scala:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.mtags.ScalaToplevelMtags.acceptBalancedDelimeters(ScalaToplevelMtags.scala:691)
	at scala.meta.internal.mtags.ScalaToplevelMtags.loop(ScalaToplevelMtags.scala:437)
	at scala.meta.internal.mtags.ScalaToplevelMtags.indexRoot(ScalaToplevelMtags.scala:56)
	at scala.meta.internal.mtags.MtagsIndexer.index(MtagsIndexer.scala:19)
	at scala.meta.internal.mtags.MtagsIndexer.index$(MtagsIndexer.scala:18)
	at scala.meta.internal.mtags.ScalaToplevelMtags.index(ScalaToplevelMtags.scala:43)
	at scala.meta.internal.mtags.Mtags$.allToplevels(Mtags.scala:125)
	at scala.meta.internal.metals.DefinitionProvider.fromMtags(DefinitionProvider.scala:376)
	at scala.meta.internal.metals.DefinitionProvider.$anonfun$positionOccurrence$4(DefinitionProvider.scala:296)
	at scala.Option.orElse(Option.scala:477)
	at scala.meta.internal.metals.DefinitionProvider.$anonfun$positionOccurrence$1(DefinitionProvider.scala:296)
	at scala.Option.flatMap(Option.scala:283)
	at scala.meta.internal.metals.DefinitionProvider.positionOccurrence(DefinitionProvider.scala:288)
	at scala.meta.internal.metals.MetalsLspService.$anonfun$definitionOrReferences$1(MetalsLspService.scala:2564)
	at scala.Option.map(Option.scala:242)
	at scala.meta.internal.metals.MetalsLspService.definitionOrReferences(MetalsLspService.scala:2560)
	at scala.meta.internal.metals.MetalsLspService.$anonfun$definition$1(MetalsLspService.scala:1404)
	at scala.meta.internal.metals.CancelTokens$.future(CancelTokens.scala:38)
	at scala.meta.internal.metals.MetalsLspService.definition(MetalsLspService.scala:1403)
	at scala.meta.internal.metals.WorkspaceLspService.definition(WorkspaceLspService.scala:373)
	at scala.meta.metals.lsp.DelegatingScalaService.definition(DelegatingScalaService.scala:69)
	at java.base/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:103)
	... 13 more

2024.03.12 17:05:36 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\customer.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:33)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:744)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:732)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:753)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:546)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:372)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:376)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:211)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:1011)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:24)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:962)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:332)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:25)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:14)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:541)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.03.12 18:46:24 INFO  Shutting down server
2024.03.12 18:46:24 INFO  shutting down Metals
2024.03.12 18:46:24 INFO  Exiting server
2024.03.22 10:22:25 INFO  Started: Metals version 1.2.2 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.87.2.
10:22:25.645 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- Flyway Community Edition 9.22.3 by Redgate
10:22:25.646 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- See release notes here: https://rd.gt/416ObMi
10:22:25.646 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- 
10:22:25.646 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classpath resources at 'classpath:db/callback' ...
10:22:25.646 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Determining location urls for classpath:db/callback using ClassLoader jdk.internal.loader.ClassLoaders$AppClassLoader@70dea4e ...
10:22:25.646 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Unable to resolve location classpath:db/callback.
10:22:25.646 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classpath resources at 'classpath:db/migration' ...
10:22:25.646 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Determining location urls for classpath:db/migration using ClassLoader jdk.internal.loader.ClassLoaders$AppClassLoader@70dea4e ...
10:22:25.646 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning URL: jar:file:/C:/Users/pp255070/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/scalameta/metals_2.13/1.2.2/metals_2.13-1.2.2.jar!/db/migration
10:22:25.654 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/
10:22:25.654 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V1__Create_tables.sql
10:22:25.654 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V2__Server_discovery.sql
10:22:25.654 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V3__Jar_symbols.sql
10:22:25.654 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V4__Fingerprints.sql
10:22:25.654 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classes at classpath:db/migration
10:22:25.654 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
10:22:25.654 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V1__Create_tables.sql
10:22:25.654 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V3__Jar_symbols.sql
10:22:25.654 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V4__Fingerprints.sql
10:22:25.654 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V2__Server_discovery.sql
10:22:25.720 [pool-1-thread-1] INFO org.flywaydb.core.FlywayExecutor -- Database: jdbc:h2:file:C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\metals (H2 2.2)
10:22:25.720 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- Driver: H2 JDBC Driver 2.2.224 (2023-09-17)
10:22:25.720 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- DDL Transactions Supported: false
10:22:25.720 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.schemahistory.SchemaHistoryFactory -- Schemas: 
10:22:25.720 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.schemahistory.SchemaHistoryFactory -- Default schema: null
10:22:25.735 [pool-1-thread-1] WARN org.flywaydb.core.internal.database.base.Database -- Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
10:22:25.740 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.callback.SqlScriptCallbackFactory -- Scanning for SQL callbacks ...
10:22:25.740 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
10:22:25.746 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.command.DbValidate -- Validating migrations ...
10:22:25.747 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
10:22:25.747 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
10:22:25.747 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V1__Create_tables.sql (filename: V1__Create_tables.sql)
10:22:25.747 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V3__Jar_symbols.sql (filename: V3__Jar_symbols.sql)
10:22:25.747 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V4__Fingerprints.sql (filename: V4__Fingerprints.sql)
10:22:25.747 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V2__Server_discovery.sql (filename: V2__Server_discovery.sql)
10:22:25.747 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
10:22:25.747 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V1__Create_tables.sql (filename: V1__Create_tables.sql)
10:22:25.747 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V3__Jar_symbols.sql (filename: V3__Jar_symbols.sql)
10:22:25.747 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V4__Fingerprints.sql (filename: V4__Fingerprints.sql)
10:22:25.747 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V2__Server_discovery.sql (filename: V2__Server_discovery.sql)
10:22:25.754 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbValidate -- Successfully validated 4 migrations (execution time 00:00.013s)
10:22:25.754 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.command.DbSchemas -- Skipping creation of existing schema: "PUBLIC"
10:22:25.765 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbMigrate -- Current version of schema "PUBLIC": 4
10:22:25.765 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbMigrate -- Schema "PUBLIC" is up to date. No migration necessary.
10:22:25.781 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- Memory usage: 47 of 100M
2024.03.22 10:22:26 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.03.22 10:22:26 WARN  Build server is not auto-connectable.
2024.03.22 10:22:34 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.03.22 10:22:36 INFO  time: code lens generation in 9.71s
2024.03.22 12:23:25 INFO  Shutting down server
2024.03.22 12:23:25 INFO  shutting down Metals
2024.03.22 12:23:25 INFO  Exiting server
2024.04.02 19:44:09 INFO  Started: Metals version 1.2.2 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.87.2.
19:44:10.592 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- Flyway Community Edition 9.22.3 by Redgate
19:44:10.593 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- See release notes here: https://rd.gt/416ObMi
19:44:10.593 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- 
19:44:10.597 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classpath resources at 'classpath:db/callback' ...
19:44:10.597 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Determining location urls for classpath:db/callback using ClassLoader jdk.internal.loader.ClassLoaders$AppClassLoader@70dea4e ...
19:44:10.597 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Unable to resolve location classpath:db/callback.
19:44:10.597 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classpath resources at 'classpath:db/migration' ...
19:44:10.598 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Determining location urls for classpath:db/migration using ClassLoader jdk.internal.loader.ClassLoaders$AppClassLoader@70dea4e ...
19:44:10.598 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning URL: jar:file:/C:/Users/pp255070/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/scalameta/metals_2.13/1.2.2/metals_2.13-1.2.2.jar!/db/migration
19:44:10.619 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/
19:44:10.620 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V1__Create_tables.sql
19:44:10.620 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V2__Server_discovery.sql
19:44:10.620 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V3__Jar_symbols.sql
19:44:10.620 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V4__Fingerprints.sql
19:44:10.620 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classes at classpath:db/migration
19:44:10.626 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
19:44:10.626 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V1__Create_tables.sql
19:44:10.627 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V3__Jar_symbols.sql
19:44:10.627 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V4__Fingerprints.sql
19:44:10.628 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V2__Server_discovery.sql
19:44:10.758 [pool-1-thread-1] INFO org.flywaydb.core.FlywayExecutor -- Database: jdbc:h2:file:C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\metals (H2 2.2)
19:44:10.758 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- Driver: H2 JDBC Driver 2.2.224 (2023-09-17)
19:44:10.758 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- DDL Transactions Supported: false
19:44:10.761 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.schemahistory.SchemaHistoryFactory -- Schemas: 
19:44:10.761 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.schemahistory.SchemaHistoryFactory -- Default schema: null
19:44:10.767 [pool-1-thread-1] WARN org.flywaydb.core.internal.database.base.Database -- Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
19:44:10.768 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.callback.SqlScriptCallbackFactory -- Scanning for SQL callbacks ...
19:44:10.770 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
19:44:10.777 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.command.DbValidate -- Validating migrations ...
19:44:10.780 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
19:44:10.786 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
19:44:10.786 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V1__Create_tables.sql (filename: V1__Create_tables.sql)
19:44:10.786 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V3__Jar_symbols.sql (filename: V3__Jar_symbols.sql)
19:44:10.787 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V4__Fingerprints.sql (filename: V4__Fingerprints.sql)
19:44:10.787 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V2__Server_discovery.sql (filename: V2__Server_discovery.sql)
19:44:10.787 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
19:44:10.787 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V1__Create_tables.sql (filename: V1__Create_tables.sql)
19:44:10.787 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V3__Jar_symbols.sql (filename: V3__Jar_symbols.sql)
19:44:10.787 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V4__Fingerprints.sql (filename: V4__Fingerprints.sql)
19:44:10.787 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V2__Server_discovery.sql (filename: V2__Server_discovery.sql)
19:44:10.800 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbValidate -- Successfully validated 4 migrations (execution time 00:00.023s)
19:44:10.803 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.command.DbSchemas -- Skipping creation of existing schema: "PUBLIC"
19:44:10.807 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbMigrate -- Current version of schema "PUBLIC": 4
19:44:10.812 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbMigrate -- Schema "PUBLIC" is up to date. No migration necessary.
19:44:10.845 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- Memory usage: 50 of 100M
2024.04.02 19:44:14 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.04.02 19:44:15 WARN  Build server is not auto-connectable.
2024.04.02 19:44:29 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\read.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.04.02 19:44:33 INFO  time: code lens generation in 18s
2024.04.02 21:17:17 INFO  Shutting down server
2024.04.02 21:17:17 INFO  shutting down Metals
2024.04.02 21:17:17 INFO  Exiting server
2024.04.08 20:10:34 INFO  Started: Metals version 1.2.2 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.88.0.
20:10:35.022 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- Flyway Community Edition 9.22.3 by Redgate
20:10:35.024 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- See release notes here: https://rd.gt/416ObMi
20:10:35.024 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- 
20:10:35.026 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classpath resources at 'classpath:db/callback' ...
20:10:35.026 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Determining location urls for classpath:db/callback using ClassLoader jdk.internal.loader.ClassLoaders$AppClassLoader@70dea4e ...
20:10:35.027 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Unable to resolve location classpath:db/callback.
20:10:35.027 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classpath resources at 'classpath:db/migration' ...
20:10:35.027 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Determining location urls for classpath:db/migration using ClassLoader jdk.internal.loader.ClassLoaders$AppClassLoader@70dea4e ...
20:10:35.027 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning URL: jar:file:/C:/Users/pp255070/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/scalameta/metals_2.13/1.2.2/metals_2.13-1.2.2.jar!/db/migration
20:10:35.031 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/
20:10:35.031 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V1__Create_tables.sql
20:10:35.032 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V2__Server_discovery.sql
20:10:35.032 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V3__Jar_symbols.sql
20:10:35.032 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V4__Fingerprints.sql
20:10:35.032 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classes at classpath:db/migration
20:10:35.034 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
20:10:35.034 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V1__Create_tables.sql
20:10:35.035 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V3__Jar_symbols.sql
20:10:35.035 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V4__Fingerprints.sql
20:10:35.035 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V2__Server_discovery.sql
20:10:35.118 [pool-1-thread-1] INFO org.flywaydb.core.FlywayExecutor -- Database: jdbc:h2:file:C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\metals (H2 2.2)
20:10:35.118 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- Driver: H2 JDBC Driver 2.2.224 (2023-09-17)
20:10:35.119 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- DDL Transactions Supported: false
20:10:35.119 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.schemahistory.SchemaHistoryFactory -- Schemas: 
20:10:35.119 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.schemahistory.SchemaHistoryFactory -- Default schema: null
20:10:35.125 [pool-1-thread-1] WARN org.flywaydb.core.internal.database.base.Database -- Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
20:10:35.127 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.callback.SqlScriptCallbackFactory -- Scanning for SQL callbacks ...
20:10:35.127 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
20:10:35.139 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.command.DbValidate -- Validating migrations ...
20:10:35.141 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
20:10:35.145 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
20:10:35.145 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V1__Create_tables.sql (filename: V1__Create_tables.sql)
20:10:35.145 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V3__Jar_symbols.sql (filename: V3__Jar_symbols.sql)
20:10:35.145 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V4__Fingerprints.sql (filename: V4__Fingerprints.sql)
20:10:35.145 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V2__Server_discovery.sql (filename: V2__Server_discovery.sql)
20:10:35.146 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
20:10:35.146 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V1__Create_tables.sql (filename: V1__Create_tables.sql)
20:10:35.146 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V3__Jar_symbols.sql (filename: V3__Jar_symbols.sql)
20:10:35.146 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V4__Fingerprints.sql (filename: V4__Fingerprints.sql)
20:10:35.146 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V2__Server_discovery.sql (filename: V2__Server_discovery.sql)
20:10:35.155 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbValidate -- Successfully validated 4 migrations (execution time 00:00.015s)
20:10:35.156 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.command.DbSchemas -- Skipping creation of existing schema: "PUBLIC"
20:10:35.159 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbMigrate -- Current version of schema "PUBLIC": 4
20:10:35.161 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbMigrate -- Schema "PUBLIC" is up to date. No migration necessary.
20:10:35.376 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- Memory usage: 24 of 128M
2024.04.08 20:10:35 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.04.08 20:10:35 WARN  Build server is not auto-connectable.
2024.04.08 20:10:39 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\3.ratings.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.04.08 20:10:41 INFO  time: code lens generation in 5.32s
2024.04.08 21:04:37 INFO  Shutting down server
2024.04.08 21:04:37 INFO  shutting down Metals
2024.04.08 21:04:37 INFO  Exiting server
2024.04.09 10:33:24 INFO  Started: Metals version 1.2.2 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.88.0.
10:33:25.440 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- Flyway Community Edition 9.22.3 by Redgate
10:33:25.440 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- See release notes here: https://rd.gt/416ObMi
10:33:25.440 [pool-1-thread-1] INFO org.flywaydb.core.internal.license.VersionPrinter -- 
10:33:25.455 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classpath resources at 'classpath:db/callback' ...
10:33:25.455 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Determining location urls for classpath:db/callback using ClassLoader jdk.internal.loader.ClassLoaders$AppClassLoader@70dea4e ...
10:33:25.455 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Unable to resolve location classpath:db/callback.
10:33:25.455 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classpath resources at 'classpath:db/migration' ...
10:33:25.455 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Determining location urls for classpath:db/migration using ClassLoader jdk.internal.loader.ClassLoaders$AppClassLoader@70dea4e ...
10:33:25.455 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning URL: jar:file:/C:/Users/pp255070/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/scalameta/metals_2.13/1.2.2/metals_2.13-1.2.2.jar!/db/migration
10:33:25.455 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/
10:33:25.455 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V1__Create_tables.sql
10:33:25.455 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V2__Server_discovery.sql
10:33:25.455 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V3__Jar_symbols.sql
10:33:25.455 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Found resource: db/migration/V4__Fingerprints.sql
10:33:25.455 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.classpath.ClassPathScanner -- Scanning for classes at classpath:db/migration
10:33:25.455 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
10:33:25.455 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V1__Create_tables.sql
10:33:25.455 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V3__Jar_symbols.sql
10:33:25.455 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V4__Fingerprints.sql
10:33:25.455 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.resource.ResourceNameValidator -- Validating V2__Server_discovery.sql
10:33:25.549 [pool-1-thread-1] INFO org.flywaydb.core.FlywayExecutor -- Database: jdbc:h2:file:C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\metals (H2 2.2)
10:33:25.549 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- Driver: H2 JDBC Driver 2.2.224 (2023-09-17)
10:33:25.549 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- DDL Transactions Supported: false
10:33:25.549 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.schemahistory.SchemaHistoryFactory -- Schemas: 
10:33:25.549 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.schemahistory.SchemaHistoryFactory -- Default schema: null
10:33:25.549 [pool-1-thread-1] WARN org.flywaydb.core.internal.database.base.Database -- Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
10:33:25.565 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.callback.SqlScriptCallbackFactory -- Scanning for SQL callbacks ...
10:33:25.565 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
10:33:25.565 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.command.DbValidate -- Validating migrations ...
10:33:25.565 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
10:33:25.577 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
10:33:25.577 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V1__Create_tables.sql (filename: V1__Create_tables.sql)
10:33:25.577 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V3__Jar_symbols.sql (filename: V3__Jar_symbols.sql)
10:33:25.577 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V4__Fingerprints.sql (filename: V4__Fingerprints.sql)
10:33:25.577 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V2__Server_discovery.sql (filename: V2__Server_discovery.sql)
10:33:25.577 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/ (filename: )
10:33:25.577 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V1__Create_tables.sql (filename: V1__Create_tables.sql)
10:33:25.577 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V3__Jar_symbols.sql (filename: V3__Jar_symbols.sql)
10:33:25.577 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V4__Fingerprints.sql (filename: V4__Fingerprints.sql)
10:33:25.577 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.scanner.Scanner -- Filtering out resource: db/migration/V2__Server_discovery.sql (filename: V2__Server_discovery.sql)
10:33:25.593 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbValidate -- Successfully validated 4 migrations (execution time 00:00.019s)
10:33:25.595 [pool-1-thread-1] DEBUG org.flywaydb.core.internal.command.DbSchemas -- Skipping creation of existing schema: "PUBLIC"
10:33:25.595 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbMigrate -- Current version of schema "PUBLIC": 4
10:33:25.603 [pool-1-thread-1] INFO org.flywaydb.core.internal.command.DbMigrate -- Schema "PUBLIC" is up to date. No migration necessary.
10:33:25.638 [pool-1-thread-1] DEBUG org.flywaydb.core.FlywayExecutor -- Memory usage: 47 of 100M
2024.04.09 10:33:27 WARN  no build tool detected in workspace 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning'. The most common cause for this problem is that the editor was opened in the wrong working directory, for example if you use sbt then the workspace directory should contain build.sbt. 
2024.04.09 10:33:27 WARN  Build server is not auto-connectable.
2024.04.09 10:33:33 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\3.ratings.scala. Using presentation compiler with project's scala-library version: 3.3.1
2024.04.09 10:33:34 INFO  time: code lens generation in 7.66s
Apr 09, 2024 12:30:18 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 89
Apr 09, 2024 12:30:27 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 99
Apr 09, 2024 12:40:34 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 107
Apr 09, 2024 12:47:22 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 109
Apr 09, 2024 12:50:29 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 136
Apr 09, 2024 12:50:30 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 137
Apr 09, 2024 12:51:41 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 145
2024.04.09 13:28:07 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\broadcast.scala
Apr 09, 2024 1:30:58 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 209
Apr 09, 2024 1:46:15 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 229
2024.04.09 14:01:30 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\5.linkedin.scala
Apr 09, 2024 2:01:36 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 271
Apr 09, 2024 3:40:48 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 388
2024.04.09 15:40:51 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\salting.scala
2024.04.09 15:42:08 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\salting.scala
Apr 09, 2024 3:42:28 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 448
2024.04.09 20:40:05 INFO  Shutting down server
2024.04.09 20:40:05 INFO  shutting down Metals
2024.04.09 20:40:05 INFO  Exiting server
2024.04.23 15:51:55 INFO  Started: Metals version 1.3.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.88.1.
SLF4J: Class path contains multiple SLF4J providers.
SLF4J: Found provider [scribe.slf4j.ScribeServiceProvider@5342c0d0]
SLF4J: Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@41239041]
SLF4J: See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual provider is of type [scribe.slf4j.ScribeServiceProvider@5342c0d0]
2024.04.23 15:51:55 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
Apr 23, 2024 3:51:57 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2
Apr 23, 2024 3:51:57 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1
2024.04.23 15:52:02 INFO  Running List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\scala-cli.BAT, setup-ide, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.04.23 15:52:02 INFO  Attempting to connect to the build server...
2024.04.23 15:52:02 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.04.23 15:52:03 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.04.23 15:52:06 INFO  BSP server: Starting compilation server
2024.04.23 15:52:12 INFO  time: Connected to build server in 9.87s
2024.04.23 15:52:12 INFO  Connected to Build server: scala-cli v1.1.0
2024.04.23 15:52:13 INFO  time: Imported build in 0.2s
2024.04.23 15:52:13 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.04.23 15:52:23 INFO  time: indexed workspace in 10s
2024.04.23 15:52:40 INFO  time: compiled sparklearning_bd2c96d2de in 26s
2024.04.23 15:52:40 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.04.23 15:52:41 INFO  time: compiled sparklearning_bd2c96d2de in 1.74s
2024.04.23 15:52:41 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.04.23 15:52:46 INFO  time: compiled sparklearning_bd2c96d2de in 4.59s
2024.04.23 15:52:53 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.04.23 15:52:56 INFO  time: compiled sparklearning_bd2c96d2de in 2.73s
Apr 23, 2024 3:54:25 PM org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint notify
INFO: Unsupported notification method: $/setTrace
2024.04.23 15:55:29 INFO  Shutting down server
2024.04.23 15:55:29 INFO  shutting down Metals
2024.04.23 15:55:29 INFO  Shut down connection with build server.
2024.04.23 15:55:29 INFO  Exiting server
2024.04.23 15:56:02 INFO  Started: Metals version 1.3.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.88.1.
SLF4J: Class path contains multiple SLF4J providers.
SLF4J: Found provider [scribe.slf4j.ScribeServiceProvider@56da4ddb]
SLF4J: Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@295bc6fd]
SLF4J: See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual provider is of type [scribe.slf4j.ScribeServiceProvider@56da4ddb]
2024.04.23 15:56:02 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.04.23 15:56:05 INFO  Attempting to connect to the build server...
2024.04.23 15:56:05 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.04.23 15:56:05 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.04.23 15:56:11 INFO  time: Connected to build server in 6.47s
2024.04.23 15:56:11 INFO  Connected to Build server: scala-cli v1.1.0
2024.04.23 15:56:12 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.04.23 15:56:15 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.04.23 15:56:23 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\example.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.04.23 15:56:27 INFO  time: indexed workspace in 3.81s
2024.04.23 15:56:28 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.04.23 15:56:36 INFO  time: compiled sparklearning_bd2c96d2de in 8.25s
2024.04.23 15:56:36 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.04.23 15:56:39 INFO  time: compiled sparklearning_bd2c96d2de in 2.87s
2024.04.23 21:24:57 INFO  Shutting down server
2024.04.23 21:24:57 INFO  shutting down Metals
2024.04.23 21:24:57 INFO  Shut down connection with build server.
2024.04.23 21:24:57 INFO  Exiting server
2024.04.24 11:12:31 INFO  Started: Metals version 1.3.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.88.1.
SLF4J: Class path contains multiple SLF4J providers.
SLF4J: Found provider [scribe.slf4j.ScribeServiceProvider@2995c796]
SLF4J: Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@6026d0d]
SLF4J: See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual provider is of type [scribe.slf4j.ScribeServiceProvider@2995c796]
2024.04.24 11:12:31 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.04.24 11:12:34 INFO  Attempting to connect to the build server...
2024.04.24 11:12:34 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.04.24 11:12:34 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.04.24 11:12:39 INFO  BSP server: Starting compilation server
2024.04.24 11:12:46 INFO  time: Connected to build server in 12s
2024.04.24 11:12:46 INFO  Connected to Build server: scala-cli v1.1.0
2024.04.24 11:12:47 INFO  time: Imported build in 0.19s
2024.04.24 11:12:48 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.04.24 11:12:48 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_stateful.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.04.24 11:12:57 INFO  time: indexed workspace in 8.62s
2024.04.24 11:13:01 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.04.24 11:13:06 INFO  time: compiled sparklearning_bd2c96d2de in 4.85s
2024.04.24 11:13:17 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.04.24 11:13:19 INFO  time: compiled sparklearning_bd2c96d2de in 2.46s
2024.04.24 19:30:26 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.04.24 19:30:31 INFO  time: compiled sparklearning_bd2c96d2de in 4.55s
2024.04.24 21:26:50 INFO  Shutting down server
2024.04.24 21:26:50 INFO  shutting down Metals
2024.04.24 21:26:50 INFO  Shut down connection with build server.
2024.04.24 21:26:50 INFO  Exiting server
2024.04.25 12:12:10 INFO  Started: Metals version 1.3.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.88.1.
SLF4J: Class path contains multiple SLF4J providers.
SLF4J: Found provider [scribe.slf4j.ScribeServiceProvider@3435dc21]
SLF4J: Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@2086f935]
SLF4J: See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual provider is of type [scribe.slf4j.ScribeServiceProvider@3435dc21]
2024.04.25 12:12:10 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.04.25 12:12:13 INFO  Attempting to connect to the build server...
2024.04.25 12:12:13 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.04.25 12:12:13 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.04.25 12:12:18 INFO  BSP server: Starting compilation server
2024.04.25 12:12:23 INFO  time: Connected to build server in 10s
2024.04.25 12:12:23 INFO  Connected to Build server: scala-cli v1.1.0
2024.04.25 12:12:24 INFO  time: Imported build in 0.22s
2024.04.25 12:12:25 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.04.25 12:12:33 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_stateful.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.04.25 12:12:38 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.04.25 12:12:38 INFO  time: indexed workspace in 4.8s
2024.04.25 12:12:45 INFO  time: compiled sparklearning_bd2c96d2de in 7.39s
2024.04.25 12:12:45 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.04.25 12:12:45 INFO  time: compiled sparklearning_bd2c96d2de in 0.94s
2024.04.25 18:52:56 INFO  Shutting down server
2024.04.25 18:52:56 INFO  shutting down Metals
2024.04.25 18:52:56 INFO  Shut down connection with build server.
2024.04.25 18:52:56 INFO  Exiting server
2024.05.02 11:46:25 INFO  Started: Metals version 1.3.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.88.1.
SLF4J: Class path contains multiple SLF4J providers.
SLF4J: Found provider [scribe.slf4j.ScribeServiceProvider@10694a4e]
SLF4J: Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@179f9927]
SLF4J: See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual provider is of type [scribe.slf4j.ScribeServiceProvider@10694a4e]
2024.05.02 11:46:25 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.05.02 11:46:27 INFO  Attempting to connect to the build server...
2024.05.02 11:46:27 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.05.02 11:46:27 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.05.02 11:46:30 INFO  BSP server: Starting compilation server
2024.05.02 11:46:34 INFO  time: Connected to build server in 7.29s
2024.05.02 11:46:34 INFO  Connected to Build server: scala-cli v1.1.0
2024.05.02 11:46:34 INFO  time: Imported build in 0.11s
2024.05.02 11:46:34 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.05.02 11:46:38 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_stateful.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.05.02 11:46:42 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.05.02 11:46:43 INFO  time: indexed workspace in 4.64s
2024.05.02 11:46:51 INFO  time: compiled sparklearning_bd2c96d2de in 8.27s
2024.05.02 11:46:51 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.05.02 11:46:51 INFO  time: compiled sparklearning_bd2c96d2de in 0.87s
2024.05.02 21:37:49 INFO  Shutting down server
2024.05.02 21:37:49 INFO  shutting down Metals
2024.05.02 21:37:49 INFO  Shut down connection with build server.
2024.05.02 21:37:49 INFO  Exiting server
2024.05.10 16:13:22 INFO  Started: Metals version 1.3.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.89.0.
SLF4J: Class path contains multiple SLF4J providers.
SLF4J: Found provider [scribe.slf4j.ScribeServiceProvider@667062b9]
SLF4J: Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@71c25d0c]
SLF4J: See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual provider is of type [scribe.slf4j.ScribeServiceProvider@667062b9]
2024.05.10 16:13:23 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.05.10 16:13:23 INFO  Attempting to connect to the build server...
2024.05.10 16:13:23 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.05.10 16:13:23 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.05.10 16:13:26 INFO  BSP server: Starting compilation server
2024.05.10 16:13:31 INFO  time: Connected to build server in 7.37s
2024.05.10 16:13:31 INFO  Connected to Build server: scala-cli v1.1.0
2024.05.10 16:13:31 INFO  time: Imported build in 0.12s
2024.05.10 16:13:31 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.05.10 16:13:37 INFO  time: indexed workspace in 5.78s
2024.05.10 16:13:47 INFO  time: compiled sparklearning_bd2c96d2de in 15s
2024.05.10 16:13:47 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.05.10 16:13:47 INFO  time: compiled sparklearning_bd2c96d2de in 0.71s
2024.05.10 16:34:48 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.05.10 16:34:54 INFO  time: compiled sparklearning_bd2c96d2de in 5.59s
May 10, 2024 4:37:08 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 43
2024.05.10 20:24:40 INFO  Shutting down server
2024.05.10 20:24:40 INFO  shutting down Metals
2024.05.10 20:24:40 INFO  Shut down connection with build server.
2024.05.10 20:24:40 INFO  Exiting server
2024.06.05 13:28:31 INFO  Started: Metals version 1.3.1 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.89.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@3c618c46]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@5e12e7fb]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@3c618c46]
2024.06.05 13:28:31 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.06.05 13:28:32 INFO  Attempting to connect to the build server...
2024.06.05 13:28:32 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.06.05 13:28:32 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.06.05 13:28:36 INFO  BSP server: Starting compilation server
2024.06.05 13:28:42 INFO  time: Connected to build server in 10s
2024.06.05 13:28:42 INFO  Connected to Build server: scala-cli v1.1.0
2024.06.05 13:28:42 INFO  time: Imported build in 0.13s
2024.06.05 13:28:43 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.06.05 13:28:53 INFO  time: compiled sparklearning_bd2c96d2de in 9.94s
2024.06.05 13:28:53 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.06.05 13:28:55 INFO  time: indexed workspace in 13s
2024.06.05 13:28:56 INFO  time: compiled sparklearning_bd2c96d2de in 2.77s
2024.06.05 17:12:11 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.06.05 17:12:16 INFO  time: compiled sparklearning_bd2c96d2de in 4.43s
2024.06.05 22:39:39 INFO  Shutting down server
2024.06.05 22:39:39 INFO  shutting down Metals
2024.06.05 22:39:39 INFO  Shut down connection with build server.
2024.06.05 22:39:39 INFO  Exiting server
2024.06.06 10:55:08 INFO  Started: Metals version 1.3.1 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.89.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@11554b05]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@568afd3]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@11554b05]
2024.06.06 10:55:10 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.06.06 10:55:11 INFO  Attempting to connect to the build server...
2024.06.06 10:55:11 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.06.06 10:55:11 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.06.06 10:55:19 INFO  BSP server: Starting compilation server
2024.06.06 10:55:27 INFO  time: Connected to build server in 15s
2024.06.06 10:55:27 INFO  Connected to Build server: scala-cli v1.1.0
2024.06.06 10:55:27 INFO  time: Imported build in 0.19s
2024.06.06 10:55:28 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.06.06 10:55:40 INFO  time: indexed workspace in 13s
2024.06.06 10:55:43 INFO  time: compiled sparklearning_bd2c96d2de in 14s
2024.06.06 10:55:43 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.06.06 10:55:51 INFO  time: compiled sparklearning_bd2c96d2de in 7.49s
2024.06.06 23:45:06 INFO  Shutting down server
2024.06.06 23:45:06 INFO  shutting down Metals
2024.06.06 23:45:06 INFO  Shut down connection with build server.
2024.06.06 23:45:06 INFO  Exiting server
2024.06.12 14:42:01 INFO  Started: Metals version 1.3.1 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.90.0.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@1f07cb5f]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@e1d3359]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@1f07cb5f]
2024.06.12 14:42:02 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.06.12 14:42:03 INFO  Attempting to connect to the build server...
2024.06.12 14:42:03 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.06.12 14:42:03 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.06.12 14:42:07 INFO  BSP server: Starting compilation server
2024.06.12 14:42:14 INFO  time: Connected to build server in 11s
2024.06.12 14:42:14 INFO  Connected to Build server: scala-cli v1.1.0
2024.06.12 14:42:14 INFO  time: Imported build in 0.15s
2024.06.12 14:42:15 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.06.12 14:42:28 INFO  time: compiled sparklearning_bd2c96d2de in 13s
2024.06.12 14:42:28 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.06.12 14:42:29 INFO  time: indexed workspace in 14s
2024.06.12 14:42:33 INFO  time: compiled sparklearning_bd2c96d2de in 4.37s
2024.06.12 21:41:38 INFO  Shutting down server
2024.06.12 21:41:38 INFO  shutting down Metals
2024.06.12 21:41:38 INFO  Shut down connection with build server.
2024.06.12 21:41:38 INFO  Exiting server
2024.06.17 14:57:03 INFO  Started: Metals version 1.3.1 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.90.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@23f40dde]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@3d11e583]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@23f40dde]
2024.06.17 14:57:04 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.06.17 14:57:05 INFO  Attempting to connect to the build server...
2024.06.17 14:57:05 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.06.17 14:57:05 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.06.17 14:57:09 INFO  BSP server: Starting compilation server
2024.06.17 14:57:14 INFO  time: Connected to build server in 9.41s
2024.06.17 14:57:14 INFO  Connected to Build server: scala-cli v1.1.0
2024.06.17 14:57:15 INFO  time: Imported build in 0.14s
2024.06.17 14:57:15 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
Jun 17, 2024 2:57:24 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1
2024.06.17 14:57:25 INFO  time: indexed workspace in 10s
2024.06.17 14:57:28 INFO  time: compiled sparklearning_bd2c96d2de in 12s
2024.06.17 14:57:28 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.06.17 14:57:32 INFO  time: compiled sparklearning_bd2c96d2de in 3.77s
2024.06.17 14:57:32 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.06.17 14:57:36 INFO  time: compiled sparklearning_bd2c96d2de in 3.1s
2024.06.17 14:57:36 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.06.17 14:57:38 INFO  time: compiled sparklearning_bd2c96d2de in 2.04s
2024.06.17 14:58:50 INFO  Shutting down server
2024.06.17 14:58:50 INFO  shutting down Metals
2024.06.17 14:58:50 INFO  Shut down connection with build server.
2024.06.17 14:58:50 INFO  Exiting server
2024.06.19 15:02:27 INFO  Started: Metals version 1.3.1 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.90.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@187ec29a]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@3be5f904]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@187ec29a]
2024.06.19 15:02:27 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.06.19 15:02:28 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.06.19 15:02:29 INFO  Attempting to connect to the build server...
2024.06.19 15:02:29 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.06.19 15:02:29 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.06.19 15:02:33 INFO  BSP server: Starting compilation server
2024.06.19 15:02:35 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.06.19 15:02:40 INFO  time: Connected to build server in 11s
2024.06.19 15:02:40 INFO  Connected to Build server: scala-cli v1.1.0
2024.06.19 15:02:40 INFO  time: Imported build in 0.15s
2024.06.19 15:02:41 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.06.19 15:02:46 INFO  time: indexed workspace in 5.19s
2024.06.19 15:02:52 INFO  time: compiled sparklearning_bd2c96d2de in 10s
2024.06.19 15:02:52 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.06.19 15:02:56 INFO  time: compiled sparklearning_bd2c96d2de in 3.67s
2024.06.19 15:02:56 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.06.19 15:02:59 INFO  time: compiled sparklearning_bd2c96d2de in 2.57s
2024.06.19 15:03:29 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.06.19 15:03:31 INFO  time: compiled sparklearning_bd2c96d2de in 2.19s
2024.06.19 15:13:13 INFO  Shutting down server
2024.06.19 15:13:13 INFO  shutting down Metals
2024.06.19 15:13:13 INFO  Shut down connection with build server.
2024.06.19 15:13:13 INFO  Exiting server
2024.06.19 16:20:08 INFO  Started: Metals version 1.3.1 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.90.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@23175dd1]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@18718278]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@23175dd1]
2024.06.19 16:20:08 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.06.19 16:20:09 INFO  Attempting to connect to the build server...
2024.06.19 16:20:09 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.06.19 16:20:09 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.06.19 16:20:13 INFO  time: Connected to build server in 4.33s
2024.06.19 16:20:13 INFO  Connected to Build server: scala-cli v1.1.0
2024.06.19 16:20:14 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.06.19 16:20:19 INFO  time: indexed workspace in 6.16s
2024.06.19 16:20:20 INFO  time: compiled sparklearning_bd2c96d2de in 6.03s
2024.06.19 16:20:20 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.06.19 16:20:23 INFO  time: compiled sparklearning_bd2c96d2de in 2.95s
2024.06.19 20:54:02 INFO  Shutting down server
2024.06.19 20:54:02 INFO  shutting down Metals
2024.06.19 20:54:02 INFO  Shut down connection with build server.
2024.06.19 20:54:02 INFO  Exiting server
2024.06.24 15:11:37 INFO  Started: Metals version 1.3.1 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.90.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@6364c685]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@679da4b5]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@6364c685]
2024.06.24 15:11:38 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.06.24 15:11:39 INFO  Attempting to connect to the build server...
2024.06.24 15:11:39 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.06.24 15:11:39 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.06.24 15:11:46 INFO  BSP server: Starting compilation server
2024.06.24 15:11:57 INFO  time: Connected to build server in 17s
2024.06.24 15:11:57 INFO  Connected to Build server: scala-cli v1.1.0
2024.06.24 15:11:57 INFO  time: Imported build in 0.3s
2024.06.24 15:11:58 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.06.24 15:12:14 INFO  time: compiled sparklearning_bd2c96d2de in 15s
2024.06.24 15:12:14 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.06.24 15:12:15 INFO  time: indexed workspace in 18s
2024.06.24 15:12:20 INFO  time: compiled sparklearning_bd2c96d2de in 5.56s
2024.06.24 17:54:17 INFO  Shutting down server
2024.06.24 17:54:17 INFO  shutting down Metals
2024.06.24 17:54:18 INFO  Shut down connection with build server.
2024.06.24 17:54:17 INFO  Exiting server
2024.06.24 17:54:48 INFO  Started: Metals version 1.3.2 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.90.2.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@4d8f746e]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@3cbb1a76]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@4d8f746e]
2024.06.24 17:54:49 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.06.24 17:54:50 INFO  Attempting to connect to the build server...
2024.06.24 17:54:50 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.06.24 17:54:50 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.06.24 17:54:56 INFO  time: Connected to build server in 5.64s
2024.06.24 17:54:56 INFO  Connected to Build server: scala-cli v1.1.0
2024.06.24 17:54:56 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.06.24 17:55:03 INFO  time: compiled sparklearning_bd2c96d2de in 7.33s
2024.06.24 17:55:03 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.06.24 17:55:04 INFO  time: indexed workspace in 8.57s
2024.06.24 17:55:07 INFO  time: compiled sparklearning_bd2c96d2de in 3.5s
2024.06.24 18:33:33 INFO  Shutting down server
2024.06.24 18:33:33 INFO  shutting down Metals
2024.06.24 18:33:33 INFO  Shut down connection with build server.
2024.06.24 18:33:33 INFO  Exiting server
2024.07.01 23:20:50 INFO  Started: Metals version 1.3.2 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.90.2.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@5e799e0a]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@6e2e99d]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@5e799e0a]
2024.07.01 23:20:53 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.01 23:20:54 INFO  Attempting to connect to the build server...
2024.07.01 23:20:54 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.07.01 23:20:54 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.07.01 23:20:59 INFO  BSP server: Starting compilation server
2024.07.01 23:21:06 INFO  time: Connected to build server in 11s
2024.07.01 23:21:06 INFO  Connected to Build server: scala-cli v1.1.0
2024.07.01 23:21:06 INFO  time: Imported build in 0.18s
2024.07.01 23:21:07 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.01 23:21:13 INFO  time: indexed workspace in 6.84s
2024.07.01 23:21:20 INFO  time: compiled sparklearning_bd2c96d2de in 13s
2024.07.01 23:21:20 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.01 23:21:25 INFO  time: compiled sparklearning_bd2c96d2de in 4.52s
2024.07.01 23:31:55 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.01 23:32:00 INFO  time: compiled sparklearning_bd2c96d2de in 4.63s
2024.07.01 23:32:36 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\2.customer.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:690)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:678)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:700)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:504)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:361)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:363)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:545)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.07.02 00:04:16 INFO  Shutting down server
2024.07.02 00:04:16 INFO  shutting down Metals
2024.07.02 00:04:16 INFO  Shut down connection with build server.
2024.07.02 00:04:16 INFO  Exiting server
2024.07.02 10:53:27 INFO  Started: Metals version 1.3.2 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.90.2.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@74f35d93]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@7adfacd5]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@74f35d93]
2024.07.02 10:53:27 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.02 10:53:28 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\sparkstreaming\example_countByWindow.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.02 10:53:29 INFO  Attempting to connect to the build server...
2024.07.02 10:53:29 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.07.02 10:53:29 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.07.02 10:53:32 INFO  BSP server: Starting compilation server
2024.07.02 10:53:37 INFO  time: Connected to build server in 7.86s
2024.07.02 10:53:37 INFO  Connected to Build server: scala-cli v1.1.0
2024.07.02 10:53:37 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.02 10:53:39 INFO  time: indexed workspace in 2.12s
2024.07.02 10:53:46 INFO  time: compiled sparklearning_bd2c96d2de in 8.56s
2024.07.02 10:53:46 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.02 10:53:49 INFO  time: compiled sparklearning_bd2c96d2de in 3.05s
2024.07.02 10:53:49 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.02 10:53:52 INFO  time: compiled sparklearning_bd2c96d2de in 2s
2024.07.02 10:53:52 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.02 10:53:54 INFO  time: compiled sparklearning_bd2c96d2de in 2.06s
2024.07.02 12:07:25 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.02 12:07:29 INFO  time: compiled sparklearning_bd2c96d2de in 3.88s
2024.07.02 12:19:05 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.02 12:19:09 INFO  time: compiled sparklearning_bd2c96d2de in 4s
2024.07.02 23:47:11 INFO  Shutting down server
2024.07.02 23:47:11 INFO  shutting down Metals
2024.07.02 23:47:11 INFO  Shut down connection with build server.
2024.07.02 23:47:11 INFO  Exiting server
2024.07.03 11:11:50 INFO  Started: Metals version 1.3.2 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.90.2.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@13790e88]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@168d36d1]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@13790e88]
2024.07.03 11:11:51 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.03 11:11:53 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\sparkSQL.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.03 11:11:55 INFO  Attempting to connect to the build server...
2024.07.03 11:11:55 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.07.03 11:11:55 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.07.03 11:12:02 INFO  BSP server: Starting compilation server
2024.07.03 11:12:11 INFO  time: Connected to build server in 16s
2024.07.03 11:12:11 INFO  Connected to Build server: scala-cli v1.1.0
2024.07.03 11:12:11 INFO  time: Imported build in 0.23s
2024.07.03 11:12:13 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.03 11:12:16 INFO  time: indexed workspace in 4.76s
2024.07.03 11:12:27 INFO  time: compiled sparklearning_bd2c96d2de in 13s
2024.07.03 11:12:27 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.03 11:12:32 INFO  time: compiled sparklearning_bd2c96d2de in 4.46s
2024.07.03 11:51:25 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.03 11:51:29 INFO  time: compiled sparklearning_bd2c96d2de in 4.33s
2024.07.03 14:06:39 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.03 14:06:42 INFO  time: compiled sparklearning_bd2c96d2de in 2.91s
Jul 03, 2024 4:10:12 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 129
2024.07.03 17:16:13 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\2.customer.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:690)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:678)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:700)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:504)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:361)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:363)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:545)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.07.03 19:51:14 INFO  Shutting down server
2024.07.03 19:51:14 INFO  shutting down Metals
2024.07.03 19:51:14 INFO  Shut down connection with build server.
2024.07.03 19:51:14 INFO  Exiting server
2024.07.12 23:32:38 INFO  Started: Metals version 1.3.3 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.91.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@4e30f6e4]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@54f136f6]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@4e30f6e4]
2024.07.12 23:32:38 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.12 23:32:40 INFO  Attempting to connect to the build server...
2024.07.12 23:32:40 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.07.12 23:32:40 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.07.12 23:32:44 INFO  BSP server: Starting compilation server
2024.07.12 23:32:48 INFO  time: Connected to build server in 8.31s
2024.07.12 23:32:48 INFO  Connected to Build server: scala-cli v1.1.0
2024.07.12 23:32:48 INFO  running doctor check
2024.07.12 23:32:48 INFO  java targets: sparklearning_bd2c96d2de, sparklearning_bd2c96d2de-test
2024.07.12 23:32:49 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.12 23:32:54 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.12 23:32:58 INFO  time: compiled sparklearning_bd2c96d2de in 8.98s
2024.07.12 23:32:58 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.12 23:33:01 INFO  time: compiled sparklearning_bd2c96d2de in 2.71s
2024.07.12 23:33:04 INFO  time: indexed workspace in 16s
2024.07.12 23:33:05 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.12 23:33:07 INFO  time: compiled sparklearning_bd2c96d2de in 2.61s
2024.07.12 23:33:07 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.12 23:33:10 INFO  time: compiled sparklearning_bd2c96d2de in 1.87s
2024.07.12 23:37:52 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.12 23:37:56 INFO  time: compiled sparklearning_bd2c96d2de in 3.88s
2024.07.12 23:38:24 INFO  Shutting down server
2024.07.12 23:38:24 INFO  shutting down Metals
2024.07.12 23:38:24 INFO  Shut down connection with build server.
2024.07.12 23:38:24 INFO  Exiting server
2024.07.19 12:25:37 INFO  Started: Metals version 1.3.3 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.91.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@4f1c68a3]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@115b2bd9]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@4f1c68a3]
2024.07.19 12:25:37 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.19 12:25:39 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\watermark.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.19 12:25:39 INFO  Attempting to connect to the build server...
2024.07.19 12:25:39 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.07.19 12:25:39 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.07.19 12:25:43 INFO  BSP server: Starting compilation server
2024.07.19 12:25:48 INFO  time: Connected to build server in 8.79s
2024.07.19 12:25:48 INFO  Connected to Build server: scala-cli v1.1.0
2024.07.19 12:25:48 INFO  time: Imported build in 0.12s
2024.07.19 12:25:48 INFO  running doctor check
2024.07.19 12:25:48 INFO  java targets: sparklearning_bd2c96d2de, sparklearning_bd2c96d2de-test
2024.07.19 12:25:49 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.19 12:25:52 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.19 12:25:53 INFO  time: indexed workspace in 4.37s
2024.07.19 12:26:01 INFO  time: compiled sparklearning_bd2c96d2de in 12s
2024.07.19 12:26:01 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.19 12:26:05 INFO  time: compiled sparklearning_bd2c96d2de in 3.78s
2024.07.19 12:26:05 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.19 12:26:08 INFO  time: compiled sparklearning_bd2c96d2de in 2.84s
2024.07.19 12:26:08 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.19 12:26:11 INFO  time: compiled sparklearning_bd2c96d2de in 2.81s
2024.07.19 21:13:41 INFO  Shutting down server
2024.07.19 21:13:41 INFO  shutting down Metals
2024.07.19 21:13:41 INFO  Shut down connection with build server.
2024.07.19 21:13:41 INFO  Exiting server
2024.07.21 20:43:37 INFO  Started: Metals version 1.3.3 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.91.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@4f1c68a3]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@115b2bd9]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@4f1c68a3]
2024.07.21 20:43:39 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.21 20:43:42 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\watermark.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.21 20:43:42 INFO  Attempting to connect to the build server...
2024.07.21 20:43:42 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.07.21 20:43:43 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.07.21 20:43:49 INFO  BSP server: Starting compilation server
2024.07.21 20:43:55 INFO  time: Connected to build server in 12s
2024.07.21 20:43:55 INFO  Connected to Build server: scala-cli v1.1.0
2024.07.21 20:43:55 INFO  time: Imported build in 0.16s
2024.07.21 20:43:55 INFO  running doctor check
2024.07.21 20:43:55 INFO  java targets: sparklearning_bd2c96d2de, sparklearning_bd2c96d2de-test
2024.07.21 20:43:56 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.21 20:43:59 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.21 20:43:59 INFO  time: indexed workspace in 5.02s
2024.07.21 20:44:10 INFO  time: compiled sparklearning_bd2c96d2de in 13s
2024.07.21 20:44:10 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.21 20:44:15 INFO  time: compiled sparklearning_bd2c96d2de in 4.57s
2024.07.21 20:44:15 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.21 20:44:18 INFO  time: compiled sparklearning_bd2c96d2de in 2.97s
2024.07.21 20:44:18 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.21 20:44:22 INFO  time: compiled sparklearning_bd2c96d2de in 3.21s
2024.07.21 21:47:03 INFO  Shutting down server
2024.07.21 21:47:03 INFO  shutting down Metals
2024.07.21 21:47:03 INFO  Shut down connection with build server.
2024.07.21 21:47:03 INFO  Exiting server
2024.07.22 10:39:16 INFO  Started: Metals version 1.3.3 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.91.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@2c794b13]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@b95a64e]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@2c794b13]
2024.07.22 10:39:16 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.22 10:39:17 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\watermark.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.22 10:39:18 INFO  Attempting to connect to the build server...
2024.07.22 10:39:18 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.07.22 10:39:18 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.07.22 10:39:21 INFO  BSP server: Starting compilation server
2024.07.22 10:39:26 INFO  time: Connected to build server in 8.58s
2024.07.22 10:39:26 INFO  Connected to Build server: scala-cli v1.1.0
2024.07.22 10:39:26 INFO  time: Imported build in 0.11s
2024.07.22 10:39:26 INFO  running doctor check
2024.07.22 10:39:26 INFO  java targets: sparklearning_bd2c96d2de, sparklearning_bd2c96d2de-test
2024.07.22 10:39:27 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.22 10:39:29 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.22 10:39:29 INFO  time: indexed workspace in 3.04s
2024.07.22 10:39:36 INFO  time: compiled sparklearning_bd2c96d2de in 9.27s
2024.07.22 10:39:36 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.22 10:39:39 INFO  time: compiled sparklearning_bd2c96d2de in 2.82s
2024.07.22 10:39:39 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.22 10:39:43 INFO  time: compiled sparklearning_bd2c96d2de in 3.3s
2024.07.22 10:39:56 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.22 10:39:57 INFO  time: compiled sparklearning_bd2c96d2de in 1.69s
Jul 22, 2024 3:16:48 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 533
2024.07.22 21:05:29 INFO  Shutting down server
2024.07.22 21:05:29 INFO  shutting down Metals
2024.07.22 21:05:29 INFO  Shut down connection with build server.
2024.07.22 21:05:29 INFO  Exiting server
2024.07.23 12:37:32 INFO  Started: Metals version 1.3.3 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.91.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@39434d88]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@524b468b]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@39434d88]
2024.07.23 12:37:33 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.23 12:37:35 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.23 12:37:36 INFO  Attempting to connect to the build server...
2024.07.23 12:37:36 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.07.23 12:37:36 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.07.23 12:37:40 INFO  BSP server: Starting compilation server
2024.07.23 12:37:48 INFO  time: Connected to build server in 11s
2024.07.23 12:37:48 INFO  Connected to Build server: scala-cli v1.1.0
2024.07.23 12:37:48 INFO  time: Imported build in 0.17s
2024.07.23 12:37:48 INFO  running doctor check
2024.07.23 12:37:48 INFO  java targets: sparklearning_bd2c96d2de, sparklearning_bd2c96d2de-test
2024.07.23 12:37:49 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.23 12:37:51 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.23 12:37:51 INFO  time: indexed workspace in 3.66s
2024.07.23 12:38:01 INFO  time: compiled sparklearning_bd2c96d2de in 11s
2024.07.23 12:38:01 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.23 12:38:05 INFO  time: compiled sparklearning_bd2c96d2de in 4.33s
2024.07.23 14:13:58 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.23 14:14:02 INFO  time: compiled sparklearning_bd2c96d2de in 4.02s
2024.07.23 14:57:42 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.23 14:57:46 INFO  time: compiled sparklearning_bd2c96d2de in 4.02s
2024.07.23 21:37:28 INFO  Shutting down server
2024.07.23 21:37:28 INFO  shutting down Metals
2024.07.23 21:37:28 INFO  Shut down connection with build server.
2024.07.23 21:37:28 INFO  Exiting server
2024.07.25 13:29:27 INFO  Started: Metals version 1.3.3 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.91.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@4f1c68a3]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@115b2bd9]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@4f1c68a3]
2024.07.25 13:29:27 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.25 13:29:28 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\1.word.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.25 13:29:29 INFO  Attempting to connect to the build server...
2024.07.25 13:29:29 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.07.25 13:29:29 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.07.25 13:29:33 INFO  BSP server: Starting compilation server
2024.07.25 13:29:37 INFO  time: Connected to build server in 7.81s
2024.07.25 13:29:37 INFO  Connected to Build server: scala-cli v1.1.0
2024.07.25 13:29:37 INFO  running doctor check
2024.07.25 13:29:37 INFO  java targets: sparklearning_bd2c96d2de, sparklearning_bd2c96d2de-test
2024.07.25 13:29:38 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.25 13:29:39 WARN  Flyway upgrade recommended: H2 2.2.224 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.25 13:29:39 INFO  time: indexed workspace in 2.61s
2024.07.25 13:29:46 INFO  time: compiled sparklearning_bd2c96d2de in 8.6s
2024.07.25 13:29:46 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.25 13:29:49 INFO  time: compiled sparklearning_bd2c96d2de in 3.04s
2024.07.25 13:29:49 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.25 13:29:51 INFO  time: compiled sparklearning_bd2c96d2de in 1.88s
2024.07.25 13:29:51 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.25 13:29:54 INFO  time: compiled sparklearning_bd2c96d2de in 2.03s
Exception in thread "pool-5-thread-1" java.lang.InterruptedException
	at scala.meta.internal.metals.FutureCancelToken.checkCanceled(FutureCancelToken.scala:29)
	at scala.meta.internal.pc.CompilerAccess.onCompilerJobQueue$$anonfun$1(CompilerAccess.scala:243)
	at scala.meta.internal.pc.CompilerJobQueue$Job.run(CompilerJobQueue.scala:152)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.base/java.lang.Thread.run(Thread.java:1583)
Jul 25, 2024 1:34:01 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 158
2024.07.25 13:35:00 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.25 13:35:04 INFO  time: compiled sparklearning_bd2c96d2de in 3.96s
2024.07.25 13:35:09 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\2.customer.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:690)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:678)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:700)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:504)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:361)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:363)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:545)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.07.25 13:35:16 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\2.customer.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:690)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:678)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:700)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:504)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:361)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:363)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:545)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.07.25 21:51:18 INFO  Shutting down server
2024.07.25 21:51:18 INFO  shutting down Metals
2024.07.25 21:51:18 INFO  Shut down connection with build server.
2024.07.25 21:51:18 INFO  Exiting server
2024.07.28 11:11:05 INFO  Started: Metals version 1.3.4 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.91.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@731075e1]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@20f3ffa4]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@731075e1]
2024.07.28 11:11:05 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
Jul 28, 2024 11:11:07 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 2
Jul 28, 2024 11:11:07 AM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1
2024.07.28 11:11:07 INFO  Attempting to connect to the build server...
2024.07.28 11:11:07 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.07.28 11:11:07 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.07.28 11:11:10 INFO  BSP server: Starting compilation server
2024.07.28 11:11:14 INFO  time: Connected to build server in 7.21s
2024.07.28 11:11:14 INFO  Connected to Build server: scala-cli v1.1.0
2024.07.28 11:11:14 INFO  time: Imported build in 0.12s
2024.07.28 11:11:14 INFO  running doctor check
2024.07.28 11:11:14 INFO  java targets: sparklearning_bd2c96d2de, sparklearning_bd2c96d2de-test
2024.07.28 11:11:15 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.28 11:11:22 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.28 11:11:23 INFO  time: indexed workspace in 8.99s
2024.07.28 11:11:27 INFO  time: compiled sparklearning_bd2c96d2de in 11s
2024.07.28 11:11:27 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.28 11:11:32 INFO  time: compiled sparklearning_bd2c96d2de in 4.78s
2024.07.28 11:11:32 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.28 11:11:36 INFO  time: compiled sparklearning_bd2c96d2de in 4.03s
2024.07.28 11:11:36 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.28 11:11:40 INFO  time: compiled sparklearning_bd2c96d2de in 3.43s
2024.07.28 13:40:40 ERROR Failed to tokenize input for semantic tokens for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\rdds\2.customer.scala
scala.meta.tokenizers.TokenizeException: <input>:4: error: invalid escape character
    val input = sc.textFile("c:\Users\pp255070\Downloads\customerorders.csv")
                                ^
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:23)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.Reporter.syntaxError(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter.syntaxError$(Reporter.scala:25)
	at scala.meta.internal.tokenizers.Reporter$$anon$1.syntaxError(Reporter.scala:32)
	at scala.meta.internal.tokenizers.LegacyScanner.invalidEscape(LegacyScanner.scala:690)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChar(LegacyScanner.scala:678)
	at scala.meta.internal.tokenizers.LegacyScanner.getLitChars(LegacyScanner.scala:700)
	at scala.meta.internal.tokenizers.LegacyScanner.getStringLit(LegacyScanner.scala:504)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchDoubleQuote$1(LegacyScanner.scala:361)
	at scala.meta.internal.tokenizers.LegacyScanner.fetchToken(LegacyScanner.scala:363)
	at scala.meta.internal.tokenizers.LegacyScanner.nextToken(LegacyScanner.scala:201)
	at scala.meta.internal.tokenizers.LegacyScanner.foreach(LegacyScanner.scala:912)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.uncachedTokenize(ScalametaTokenizer.scala:23)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.$anonfun$tokenize$1(ScalametaTokenizer.scala:17)
	at scala.collection.concurrent.TrieMap.getOrElseUpdate(TrieMap.scala:960)
	at scala.meta.internal.tokenizers.ScalametaTokenizer.tokenize(ScalametaTokenizer.scala:17)
	at scala.meta.internal.tokenizers.ScalametaTokenizer$$anon$2.apply(ScalametaTokenizer.scala:322)
	at scala.meta.tokenizers.Api$XtensionTokenizeDialectInput.tokenize(Api.scala:22)
	at scala.meta.tokenizers.Api$XtensionTokenizeInputLike.tokenize(Api.scala:13)
	at scala.meta.internal.metals.SemanticTokensProvider$.getTokens(SemanticTokensProvider.scala:28)
	at scala.meta.internal.metals.SemanticTokensProvider$.provide(SemanticTokensProvider.scala:89)
	at scala.meta.internal.metals.Compilers.$anonfun$semanticTokens$3(Compilers.scala:561)
	at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642)
	at java.lang.Thread.run(Thread.java:1583)

2024.07.28 14:41:02 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.28 14:41:05 INFO  time: compiled sparklearning_bd2c96d2de in 2.1s
2024.07.28 14:41:07 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.28 14:41:08 INFO  time: compiled sparklearning_bd2c96d2de in 1.49s
2024.07.28 14:55:12 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.28 14:55:14 INFO  time: compiled sparklearning_bd2c96d2de in 1.91s
Jul 28, 2024 2:56:55 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 537
2024.07.28 15:03:58 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.28 15:04:00 INFO  time: compiled sparklearning_bd2c96d2de in 1.88s
Jul 28, 2024 4:37:21 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 928
2024.07.28 23:41:15 INFO  Shutting down server
2024.07.28 23:41:15 INFO  shutting down Metals
2024.07.28 23:41:15 INFO  Shut down connection with build server.
2024.07.28 23:41:15 INFO  Exiting server
2024.07.29 10:26:48 INFO  Started: Metals version 1.3.4 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.91.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@413903dc]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@1affd626]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@413903dc]
2024.07.29 10:26:48 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.29 10:26:49 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 10:26:50 INFO  Attempting to connect to the build server...
2024.07.29 10:26:50 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.07.29 10:26:50 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.07.29 10:26:53 INFO  BSP server: Starting compilation server
2024.07.29 10:26:55 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\adv1RddToDS(case class).scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.29 10:26:58 INFO  time: Connected to build server in 8.4s
2024.07.29 10:26:58 INFO  Connected to Build server: scala-cli v1.1.0
2024.07.29 10:26:58 INFO  running doctor check
2024.07.29 10:26:58 INFO  java targets: sparklearning_bd2c96d2de, sparklearning_bd2c96d2de-test
2024.07.29 10:26:59 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.29 10:27:00 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.29 10:27:00 INFO  time: indexed workspace in 2.74s
2024.07.29 10:27:07 INFO  time: compiled sparklearning_bd2c96d2de in 8.41s
2024.07.29 10:27:07 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.29 10:27:10 INFO  time: compiled sparklearning_bd2c96d2de in 2.86s
2024.07.29 10:27:10 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.29 10:27:12 INFO  time: compiled sparklearning_bd2c96d2de in 1.92s
2024.07.29 10:27:12 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.29 10:27:15 INFO  time: compiled sparklearning_bd2c96d2de in 2.11s
2024.07.29 21:44:30 INFO  Shutting down server
2024.07.29 21:44:30 INFO  shutting down Metals
2024.07.29 21:44:31 INFO  Shut down connection with build server.
2024.07.29 21:44:30 INFO  Exiting server
2024.07.31 07:06:44 INFO  Started: Metals version 1.3.4 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.91.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@1d4a8155]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@12c583db]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@1d4a8155]
2024.07.31 07:06:45 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.31 07:06:46 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\Kafka\ProducerApp\MyProducer.java. Using presentation compiler with project's scala-library version: 3.3.3
2024.07.31 07:06:47 INFO  Attempting to connect to the build server...
2024.07.31 07:06:47 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.07.31 07:06:48 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.07.31 07:06:53 INFO  BSP server: Starting compilation server
Jul 31, 2024 7:06:56 AM scala.meta.internal.pc.CompilerAccess handleError
SEVERE: A severe compiler error occurred, full details of the error can be found in the error report C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\.reports\metals-full\2024-07-31\r_compiler-error_07-06-56-362.md
2024.07.31 07:07:00 INFO  time: Connected to build server in 12s
2024.07.31 07:07:00 INFO  Connected to Build server: scala-cli v1.1.0
2024.07.31 07:07:00 INFO  time: Imported build in 0.14s
2024.07.31 07:07:00 INFO  running doctor check
2024.07.31 07:07:00 INFO  java targets: sparklearning_bd2c96d2de, sparklearning_bd2c96d2de-test
2024.07.31 07:07:01 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.31 07:07:06 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.07.31 07:07:07 INFO  time: indexed workspace in 7.65s
2024.07.31 07:07:18 INFO  time: compiled sparklearning_bd2c96d2de in 17s
2024.07.31 07:07:18 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.31 07:07:24 INFO  time: compiled sparklearning_bd2c96d2de in 5.53s
2024.07.31 07:07:24 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.31 07:07:30 INFO  time: compiled sparklearning_bd2c96d2de in 4.37s
2024.07.31 07:07:30 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.07.31 07:07:34 INFO  time: compiled sparklearning_bd2c96d2de in 3.91s
2024.07.31 08:51:57 INFO  Shutting down server
2024.07.31 08:51:57 INFO  shutting down Metals
2024.07.31 08:51:57 INFO  Shut down connection with build server.
2024.07.31 08:51:57 INFO  Exiting server
2024.08.03 14:26:15 INFO  Started: Metals version 1.3.5 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.92.0.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@65f10105]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@11ed1918]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@65f10105]
2024.08.03 14:26:16 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.08.03 14:26:17 INFO  Attempting to connect to the build server...
2024.08.03 14:26:17 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.08.03 14:26:17 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.08.03 14:26:20 INFO  BSP server: Starting compilation server
2024.08.03 14:26:25 INFO  time: Connected to build server in 8.3s
2024.08.03 14:26:25 INFO  Connected to Build server: scala-cli v1.1.0
2024.08.03 14:26:25 INFO  time: Imported build in 0.11s
2024.08.03 14:26:25 INFO  running doctor check
2024.08.03 14:26:25 INFO  java targets: sparklearning_bd2c96d2de, sparklearning_bd2c96d2de-test
2024.08.03 14:26:26 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.08.03 14:26:32 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.08.03 14:26:32 INFO  time: indexed workspace in 7.53s
2024.08.03 14:26:35 INFO  time: compiled sparklearning_bd2c96d2de in 9.65s
2024.08.03 14:26:35 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.08.03 14:26:39 INFO  time: compiled sparklearning_bd2c96d2de in 3.72s
2024.08.03 17:00:38 INFO  Shutting down server
2024.08.03 17:00:38 INFO  shutting down Metals
2024.08.03 17:00:38 INFO  Shut down connection with build server.
2024.08.03 17:00:38 INFO  Exiting server
2024.08.04 09:48:59 INFO  Started: Metals version 1.3.5 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.92.0.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@3e307daa]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@53789512]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@3e307daa]
2024.08.04 09:49:01 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.08.04 09:49:01 INFO  Attempting to connect to the build server...
2024.08.04 09:49:01 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.08.04 09:49:02 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.08.04 09:49:06 INFO  BSP server: Starting compilation server
2024.08.04 09:49:12 INFO  time: Connected to build server in 10s
2024.08.04 09:49:12 INFO  Connected to Build server: scala-cli v1.1.0
2024.08.04 09:49:12 INFO  time: Imported build in 0.13s
2024.08.04 09:49:12 INFO  running doctor check
2024.08.04 09:49:12 INFO  java targets: sparklearning_bd2c96d2de, sparklearning_bd2c96d2de-test
2024.08.04 09:49:13 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.08.04 09:49:16 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.08.04 09:49:16 INFO  time: indexed workspace in 4.45s
2024.08.04 09:49:20 INFO  time: compiled sparklearning_bd2c96d2de in 7.72s
2024.08.04 09:49:20 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.08.04 09:49:23 INFO  time: compiled sparklearning_bd2c96d2de in 2.54s
2024.08.04 22:36:25 INFO  Shutting down server
2024.08.04 22:36:25 INFO  shutting down Metals
2024.08.04 22:36:25 INFO  Shut down connection with build server.
2024.08.04 22:36:25 INFO  Exiting server
2024.08.05 14:28:45 INFO  Started: Metals version 1.3.5 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.92.0.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@46af28f8]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@f91c398]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@46af28f8]
2024.08.05 14:28:46 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.08.05 14:28:46 INFO  Attempting to connect to the build server...
2024.08.05 14:28:46 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.08.05 14:28:46 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.08.05 14:28:50 INFO  BSP server: Starting compilation server
2024.08.05 14:28:54 INFO  time: Connected to build server in 7.8s
2024.08.05 14:28:54 INFO  Connected to Build server: scala-cli v1.1.0
2024.08.05 14:28:54 INFO  time: Imported build in 0.1s
2024.08.05 14:28:54 INFO  running doctor check
2024.08.05 14:28:54 INFO  java targets: sparklearning_bd2c96d2de, sparklearning_bd2c96d2de-test
2024.08.05 14:28:55 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.08.05 14:28:59 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.08.05 14:28:59 INFO  time: indexed workspace in 5.03s
2024.08.05 14:29:03 INFO  time: compiled sparklearning_bd2c96d2de in 8.56s
2024.08.05 14:29:03 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.08.05 14:29:07 INFO  time: compiled sparklearning_bd2c96d2de in 3.18s
2024.08.05 23:35:23 INFO  Shutting down server
2024.08.05 23:35:23 INFO  shutting down Metals
2024.08.05 23:35:23 INFO  Shut down connection with build server.
2024.08.05 23:35:23 INFO  Exiting server
2024.09.18 14:40:22 INFO  Started: Metals version 1.3.5 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.93.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@519583bc]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@5150b71f]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@519583bc]
2024.09.18 14:40:23 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.09.18 14:40:23 INFO  Attempting to connect to the build server...
2024.09.18 14:40:23 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.09.18 14:40:23 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.09.18 14:40:26 INFO  BSP server: Starting compilation server
2024.09.18 14:40:29 INFO  time: Connected to build server in 6.14s
2024.09.18 14:40:29 INFO  Connected to Build server: scala-cli v1.1.0
2024.09.18 14:40:29 INFO  running doctor check
2024.09.18 14:40:29 INFO  java targets: sparklearning_bd2c96d2de, sparklearning_bd2c96d2de-test
2024.09.18 14:40:30 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.09.18 14:40:33 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.09.18 14:40:33 INFO  time: indexed workspace in 4.11s
2024.09.18 14:40:37 INFO  time: compiled sparklearning_bd2c96d2de in 6.7s
2024.09.18 14:40:37 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.09.18 14:40:39 INFO  time: compiled sparklearning_bd2c96d2de in 2.45s
2024.09.18 14:41:08 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.09.18 14:41:10 INFO  time: compiled sparklearning_bd2c96d2de in 2.23s
2024.09.18 21:43:32 INFO  Shutting down server
2024.09.18 21:43:32 INFO  shutting down Metals
2024.09.18 21:43:32 INFO  Shut down connection with build server.
2024.09.18 21:43:32 INFO  Exiting server
2024.09.19 11:37:52 INFO  Started: Metals version 1.3.5 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.93.1.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@2b8c2d6b]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@5d07e75e]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@2b8c2d6b]
2024.09.19 11:37:52 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.09.19 11:37:53 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\tumbling_window.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.09.19 11:37:54 INFO  Attempting to connect to the build server...
2024.09.19 11:37:54 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.09.19 11:37:54 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.09.19 11:37:57 INFO  BSP server: Starting compilation server
2024.09.19 11:38:05 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.09.19 11:38:06 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.09.19 11:38:06 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.09.19 11:38:06 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.09.19 11:38:08 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.09.19 11:38:11 WARN  no build target for: C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala
2024.09.19 11:38:11 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\dataframes\writeexample.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.09.19 11:38:13 INFO  Shutting down server
2024.09.19 11:38:13 INFO  shutting down Metals
2024.09.19 11:38:13 INFO  Exiting server
2024.10.10 17:27:10 INFO  Started: Metals version 1.3.5 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.94.0.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@1daa7a3c]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@35a938bb]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@1daa7a3c]
2024.10.10 17:27:11 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.10.10 17:27:12 INFO  Attempting to connect to the build server...
2024.10.10 17:27:12 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.10.10 17:27:12 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.10.10 17:27:15 INFO  BSP server: Starting compilation server
2024.10.10 17:27:20 INFO  time: Connected to build server in 8.53s
2024.10.10 17:27:20 INFO  Connected to Build server: scala-cli v1.1.0
2024.10.10 17:27:20 INFO  time: Imported build in 0.12s
2024.10.10 17:27:20 INFO  running doctor check
2024.10.10 17:27:20 INFO  java targets: sparklearning_bd2c96d2de, sparklearning_bd2c96d2de-test
2024.10.10 17:27:21 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.10.10 17:27:26 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.10.10 17:27:26 INFO  time: indexed workspace in 6.4s
2024.10.10 17:27:32 INFO  time: compiled sparklearning_bd2c96d2de in 10s
2024.10.10 17:27:32 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.10.10 17:27:35 INFO  time: compiled sparklearning_bd2c96d2de in 2.87s
2024.10.10 17:27:35 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.10.10 17:27:37 INFO  time: compiled sparklearning_bd2c96d2de in 2.43s
2024.10.10 17:27:37 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.10.10 17:27:40 INFO  time: compiled sparklearning_bd2c96d2de in 2.22s
2024.10.10 19:57:22 INFO  Shutting down server
2024.10.10 19:57:22 INFO  shutting down Metals
2024.10.10 19:57:23 INFO  Shut down connection with build server.
2024.10.10 19:57:22 INFO  Exiting server
2024.10.17 22:25:40 INFO  Started: Metals version 1.3.5 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.94.2.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@7e29179f]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@4bfd100e]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@7e29179f]
2024.10.17 22:25:41 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.10.17 22:25:42 INFO  Attempting to connect to the build server...
2024.10.17 22:25:42 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.10.17 22:25:42 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.10.17 22:25:45 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala. Using presentation compiler with project's scala-library version: 3.3.3
Oct 17, 2024 10:25:45 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1
2024.10.17 22:25:45 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.10.17 22:25:45 INFO  BSP server: Starting compilation server
2024.10.17 22:25:51 INFO  time: Connected to build server in 8.7s
2024.10.17 22:25:51 INFO  Connected to Build server: scala-cli v1.1.0
2024.10.17 22:25:51 INFO  time: Imported build in 0.1s
2024.10.17 22:25:51 INFO  running doctor check
2024.10.17 22:25:51 INFO  java targets: sparklearning_bd2c96d2de, sparklearning_bd2c96d2de-test
2024.10.17 22:25:51 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.10.17 22:25:53 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.10.17 22:25:53 INFO  time: indexed workspace in 3.33s
2024.10.17 22:26:00 INFO  time: compiled sparklearning_bd2c96d2de in 8.88s
2024.10.17 22:26:00 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.10.17 22:26:03 INFO  time: compiled sparklearning_bd2c96d2de in 2.77s
2024.10.17 22:26:03 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.10.17 22:26:06 INFO  time: compiled sparklearning_bd2c96d2de in 2.31s
2024.10.17 22:26:06 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.10.17 22:26:08 INFO  time: compiled sparklearning_bd2c96d2de in 1.79s
2024.10.17 23:52:44 INFO  Shutting down server
2024.10.17 23:52:44 INFO  shutting down Metals
2024.10.17 23:52:44 INFO  Shut down connection with build server.
2024.10.17 23:52:44 INFO  Exiting server
2024.10.18 14:04:02 INFO  Started: Metals version 1.3.5 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.94.2.
SLF4J(W): Class path contains multiple SLF4J providers.
SLF4J(W): Found provider [scribe.slf4j.ScribeServiceProvider@26d8d269]
SLF4J(W): Found provider [ch.qos.logback.classic.spi.LogbackServiceProvider@36e42f23]
SLF4J(W): See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J(I): Actual provider is of type [scribe.slf4j.ScribeServiceProvider@26d8d269]
2024.10.18 14:04:03 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.10.18 14:04:04 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala. Using presentation compiler with project's scala-library version: 3.3.3
2024.10.18 14:04:05 INFO  Attempting to connect to the build server...
2024.10.18 14:04:05 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.10.18 14:04:05 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.10.18 14:04:10 INFO  BSP server: Starting compilation server
2024.10.18 14:04:16 INFO  time: Connected to build server in 11s
2024.10.18 14:04:16 INFO  Connected to Build server: scala-cli v1.1.0
2024.10.18 14:04:16 INFO  time: Imported build in 0.13s
2024.10.18 14:04:16 INFO  running doctor check
2024.10.18 14:04:16 INFO  java targets: sparklearning_bd2c96d2de, sparklearning_bd2c96d2de-test
2024.10.18 14:04:17 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.10.18 14:04:19 WARN  Flyway upgrade recommended: H2 2.3.230 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.220.
2024.10.18 14:04:19 INFO  time: indexed workspace in 3.02s
2024.10.18 14:04:26 INFO  time: compiled sparklearning_bd2c96d2de in 9.56s
2024.10.18 14:04:26 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.10.18 14:04:29 INFO  time: compiled sparklearning_bd2c96d2de in 2.78s
2024.10.18 14:04:29 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.10.18 14:04:32 INFO  time: compiled sparklearning_bd2c96d2de in 2.41s
2024.10.18 14:04:32 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.10.18 14:04:34 INFO  time: compiled sparklearning_bd2c96d2de in 1.9s
2024.10.18 21:25:49 INFO  Shutting down server
2024.10.18 21:25:49 INFO  shutting down Metals
2024.10.18 21:25:50 INFO  BSP server: Oct 18, 2024 9:25:50 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleNotification
2024.10.18 21:25:50 INFO  BSP server: WARNING: Notification threw an exception: {
2024.10.18 21:25:50 INFO  Shut down connection with build server.
2024.10.18 21:25:50 INFO  BSP server:   "jsonrpc": "2.0",
2024.10.18 21:25:50 INFO  BSP server:   "method": "build/exit",
2024.10.18 21:25:50 INFO  BSP server:   "params": null
2024.10.18 21:25:50 INFO  BSP server: }
2024.10.18 21:25:50 INFO  BSP server: java.lang.RuntimeException: java.lang.reflect.InvocationTargetException
2024.10.18 21:25:50 INFO  BSP server: 	at org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint.lambda$null$0(GenericEndpoint.java:67)
2024.10.18 21:25:50 INFO  BSP server: 	at org.eclipse.lsp4j.jsonrpc.services.GenericEndpoint.notify(GenericEndpoint.java:152)
2024.10.18 21:25:50 INFO  BSP server: 	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.handleNotification(RemoteEndpoint.java:220)
2024.10.18 21:25:50 INFO  BSP server: 	at org.eclipse.lsp4j.jsonrpc.RemoteEndpoint.consume(RemoteEndpoint.java:187)
2024.10.18 21:25:50 INFO  BSP server: 	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.handleMessage(StreamMessageProducer.java:194)
2024.10.18 21:25:50 INFO  BSP server: 	at org.eclipse.lsp4j.jsonrpc.json.StreamMessageProducer.listen(StreamMessageProducer.java:94)
2024.10.18 21:25:50 INFO  BSP server: 	at org.eclipse.lsp4j.jsonrpc.json.ConcurrentMessageProcessor.run(ConcurrentMessageProcessor.java:113)
2024.10.18 21:25:50 INFO  BSP server: 	at java.base@17.0.6/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
2024.10.18 21:25:50 INFO  BSP server: 	at java.base@17.0.6/java.util.concurrent.FutureTask.run(FutureTask.java:264)
2024.10.18 21:25:50 INFO  BSP server: 	at java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
2024.10.18 21:25:50 INFO  BSP server: 	at java.base@17.0.6/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
2024.10.18 21:25:50 INFO  BSP server: 	at java.base@17.0.6/java.lang.Thread.run(Thread.java:833)
2024.10.18 21:25:50 INFO  BSP server: 	at com.oracle.svm.core.thread.PlatformThreads.threadStartRoutine(PlatformThreads.java:775)
2024.10.18 21:25:50 INFO  BSP server: 	at com.oracle.svm.core.windows.WindowsPlatformThreads.osThreadStartRoutine(WindowsPlatformThreads.java:178)
2024.10.18 21:25:50 INFO  BSP server: Caused by: java.lang.reflect.InvocationTargetException
2024.10.18 21:25:49 INFO  Exiting server
2024.11.05 13:05:10 INFO  Started: Metals version 1.4.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.95.0.
2024.11.05 13:05:10 WARN  Flyway upgrade recommended: H2 2.3.232 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.224.
2024.11.05 13:05:11 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala. Using presentation compiler with project's scala-library version: 3.3.4
Nov 05, 2024 1:05:17 PM org.eclipse.lsp4j.jsonrpc.RemoteEndpoint handleCancellation
WARNING: Unmatched cancel notification for request id 1
2024.11.05 13:05:18 INFO  Attempting to connect to the build server...
2024.11.05 13:05:18 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.11.05 13:05:18 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.11.05 13:05:21 INFO  BSP server: Starting compilation server
2024.11.05 13:05:26 INFO  time: Connected to build server in 7.91s
2024.11.05 13:05:26 INFO  Connected to Build server: scala-cli v1.1.0
2024.11.05 13:05:26 INFO  time: Imported build in 0.1s
2024.11.05 13:05:26 INFO  running doctor check
2024.11.05 13:05:26 INFO  java targets: sparklearning_bd2c96d2de, sparklearning_bd2c96d2de-test
2024.11.05 13:05:26 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.11.05 13:05:33 WARN  Flyway upgrade recommended: H2 2.3.232 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.224.
2024.11.05 13:05:36 INFO  time: compiled sparklearning_bd2c96d2de in 9.84s
2024.11.05 13:05:36 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.11.05 13:05:40 INFO  time: compiled sparklearning_bd2c96d2de in 3.65s
2024.11.05 13:05:46 INFO  time: indexed workspace in 19s
2024.11.05 17:04:03 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.11.05 17:04:07 INFO  time: compiled sparklearning_bd2c96d2de in 4.54s
2024.11.05 17:04:07 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.11.05 17:04:10 INFO  time: compiled sparklearning_bd2c96d2de in 2.56s
2024.11.05 23:58:01 INFO  Shutting down server
2024.11.05 23:58:01 INFO  shutting down Metals
2024.11.05 23:58:01 INFO  Shut down connection with build server.
2024.11.05 23:58:01 INFO  Exiting server
2024.11.06 14:46:24 INFO  Started: Metals version 1.4.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.95.1.
2024.11.06 14:46:25 WARN  Flyway upgrade recommended: H2 2.3.232 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.224.
2024.11.06 14:46:25 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala. Using presentation compiler with project's scala-library version: 3.3.4
2024.11.06 14:46:27 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala. Using presentation compiler with project's scala-library version: 3.3.4
2024.11.06 14:46:27 INFO  Attempting to connect to the build server...
2024.11.06 14:46:27 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.11.06 14:46:28 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.11.06 14:46:30 INFO  BSP server: Starting compilation server
2024.11.06 14:46:32 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala. Using presentation compiler with project's scala-library version: 3.3.4
2024.11.06 14:46:32 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala. Using presentation compiler with project's scala-library version: 3.3.4
2024.11.06 14:46:33 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala. Using presentation compiler with project's scala-library version: 3.3.4
2024.11.06 14:46:33 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala. Using presentation compiler with project's scala-library version: 3.3.4
2024.11.06 14:46:34 INFO  time: Connected to build server in 7.05s
2024.11.06 14:46:34 INFO  Connected to Build server: scala-cli v1.1.0
2024.11.06 14:46:35 INFO  running doctor check
2024.11.06 14:46:35 INFO  java targets: sparklearning_bd2c96d2de, sparklearning_bd2c96d2de-test
2024.11.06 14:46:35 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.11.06 14:46:41 WARN  Flyway upgrade recommended: H2 2.3.232 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.224.
2024.11.06 14:46:41 INFO  time: indexed workspace in 6.64s
2024.11.06 14:46:43 INFO  time: compiled sparklearning_bd2c96d2de in 8.13s
2024.11.06 14:46:43 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.11.06 14:46:46 INFO  time: compiled sparklearning_bd2c96d2de in 2.69s
2024.11.06 14:46:46 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.11.06 14:46:48 INFO  time: compiled sparklearning_bd2c96d2de in 1.9s
2024.11.06 14:46:48 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.11.06 14:46:50 INFO  time: compiled sparklearning_bd2c96d2de in 1.78s
2024.11.06 18:58:26 INFO  Shutting down server
2024.11.06 18:58:26 INFO  shutting down Metals
2024.11.06 18:58:26 INFO  Shut down connection with build server.
2024.11.06 18:58:26 INFO  Exiting server
2024.11.07 13:24:35 INFO  Started: Metals version 1.4.0 in folders 'C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning' for client Visual Studio Code 1.95.1.
2024.11.07 13:24:37 WARN  Flyway upgrade recommended: H2 2.3.232 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.224.
2024.11.07 13:24:37 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala. Using presentation compiler with project's scala-library version: 3.3.4
2024.11.07 13:24:38 INFO  no build target found for C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\SparkStructuredStreaming\innerjoin_streamtostream.scala. Using presentation compiler with project's scala-library version: 3.3.4
2024.11.07 13:24:39 INFO  Attempting to connect to the build server...
2024.11.07 13:24:39 INFO  Running BSP server List(C:\Users\pp255070\AppData\Local\Coursier\data\bin\.scala-cli.aux.exe, bsp, --json-options, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.scala-build\ide-options-v2.json, C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning)
2024.11.07 13:24:39 INFO  tracing is disabled for protocol BSP, to enable tracing of incoming and outgoing JSON messages create an empty file at C:\Users\pp255070\OneDrive - Teradata\Documents\sparklearning\.metals\bsp.trace.json or C:\Users\pp255070\AppData\Local\scalameta\metals\cache\bsp.trace.json
2024.11.07 13:24:44 INFO  BSP server: Starting compilation server
2024.11.07 13:24:51 INFO  time: Connected to build server in 12s
2024.11.07 13:24:51 INFO  Connected to Build server: scala-cli v1.1.0
2024.11.07 13:24:51 INFO  time: Imported build in 0.12s
2024.11.07 13:24:51 INFO  running doctor check
2024.11.07 13:24:51 INFO  java targets: sparklearning_bd2c96d2de, sparklearning_bd2c96d2de-test
2024.11.07 13:24:52 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.11.07 13:24:55 WARN  Flyway upgrade recommended: H2 2.3.232 is newer than this version of Flyway and support has not been tested. The latest supported version of H2 is 2.2.224.
2024.11.07 13:24:55 INFO  time: indexed workspace in 3.69s
2024.11.07 13:25:01 INFO  time: compiled sparklearning_bd2c96d2de in 9.17s
2024.11.07 13:25:01 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.11.07 13:25:04 INFO  time: compiled sparklearning_bd2c96d2de in 2.74s
2024.11.07 13:25:04 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.11.07 13:25:07 INFO  time: compiled sparklearning_bd2c96d2de in 2.4s
2024.11.07 13:25:07 INFO  compiling sparklearning_bd2c96d2de (56 scala sources and 5 java sources)
2024.11.07 13:25:09 INFO  time: compiled sparklearning_bd2c96d2de in 1.75s
2024.11.08 00:13:23 INFO  Shutting down server
2024.11.08 00:13:23 INFO  shutting down Metals
2024.11.08 00:13:24 INFO  Shut down connection with build server.
2024.11.08 00:13:23 INFO  Exiting server
